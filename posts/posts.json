[
  {
    "path": "posts/2023-02-21-reanalysis-sexual-attraction-to-visual-sexual-stimuli-in-association-with-steroid-hormones-across-menstrual-cycles-and-fertility-treatment/",
    "title": "Reanalysis: Sexual attraction to visual sexual stimuli and hormones",
    "description": "Analyzing the public data shared along with a recent publication by Schön et al. (2023): Sexual attraction to visual sexual stimuli in association with steroid hormones across menstrual cycles and fertility treatment",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2023-02-22",
    "categories": [
      "hormones",
      "hibar"
    ],
    "contents": "\n\nContents\nAccuracy of our estradiol and progesterone imputations\nSlightly different analyses\nMultilevel generalizability\nA multivariate model\nA location-scale model\nGroup mean centering\nLatent group mean centering\nImputations and lag\nLatent lag\nBringing it all together\n\n“Conclusion”\nThings I didn’t do or that still confuse me\n\n\n\n\nShow code\n\n# importing the data downloaded from the supplementary here https://www.sciencedirect.com/science/article/pii/S0306453023000380#sec0115\nlibrary(tidyverse)\n\ntheme_set(theme_bw())\ncycles <- rio::import(\"ScienceDirect_files_21Feb2023_09-06-38.857/mmc3/SPSS_Dataset_Cycle_1_2.sav\")\n# cycles %>% names()\n\n# cycles %>% select(starts_with(\"Z\"))\ncycles_long <- cycles %>% pivot_longer(starts_with(\"Z\")) %>% \n  separate(name, c(\"cycle\", \"time\", \"name\"), extra = \"merge\") %>% \n  pivot_wider()\n\n# unique(cycles_long$cycle)\n# unique(cycles_long$time)\ncycles_long <- cycles_long %>% \n  mutate(fc_day = as.numeric(recode(time, \"T1\" = \"4\", \n                         \"T2\" = \"13\",\n                         \"T3\" = \"21\",\n                         \"T4\" = \"28\")) - 1)\ncycles_long$fc_day %>% table(exclude=NULL)\n\n.\n  3  12  20  27 \n180 180 180 180 \n\nShow code\n\ncycles_long <- cycles_long %>% \n  mutate(logOESTR = log(OESTR), logPROG = log(PROG))\n\nlead2 <- cycles_long %>% select(ID, cycle, fc_day, logOESTR_lag2 = logOESTR, logPROG_lag2 = logPROG) %>% \n  mutate(fc_day = fc_day + 2)\n\ncycles_long <- cycles_long %>% \n  mutate_at(vars(starts_with(\"SR_\")), ~ (. - 50)/20 )\n\ncycles_longer <- cycles_long %>% \n  group_by(ID, cycle) %>% \n  tidyr::expand(fc_day = c(3, 5, 12, 14, 20, 22, 27, 29)) %>% \n  full_join(cycles_long, by = c(\"ID\", \"cycle\", \"fc_day\")) %>% \n  left_join(lead2, by = c(\"ID\", \"cycle\", \"fc_day\")) %>% \n  mutate(fc_day_lag2 = fc_day - 2)\n\n# table(cycles_longer$fc_day)\n# table(cycles_longer$fc_day_lag2)\n\nfc_days <- rio::import(\"https://files.osf.io/v1/resources/u9xad/providers/github/merge_files/fc_days.sav\")\ncycles_longer <- cycles_longer %>% \n  left_join(fc_days, by = c(\"fc_day\" = \"fc_day\")) %>% \n  ungroup()\n\ncycles_longer <- cycles_longer %>% \n  left_join(fc_days %>% rename_with(~ str_c(., \"_lag2\")), by = c(\"fc_day_lag2\" = \"fc_day_lag2\")) %>% \n  ungroup()\n\n\n# ggplot(cycles_long, aes(fc_day, log(OESTR))) + geom_point() + geom_smooth()\n# ggplot(cycles_longer, aes(fc_day, logOESTR_lag2)) + geom_point() + geom_smooth()\n# ggplot(cycles_long, aes(fc_day, log(PROG))) + geom_point() + geom_smooth()\n# ggplot(cycles_longer, aes(log(OESTR), est_estradiol_fc)) + geom_point()\n\n# lm(log(OESTR) ~ est_estradiol_fc, cycles_longer)\n# lm(log(PROG) ~ est_progesterone_fc, cycles_longer)\n\n\nThe following paper was recently published by Schön et al. in Psychoneuroendocrinology: Sexual attraction to visual sexual stimuli in association with steroid hormones across menstrual cycles and fertility treatment, doi:10.1016/j.psyneuen.2023.106060\n\nAbstract\nBackground\nSteroid hormones (i.e., estradiol, progesterone, and testosterone) are considered to play a crucial role in the regulation of women’s sexual desire and sexual attraction to sexual stimuli throughout the menstrual cycle. However, the literature is inconsistent, and methodologically sound studies on the relationship between steroid hormones and women’s sexual attraction are rare.\nMethods:\nThis prospective longitudinal multisite study examined estradiol, progesterone, and testosterone serum levels in association with sexual attraction to visual sexual stimuli in naturally cycling women and in women undergoing fertility treatment (in vitro fertilization, IVF). Across ovarian stimulation of fertility treatment, estradiol reaches supraphysiological levels, while other ovarian hormones remain nearly stable. Ovarian stimulation hence offers a unique quasi-experimental model to study concentration-dependent effects of estradiol. Hormonal parameters and sexual attraction to visual sexual stimuli assessed with computerized visual analogue scales were collected at four time points per cycle, i.e., during the menstrual, preovulatory, mid-luteal, and premenstrual phases, across two consecutive menstrual cycles (n = 88 and n = 68 for the first and second cycle, respectively). Women undergoing fertility treatment (n = 44) were assessed twice, at the beginning and at the end of ovarian stimulation. Sexually explicit photographs served as visual sexual stimuli.\nResults\nIn naturally cycling women, sexual attraction to visual sexual stimuli did not vary consistently across two consecutive menstrual cycles. While in the first menstrual cycle sexual attraction to male bodies, couples kissing, and at intercourse varied significantly with a peak in the preovulatory phase, (all p ≤ 0.001), there was no significant variability across the second cycle. Univariable and multivariable models evaluating repeated cross-sectional relationships and intraindividual change scores revealed no consistent associations between estradiol, progesterone, and testosterone and sexual attraction to visual sexual stimuli throughout both menstrual cycles. Also, no significant association with any hormone was found when the data from both menstrual cycles were combined. In women undergoing ovarian stimulation of IVF, sexual attraction to visual sexual stimuli did not vary over time and was not associated with estradiol levels despite intraindividual changes in estradiol levels from 122.0 to 11,746.0 pmol/l with a mean (SD) of 3,553.9 (2,472.4) pmol/l.\nConclusions\nThese results imply that neither physiological levels of estradiol, progesterone, and testosterone in naturally cycling women nor supraphysiological levels of estradiol due to ovarian stimulation exert any relevant effect on women’s sexual attraction to visual sexual stimuli.\nThe paper caught my attention for two reasons:\nit’s well-done, interesting work, including serum hormones and both a naturally cycling sample as well as a sample of women undergoing ovarian hyperstimulation in preparation for in vitro fertilisation\nthey openly shared their data, which I love to see1.\nSo, naturally, I delved right in.\nAccuracy of our estradiol and progesterone imputations\nAlmost the first thing I wanted to do was to check the accuracy of our imputations for estradiol and progesterone. In our recent paper, we had computed the accuracy of imputing log estradiol and progesterone from menstrual cycle phase. However, because we only had raw data for one serum dataset, we used a statistical approach (approximative LOO) to reduce overfitting. One reviewer was skeptical that we would find such good performance in independent data.\n\n\nShow code\n\no_ests <- broom::tidy(cor.test(cycles_longer$est_estradiol_fc, log(cycles_longer$OESTR)))\np_ests <- broom::tidy(cor.test(cycles_longer$est_progesterone_fc, log(cycles_longer$PROG)))\n\n\nSo, I merged my imputed estradiol and progesterone values on their “time” variable, which, I thought, can be understood as a cycle day counted forward from the last menstrual onset.\ntheir sampling scheduleIn the BioCycle study data, I had found the accuracy to be 0.57 [0.55;0.59]. Here, it was 0.68 [0.64;0.72]. For progesterone, we had reported 0.72 [0.70;0.74] and here I got 0.79 [0.76;0.82].\nThe values here are actually better! They are more in line with our accuracy estimates for backward-counting (.68 & .83). This might be because they do not have strictly days since last menstrual onset here, but rather I back-translated that from their graph of time points. In actual fact, they used some smart scheduling techniques based on LH and sonography. Another difference might be the variance in cycle phase, which they maximized with two measurement occasions close to menstruation, one around ovulation, and one mid-luteal occasion. I could adjust for that, but for now, I mainly take the message that our imputations seem to work pretty well on independent data.\nSlightly different analyses\nReading the paper, I couldn’t help wonder whether slightly different analysis choices would have led to different results. They used generalized estimating equations and it all seemed well-done if slightly different than what I normally do. But from my own experience with this kind of data (mostly unpublished), I’ve come to the conclusion that:\nlogging steroid hormone concentrations is slightly better than not doing so because\nnot logging you have to make arbitrary decisions how to deal with influential ‘outliers’ which are, however, still bioplausible\nthere is some evidence that associations are linear after logging\nexplained variance by cycle phase was slightly bigger in my recent paper\ninteractions between E and P, or their ratio E/P naturally turn into additive (or rather subtractive) terms after logging, reducing model complexity\n\nthat the relationship between steroid hormones and sexual desire is best predicted by log(estradiol/progesterone)\nthere is some evidence that the effect of serum log(estradiol/progesterone) is strongest at a lag of around two days on psychological outcomes, but much of that is based on salivary immunoassays, which I don’t put much stock in\nthat it might be better to leave log(testosterone) out of the equation at first, because it’s plausibly a mediator\nI figured I could probably aggregate across their four outcomes (ratings of stimuli of male faces, bodies, kissing, intercourse).\nI figured their might be substantial heterogeneity in residual variances, as that’s been my experience with visual analogue rating scales\nMultilevel generalizability\nTo determine whether I could aggregate across their four outcomes, I ran a multilevel generalizability analysis. I brought their visual analogue scales from 0 to 100 to approximate unit variance by subtracting 50 and dividing by 20.\n\n\nShow code\n\ncycles_long <- cycles_long %>% mutate(cycle_time = str_c(cycle, time))\ndf <- cycles_long %>% select(ID, cycle_time, starts_with(\"SR_\")) %>% drop_na() %>% as.data.frame\npsych::mlr(df, grp = \"ID\", Time = \"cycle_time\")\n\n\nMultilevel Generalizability analysis   \nCall: psych::mlr(x = df, grp = \"ID\", Time = \"cycle_time\")\n\nThe data had  88  observations taken over  8  time intervals for  3 items.\n\n Alternative estimates of reliability based upon Generalizability theory\n\nRkF  =  0.98 Reliability of average of all ratings across all items and  times (Fixed time effects)\nR1R  =  0.75 Generalizability of a single time point across all items (Random time effects)\nRkR  =  0.96 Generalizability of average time points across all items (Random time effects)\nRc   =  0.41 Generalizability of change (fixed time points, fixed items) \nRkRn =  0.92 Generalizability of between person differences averaged over time (time nested within people)\nRcn  =  0 Generalizability of within person variations averaged over items  (time nested within people)\n\n These reliabilities are derived from the components of variance estimated by ANOVA \n             variance Percent\nID               0.25    0.20\nTime             0.00    0.00\nItems            0.30    0.24\nID x time        0.05    0.04\nID x items       0.41    0.33\ntime x items     0.00    0.00\nResidual         0.22    0.18\nTotal            1.24    1.00\n\n The nested components of variance estimated from lme are:\n         variance Percent\nid        4.3e-01 3.2e-01\nid(time)  1.1e-09 8.4e-10\nresidual  8.9e-01 6.8e-01\ntotal     1.3e+00 1.0e+00\n\nTo see the ANOVA and alpha by subject, use the short = FALSE option.\n To see the summaries of the ICCs by subject and time, use all=TRUE\n To see specific objects select from the following list:\n ANOVA s.lmer s.lme alpha summary.by.person summary.by.time ICC.by.person ICC.by.time lmer long Call\n\n\n\nShow code\n\ncycles_long %>% select(ID, cycle_time, starts_with(\"SR_\")) %>% pivot_longer(-c(ID, cycle_time)) %>% \n  ggplot(aes(value)) + geom_histogram() +\n  facet_grid(cycle_time ~ name)\n\n\n\nFigure 1: Distributions of the outcome visual analogue scale ratings over time. (Z=cycle, T=time point)\n\n\n\nHmm, the generalizability of within person variations averaged over items is zero, so maybe aggregating is not a good idea. However, a multivariate model would allow me to do some partial pooling across outcomes, so went with that.\nA multivariate model\nSo, in the below model, I:\nlogged estradiol and progesterone, this way I did not have to include the estradiol-progesterone ratio in the model\nomitted testosterone, at least as a first step\nallowed slopes to vary by person and cycle\nallowed correlations across outcomes, both for the residuals and the varying slopes and intercepts\n\n\nShow code\n\nlibrary(brms)\nlibrary(cmdstanr)\nlibrary(tidybayes)\nknitr::opts_chunk$set(tidy = FALSE)\noptions(brms.backend = \"cmdstanr\",  # I use the cmdstanr backend\n        mc.cores = 8, \n        brms.threads = 2,           # which allows me to multithread\n        brms.file_refit = \"on_change\", # this is useful when doing iterative model building, though it can misfire, be careful\n        width = 8000) \n\nm1mv0 <- brm(mvbind(SR_Faces, SR_Bodies, SR_Kissing, SR_Intercourse) ~  cycle + (1 |i|ID) + (1 |c|ID:cycle), cycles_long %>% drop_na(logOESTR, logPROG),\n            iter = 6000, file = \"m1mv0\",\n            control = list(adapt_delta = 0.99))\n\nm1mv <- brm(mvbind(SR_Faces, SR_Bodies, SR_Kissing, SR_Intercourse) ~ log(OESTR) + log(PROG) + cycle + (1 + log(OESTR) + log(PROG)|i|ID) + (1 + log(OESTR) + log(PROG)|c|ID:cycle), cycles_long, \n            iter = 6000, file = \"m1mv\",\n            control = list(adapt_delta = 0.99))\n\n\n\nModel output and comparison to null model\n\n\nShow code\n\noptions(width = 8000)\nm1mv\n\n Family: MV(gaussian, gaussian, gaussian, gaussian) \n  Links: mu = identity; sigma = identity\n         mu = identity; sigma = identity\n         mu = identity; sigma = identity\n         mu = identity; sigma = identity \nFormula: SR_Faces ~ log(OESTR) + log(PROG) + cycle + (1 + log(OESTR) + log(PROG) | i | ID) + (1 + log(OESTR) + log(PROG) | c | ID:cycle) \n         SR_Bodies ~ log(OESTR) + log(PROG) + cycle + (1 + log(OESTR) + log(PROG) | i | ID) + (1 + log(OESTR) + log(PROG) | c | ID:cycle) \n         SR_Kissing ~ log(OESTR) + log(PROG) + cycle + (1 + log(OESTR) + log(PROG) | i | ID) + (1 + log(OESTR) + log(PROG) | c | ID:cycle) \n         SR_Intercourse ~ log(OESTR) + log(PROG) + cycle + (1 + log(OESTR) + log(PROG) | i | ID) + (1 + log(OESTR) + log(PROG) | c | ID:cycle) \n   Data: cycles_long (Number of observations: 551) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 1;\n         total post-warmup draws = 12000\n\nGroup-Level Effects: \n~ID (Number of levels: 87) \n                                                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(SRFaces_Intercept)                                   0.91      0.18     0.52     1.24 1.00     1754      954\nsd(SRFaces_logOESTR)                                    0.09      0.05     0.01     0.18 1.01      384     1451\nsd(SRFaces_logPROG)                                     0.06      0.03     0.01     0.12 1.00     1262     1162\nsd(SRBodies_Intercept)                                  0.71      0.09     0.52     0.89 1.00     3926     3637\nsd(SRBodies_logOESTR)                                   0.03      0.02     0.00     0.09 1.01      802     1388\nsd(SRBodies_logPROG)                                    0.03      0.02     0.00     0.07 1.00     2272     4007\nsd(SRKissing_Intercept)                                 0.80      0.11     0.60     1.05 1.00     5869     6772\nsd(SRKissing_logOESTR)                                  0.05      0.03     0.00     0.12 1.00     1228     3401\nsd(SRKissing_logPROG)                                   0.03      0.02     0.00     0.07 1.00     2925     5597\nsd(SRIntercourse_Intercept)                             0.69      0.14     0.39     0.97 1.00     4201     4153\nsd(SRIntercourse_logOESTR)                              0.08      0.03     0.01     0.14 1.01     1482     2455\nsd(SRIntercourse_logPROG)                               0.02      0.01     0.00     0.05 1.00     7089     5680\ncor(SRFaces_Intercept,SRFaces_logOESTR)                -0.07      0.27    -0.57     0.47 1.00     2049     5232\ncor(SRFaces_Intercept,SRFaces_logPROG)                  0.06      0.24    -0.44     0.52 1.00     2412     6102\ncor(SRFaces_logOESTR,SRFaces_logPROG)                   0.10      0.27    -0.43     0.59 1.00     2919     5583\ncor(SRFaces_Intercept,SRBodies_Intercept)               0.36      0.16     0.00     0.64 1.00     1142     2225\ncor(SRFaces_logOESTR,SRBodies_Intercept)                0.15      0.24    -0.35     0.59 1.00      876     1793\ncor(SRFaces_logPROG,SRBodies_Intercept)                 0.17      0.23    -0.30     0.59 1.00     1093     2287\ncor(SRFaces_Intercept,SRBodies_logOESTR)                0.01      0.26    -0.50     0.51 1.00    12488     9042\ncor(SRFaces_logOESTR,SRBodies_logOESTR)                 0.02      0.27    -0.49     0.54 1.00     5779     8230\ncor(SRFaces_logPROG,SRBodies_logOESTR)                  0.00      0.27    -0.53     0.53 1.00     8097     8997\ncor(SRBodies_Intercept,SRBodies_logOESTR)              -0.01      0.27    -0.51     0.51 1.00     8516     9109\ncor(SRFaces_Intercept,SRBodies_logPROG)                 0.03      0.25    -0.46     0.51 1.00    11937     9061\ncor(SRFaces_logOESTR,SRBodies_logPROG)                 -0.02      0.27    -0.53     0.51 1.00     6642     8450\ncor(SRFaces_logPROG,SRBodies_logPROG)                   0.02      0.27    -0.50     0.54 1.00     7737     8150\ncor(SRBodies_Intercept,SRBodies_logPROG)                0.10      0.25    -0.40     0.56 1.00    12621     8147\ncor(SRBodies_logOESTR,SRBodies_logPROG)                 0.02      0.27    -0.51     0.54 1.00     6623     8980\ncor(SRFaces_Intercept,SRKissing_Intercept)              0.40      0.16     0.05     0.67 1.00     1375     1418\ncor(SRFaces_logOESTR,SRKissing_Intercept)               0.11      0.24    -0.39     0.56 1.01     1090     1814\ncor(SRFaces_logPROG,SRKissing_Intercept)               -0.17      0.23    -0.59     0.31 1.00     1347     1555\ncor(SRBodies_Intercept,SRKissing_Intercept)             0.19      0.16    -0.14     0.46 1.00     3093     5296\ncor(SRBodies_logOESTR,SRKissing_Intercept)              0.06      0.26    -0.45     0.54 1.00     1436     3259\ncor(SRBodies_logPROG,SRKissing_Intercept)               0.13      0.24    -0.38     0.58 1.00     2175     4124\ncor(SRFaces_Intercept,SRKissing_logOESTR)              -0.03      0.26    -0.53     0.48 1.00     6664     8724\ncor(SRFaces_logOESTR,SRKissing_logOESTR)               -0.08      0.27    -0.57     0.46 1.00     4768     7422\ncor(SRFaces_logPROG,SRKissing_logOESTR)                -0.08      0.27    -0.57     0.45 1.00     5973     8418\ncor(SRBodies_Intercept,SRKissing_logOESTR)              0.15      0.26    -0.38     0.61 1.00    10292     8256\ncor(SRBodies_logOESTR,SRKissing_logOESTR)               0.07      0.27    -0.47     0.58 1.00     7156     8895\ncor(SRBodies_logPROG,SRKissing_logOESTR)                0.06      0.27    -0.49     0.57 1.00     8805     9999\ncor(SRKissing_Intercept,SRKissing_logOESTR)            -0.18      0.28    -0.66     0.40 1.00     4508     8079\ncor(SRFaces_Intercept,SRKissing_logPROG)               -0.07      0.26    -0.54     0.45 1.00    13308     8995\ncor(SRFaces_logOESTR,SRKissing_logPROG)                -0.03      0.27    -0.54     0.51 1.00     8504     9278\ncor(SRFaces_logPROG,SRKissing_logPROG)                  0.04      0.27    -0.50     0.55 1.00     9818     8006\ncor(SRBodies_Intercept,SRKissing_logPROG)              -0.00      0.26    -0.49     0.50 1.00    14921     8442\ncor(SRBodies_logOESTR,SRKissing_logPROG)               -0.01      0.27    -0.52     0.51 1.00     7387     8837\ncor(SRBodies_logPROG,SRKissing_logPROG)                 0.02      0.27    -0.50     0.54 1.00     8177     9815\ncor(SRKissing_Intercept,SRKissing_logPROG)             -0.05      0.26    -0.53     0.47 1.00    13370     9196\ncor(SRKissing_logOESTR,SRKissing_logPROG)              -0.00      0.27    -0.52     0.53 1.00     7398     9032\ncor(SRFaces_Intercept,SRIntercourse_Intercept)          0.02      0.20    -0.36     0.40 1.00     2583     4005\ncor(SRFaces_logOESTR,SRIntercourse_Intercept)          -0.03      0.24    -0.51     0.44 1.00     1166     2638\ncor(SRFaces_logPROG,SRIntercourse_Intercept)           -0.05      0.24    -0.52     0.41 1.00     1573     3470\ncor(SRBodies_Intercept,SRIntercourse_Intercept)         0.21      0.17    -0.15     0.53 1.00     5264     7247\ncor(SRBodies_logOESTR,SRIntercourse_Intercept)          0.05      0.26    -0.45     0.54 1.00     1664     3815\ncor(SRBodies_logPROG,SRIntercourse_Intercept)           0.16      0.25    -0.36     0.61 1.00     2143     3525\ncor(SRKissing_Intercept,SRIntercourse_Intercept)        0.46      0.19     0.03     0.75 1.00     2193     5048\ncor(SRKissing_logOESTR,SRIntercourse_Intercept)         0.19      0.26    -0.35     0.66 1.00     2642     6558\ncor(SRKissing_logPROG,SRIntercourse_Intercept)          0.13      0.26    -0.40     0.60 1.00     3781     7742\ncor(SRFaces_Intercept,SRIntercourse_logOESTR)           0.12      0.23    -0.34     0.54 1.00     4581     6479\ncor(SRFaces_logOESTR,SRIntercourse_logOESTR)            0.07      0.26    -0.44     0.57 1.00     2286     5319\ncor(SRFaces_logPROG,SRIntercourse_logOESTR)             0.01      0.25    -0.48     0.50 1.00     3672     7120\ncor(SRBodies_Intercept,SRIntercourse_logOESTR)         -0.05      0.22    -0.48     0.39 1.00     9113     7600\ncor(SRBodies_logOESTR,SRIntercourse_logOESTR)          -0.04      0.27    -0.55     0.49 1.00     2956     6047\ncor(SRBodies_logPROG,SRIntercourse_logOESTR)            0.10      0.26    -0.44     0.59 1.00     3664     6303\ncor(SRKissing_Intercept,SRIntercourse_logOESTR)         0.29      0.23    -0.21     0.68 1.00     7440     5910\ncor(SRKissing_logOESTR,SRIntercourse_logOESTR)          0.02      0.27    -0.51     0.54 1.00     4481     7853\ncor(SRKissing_logPROG,SRIntercourse_logOESTR)           0.07      0.27    -0.46     0.58 1.00     5425     9041\ncor(SRIntercourse_Intercept,SRIntercourse_logOESTR)    -0.09      0.27    -0.58     0.46 1.00     4465     7950\ncor(SRFaces_Intercept,SRIntercourse_logPROG)           -0.04      0.28    -0.56     0.50 1.00    19037     8436\ncor(SRFaces_logOESTR,SRIntercourse_logPROG)            -0.01      0.27    -0.53     0.51 1.00    16186     8912\ncor(SRFaces_logPROG,SRIntercourse_logPROG)             -0.00      0.28    -0.53     0.53 1.00    14895     8501\ncor(SRBodies_Intercept,SRIntercourse_logPROG)          -0.03      0.28    -0.55     0.50 1.00    20543     8788\ncor(SRBodies_logOESTR,SRIntercourse_logPROG)            0.00      0.28    -0.54     0.54 1.00    10941     8990\ncor(SRBodies_logPROG,SRIntercourse_logPROG)            -0.00      0.28    -0.55     0.53 1.00    11439     9846\ncor(SRKissing_Intercept,SRIntercourse_logPROG)         -0.01      0.27    -0.54     0.50 1.00    16414     9556\ncor(SRKissing_logOESTR,SRIntercourse_logPROG)           0.01      0.28    -0.53     0.54 1.00     9671     9039\ncor(SRKissing_logPROG,SRIntercourse_logPROG)            0.04      0.28    -0.51     0.57 1.00     8979    10350\ncor(SRIntercourse_Intercept,SRIntercourse_logPROG)     -0.01      0.27    -0.53     0.53 1.00    13612    10073\ncor(SRIntercourse_logOESTR,SRIntercourse_logPROG)      -0.04      0.27    -0.55     0.50 1.00    10481    10230\n\n~ID:cycle (Number of levels: 155) \n                                                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(SRFaces_Intercept)                                   0.23      0.14     0.01     0.49 1.00     1060     3003\nsd(SRFaces_logOESTR)                                    0.05      0.02     0.01     0.09 1.01      755     1774\nsd(SRFaces_logPROG)                                     0.04      0.03     0.00     0.09 1.00     2833     5791\nsd(SRBodies_Intercept)                                  0.20      0.08     0.02     0.34 1.00     1123     1537\nsd(SRBodies_logOESTR)                                   0.02      0.01     0.00     0.05 1.00      676     2430\nsd(SRBodies_logPROG)                                    0.03      0.02     0.00     0.07 1.00     1976     5255\nsd(SRKissing_Intercept)                                 0.11      0.07     0.01     0.25 1.00     2373     4992\nsd(SRKissing_logOESTR)                                  0.02      0.01     0.00     0.05 1.00     1464     3148\nsd(SRKissing_logPROG)                                   0.02      0.02     0.00     0.06 1.00     4545     6123\nsd(SRIntercourse_Intercept)                             0.14      0.08     0.01     0.28 1.00     2539     4014\nsd(SRIntercourse_logOESTR)                              0.02      0.01     0.00     0.04 1.00     2537     5787\nsd(SRIntercourse_logPROG)                               0.02      0.02     0.00     0.06 1.00     4235     5040\ncor(SRFaces_Intercept,SRFaces_logOESTR)                -0.06      0.28    -0.60     0.49 1.00     3019     6296\ncor(SRFaces_Intercept,SRFaces_logPROG)                 -0.03      0.28    -0.55     0.50 1.00    11293     8423\ncor(SRFaces_logOESTR,SRFaces_logPROG)                  -0.01      0.27    -0.53     0.51 1.00    12835     8356\ncor(SRFaces_Intercept,SRBodies_Intercept)               0.09      0.27    -0.46     0.56 1.00     2221     4411\ncor(SRFaces_logOESTR,SRBodies_Intercept)                0.10      0.25    -0.42     0.55 1.00     2766     5243\ncor(SRFaces_logPROG,SRBodies_Intercept)                 0.10      0.27    -0.45     0.60 1.00     2287     4660\ncor(SRFaces_Intercept,SRBodies_logOESTR)                0.04      0.27    -0.50     0.55 1.00     5202     7342\ncor(SRFaces_logOESTR,SRBodies_logOESTR)                 0.06      0.27    -0.49     0.55 1.00     5287     6875\ncor(SRFaces_logPROG,SRBodies_logOESTR)                  0.06      0.27    -0.49     0.58 1.00     3829     6984\ncor(SRBodies_Intercept,SRBodies_logOESTR)              -0.04      0.28    -0.59     0.51 1.00     8507     6344\ncor(SRFaces_Intercept,SRBodies_logPROG)                -0.02      0.27    -0.55     0.50 1.00     8783     8879\ncor(SRFaces_logOESTR,SRBodies_logPROG)                 -0.04      0.27    -0.55     0.49 1.00     9136     9456\ncor(SRFaces_logPROG,SRBodies_logPROG)                  -0.02      0.28    -0.54     0.52 1.00     8549     9224\ncor(SRBodies_Intercept,SRBodies_logPROG)               -0.20      0.29    -0.69     0.41 1.00     3898     7763\ncor(SRBodies_logOESTR,SRBodies_logPROG)                -0.11      0.29    -0.63     0.46 1.00     5296     8147\ncor(SRFaces_Intercept,SRKissing_Intercept)              0.03      0.27    -0.50     0.55 1.00     7627     8351\ncor(SRFaces_logOESTR,SRKissing_Intercept)               0.04      0.27    -0.49     0.54 1.00     9729     8352\ncor(SRFaces_logPROG,SRKissing_Intercept)               -0.02      0.27    -0.54     0.51 1.00     7009     7496\ncor(SRBodies_Intercept,SRKissing_Intercept)             0.04      0.27    -0.49     0.54 1.00     8606     9138\ncor(SRBodies_logOESTR,SRKissing_Intercept)              0.04      0.27    -0.50     0.56 1.00     6706     9178\ncor(SRBodies_logPROG,SRKissing_Intercept)              -0.01      0.28    -0.55     0.53 1.00     7502     9014\ncor(SRFaces_Intercept,SRKissing_logOESTR)               0.03      0.26    -0.49     0.53 1.00     4404     7148\ncor(SRFaces_logOESTR,SRKissing_logOESTR)                0.02      0.26    -0.49     0.50 1.00     6463     7900\ncor(SRFaces_logPROG,SRKissing_logOESTR)                -0.04      0.28    -0.56     0.50 1.00     4373     7109\ncor(SRBodies_Intercept,SRKissing_logOESTR)              0.04      0.26    -0.47     0.53 1.00     7013     9063\ncor(SRBodies_logOESTR,SRKissing_logOESTR)               0.04      0.27    -0.49     0.55 1.00     5720     8204\ncor(SRBodies_logPROG,SRKissing_logOESTR)               -0.01      0.27    -0.54     0.51 1.00     5952     7872\ncor(SRKissing_Intercept,SRKissing_logOESTR)            -0.05      0.28    -0.58     0.50 1.00     6173     8371\ncor(SRFaces_Intercept,SRKissing_logPROG)                0.04      0.27    -0.49     0.55 1.00    12145     9111\ncor(SRFaces_logOESTR,SRKissing_logPROG)                 0.06      0.28    -0.48     0.58 1.00    13327     9312\ncor(SRFaces_logPROG,SRKissing_logPROG)                  0.02      0.27    -0.51     0.54 1.00    12235     9822\ncor(SRBodies_Intercept,SRKissing_logPROG)               0.02      0.27    -0.51     0.53 1.00    12509     9268\ncor(SRBodies_logOESTR,SRKissing_logPROG)                0.01      0.28    -0.52     0.54 1.00    10632     9904\ncor(SRBodies_logPROG,SRKissing_logPROG)                -0.04      0.28    -0.56     0.51 1.00     9590     9562\ncor(SRKissing_Intercept,SRKissing_logPROG)             -0.02      0.28    -0.56     0.53 1.00    10356    10061\ncor(SRKissing_logOESTR,SRKissing_logPROG)              -0.03      0.28    -0.56     0.51 1.00     9963     9191\ncor(SRFaces_Intercept,SRIntercourse_Intercept)         -0.07      0.27    -0.58     0.47 1.00     5145     7140\ncor(SRFaces_logOESTR,SRIntercourse_Intercept)          -0.08      0.26    -0.56     0.44 1.00     6862     8269\ncor(SRFaces_logPROG,SRIntercourse_Intercept)           -0.05      0.27    -0.56     0.50 1.00     5857     7855\ncor(SRBodies_Intercept,SRIntercourse_Intercept)        -0.09      0.26    -0.56     0.45 1.00     5792     5964\ncor(SRBodies_logOESTR,SRIntercourse_Intercept)         -0.06      0.27    -0.57     0.49 1.00     6194     8864\ncor(SRBodies_logPROG,SRIntercourse_Intercept)           0.07      0.28    -0.48     0.58 1.00     6205     8620\ncor(SRKissing_Intercept,SRIntercourse_Intercept)        0.09      0.28    -0.46     0.59 1.00     6045     9092\ncor(SRKissing_logOESTR,SRIntercourse_Intercept)         0.15      0.28    -0.42     0.65 1.00     5312     7865\ncor(SRKissing_logPROG,SRIntercourse_Intercept)         -0.00      0.27    -0.52     0.52 1.00     7463    10084\ncor(SRFaces_Intercept,SRIntercourse_logOESTR)          -0.02      0.27    -0.54     0.51 1.00     8691     8116\ncor(SRFaces_logOESTR,SRIntercourse_logOESTR)           -0.01      0.26    -0.51     0.50 1.00     9421     9011\ncor(SRFaces_logPROG,SRIntercourse_logOESTR)            -0.04      0.27    -0.55     0.50 1.00     7492     8835\ncor(SRBodies_Intercept,SRIntercourse_logOESTR)         -0.08      0.27    -0.58     0.47 1.00     7262     8595\ncor(SRBodies_logOESTR,SRIntercourse_logOESTR)          -0.06      0.27    -0.57     0.49 1.00     6478     8494\ncor(SRBodies_logPROG,SRIntercourse_logOESTR)            0.06      0.28    -0.49     0.57 1.00     7140     8383\ncor(SRKissing_Intercept,SRIntercourse_logOESTR)         0.07      0.28    -0.49     0.59 1.00     6995     9369\ncor(SRKissing_logOESTR,SRIntercourse_logOESTR)          0.11      0.28    -0.46     0.62 1.00     6502     9009\ncor(SRKissing_logPROG,SRIntercourse_logOESTR)          -0.00      0.28    -0.54     0.53 1.00     7081     9351\ncor(SRIntercourse_Intercept,SRIntercourse_logOESTR)    -0.06      0.28    -0.60     0.48 1.00     9499     9733\ncor(SRFaces_Intercept,SRIntercourse_logPROG)           -0.00      0.27    -0.53     0.52 1.00    14990     9485\ncor(SRFaces_logOESTR,SRIntercourse_logPROG)             0.01      0.27    -0.51     0.53 1.00    14252     9014\ncor(SRFaces_logPROG,SRIntercourse_logPROG)              0.00      0.28    -0.52     0.54 1.00    12405     8696\ncor(SRBodies_Intercept,SRIntercourse_logPROG)          -0.03      0.27    -0.56     0.50 1.00    13054     9155\ncor(SRBodies_logOESTR,SRIntercourse_logPROG)           -0.02      0.28    -0.55     0.52 1.00    10884     9401\ncor(SRBodies_logPROG,SRIntercourse_logPROG)             0.03      0.28    -0.52     0.56 1.00    10002     9051\ncor(SRKissing_Intercept,SRIntercourse_logPROG)          0.03      0.28    -0.51     0.55 1.00    10663    10129\ncor(SRKissing_logOESTR,SRIntercourse_logPROG)           0.04      0.28    -0.50     0.56 1.00    10282    10091\ncor(SRKissing_logPROG,SRIntercourse_logPROG)            0.03      0.28    -0.50     0.56 1.00     8733     9824\ncor(SRIntercourse_Intercept,SRIntercourse_logPROG)     -0.03      0.27    -0.54     0.50 1.00     9800    10886\ncor(SRIntercourse_logOESTR,SRIntercourse_logPROG)      -0.01      0.28    -0.54     0.53 1.00     8420    10232\n\nPopulation-Level Effects: \n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nSRFaces_Intercept          -0.04      0.24    -0.51     0.44 1.00     9371     9434\nSRBodies_Intercept         -0.79      0.15    -1.09    -0.49 1.00     9116     9399\nSRKissing_Intercept         0.10      0.19    -0.27     0.48 1.00     9851     9558\nSRIntercourse_Intercept     0.22      0.20    -0.17     0.60 1.00    10865     9431\nSRFaces_logOESTR           -0.01      0.04    -0.09     0.07 1.00    11608     9730\nSRFaces_logPROG            -0.02      0.02    -0.06     0.03 1.00    12397    10268\nSRFaces_cycleZ2            -0.15      0.09    -0.32     0.03 1.00     8394     9534\nSRBodies_logOESTR           0.02      0.02    -0.02     0.07 1.00    13214     9353\nSRBodies_logPROG           -0.03      0.01    -0.06    -0.00 1.00    12169     9525\nSRBodies_cycleZ2           -0.15      0.05    -0.25    -0.05 1.00     9394     9186\nSRKissing_logOESTR          0.07      0.03     0.01     0.13 1.00    11914    10016\nSRKissing_logPROG          -0.03      0.02    -0.06     0.00 1.00    11387     9710\nSRKissing_cycleZ2           0.05      0.05    -0.05     0.16 1.00    10076     9242\nSRIntercourse_logOESTR      0.10      0.03     0.03     0.16 1.00    10294     8333\nSRIntercourse_logPROG      -0.03      0.02    -0.07    -0.00 1.00    11949     9636\nSRIntercourse_cycleZ2       0.00      0.06    -0.10     0.12 1.00    11584     9844\n\nFamily Specific Parameters: \n                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma_SRFaces           0.60      0.02     0.55     0.64 1.00     6182     9029\nsigma_SRBodies          0.35      0.01     0.33     0.38 1.00     5629     8346\nsigma_SRKissing         0.46      0.02     0.43     0.50 1.00     6691     8625\nsigma_SRIntercourse     0.49      0.02     0.46     0.53 1.00     7790     8743\n\nResidual Correlations: \n                                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nrescor(SRFaces,SRBodies)            0.30      0.05     0.20     0.39 1.00     9539     9467\nrescor(SRFaces,SRKissing)           0.15      0.05     0.05     0.25 1.00     8908     8678\nrescor(SRBodies,SRKissing)          0.18      0.05     0.08     0.27 1.00     9600     9746\nrescor(SRFaces,SRIntercourse)       0.09      0.05    -0.01     0.19 1.00    10994     9227\nrescor(SRBodies,SRIntercourse)      0.14      0.05     0.04     0.24 1.00    10321     8966\nrescor(SRKissing,SRIntercourse)     0.48      0.04     0.40     0.55 1.00     8200     9036\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nShow code\n\nLOO(m1mv0, m1mv)\n\nOutput of model 'm1mv0':\n\nComputed from 12000 by 551 log-likelihood matrix\n\n         Estimate    SE\nelpd_loo  -1662.1  53.8\np_loo       432.1  19.4\nlooic      3324.1 107.6\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     431   78.2%   405       \n (0.5, 0.7]   (ok)       102   18.5%   116       \n   (0.7, 1]   (bad)       16    2.9%   31        \n   (1, Inf)   (very bad)   2    0.4%   9         \nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'm1mv':\n\nComputed from 12000 by 551 log-likelihood matrix\n\n         Estimate    SE\nelpd_loo  -1651.4  53.5\np_loo       509.6  21.8\nlooic      3302.8 107.0\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     325   59.0%   777       \n (0.5, 0.7]   (ok)       183   33.2%   204       \n   (0.7, 1]   (bad)       39    7.1%   31        \n   (1, Inf)   (very bad)   4    0.7%   13        \nSee help('pareto-k-diagnostic') for details.\n\nModel comparisons:\n      elpd_diff se_diff\nm1mv    0.0       0.0  \nm1mv0 -10.7       7.0  \n\nAs you can see if you expand the detail above, this doesn’t lead to very different conclusions.\nA location-scale model\nSo, on analogue rating scales, you often see substantially heterogeneous variances, this is the case here too. Will accounting for it in a simple location-scale model make a difference? From here on out, I’m going to simplify and only look at one outcome (SR_Intercourse) for now. I’ll also drop the varying slopes by cycle for simplicity.\n\n\nShow code\n\nsds <- cycles_long %>% select(ID, cycle_time, starts_with(\"SR_\")) %>% pivot_longer(-c(ID, cycle_time)) %>% \n  group_by(ID, name) %>% \n  summarise(sd = sd(value)) %>% \n  group_by(name)\n\n\nsds %>% \n  arrange(sd) %>% \n  ggplot(aes(sd)) + \n  geom_histogram() + \n  facet_wrap(~ name, scales = \"free\")\n\n\n\nFigure 2: Heterogenity in standard deviations by person.\n\n\n\n\nModel output\n\n\nShow code\n\nm1intercourse <- brm(SR_Intercourse ~ logOESTR + logPROG + cycle + (1 + logOESTR + logPROG|i|ID), cycles_long, \n            iter = 4000, file = \"m1intercourse\")\n\nm1intercourse_sigma <- brm(bf(SR_Intercourse ~ logOESTR + logPROG + cycle + (1 + logOESTR + logPROG|i|ID),\n                        sigma ~ (1|i|ID)), cycles_long, \n            iter = 6000, file = \"m1intercourse_sigma\", \n            # file_refit = \"always\",\n            control = list(adapt_delta = .99))\nm1intercourse_sigma\n\n Family: gaussian \n  Links: mu = identity; sigma = log \nFormula: SR_Intercourse ~ logOESTR + logPROG + cycle + (1 + logOESTR + logPROG | i | ID) \n         sigma ~ (1 | i | ID)\n   Data: cycles_long (Number of observations: 551) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 1;\n         total post-warmup draws = 12000\n\nGroup-Level Effects: \n~ID (Number of levels: 87) \n                               Estimate Est.Error l-95% CI u-95% CI\nsd(Intercept)                      0.79      0.17     0.46     1.15\nsd(logOESTR)                       0.08      0.04     0.01     0.17\nsd(logPROG)                        0.02      0.01     0.00     0.05\nsd(sigma_Intercept)                0.39      0.06     0.28     0.51\ncor(Intercept,logOESTR)           -0.19      0.39    -0.74     0.68\ncor(Intercept,logPROG)             0.22      0.41    -0.66     0.86\ncor(logOESTR,logPROG)             -0.07      0.44    -0.82     0.77\ncor(Intercept,sigma_Intercept)    -0.47      0.21    -0.85    -0.02\ncor(logOESTR,sigma_Intercept)      0.14      0.34    -0.57     0.74\ncor(logPROG,sigma_Intercept)      -0.23      0.42    -0.88     0.68\n                               Rhat Bulk_ESS Tail_ESS\nsd(Intercept)                  1.00     3690     4494\nsd(logOESTR)                   1.01      417     1162\nsd(logPROG)                    1.00     6321     7354\nsd(sigma_Intercept)            1.00     4169     7572\ncor(Intercept,logOESTR)        1.00     1096     3026\ncor(Intercept,logPROG)         1.00    13507     8678\ncor(logOESTR,logPROG)          1.00     9315     9202\ncor(Intercept,sigma_Intercept) 1.00     1293     2803\ncor(logOESTR,sigma_Intercept)  1.00     1043     1323\ncor(logPROG,sigma_Intercept)   1.01      637     2282\n\nPopulation-Level Effects: \n                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept           0.25      0.19    -0.12     0.62 1.00     9289\nsigma_Intercept    -0.81      0.06    -0.92    -0.70 1.00     5269\nlogOESTR            0.09      0.03     0.03     0.15 1.00     9304\nlogPROG            -0.03      0.02    -0.06    -0.00 1.00     9162\ncycleZ2             0.03      0.04    -0.05     0.11 1.00    17403\n                Tail_ESS\nIntercept           9697\nsigma_Intercept     8109\nlogOESTR            9188\nlogPROG             9117\ncycleZ2             9139\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nNot so!\nGroup mean centering\nSo, actually we expect the effects of estradiol and progesterone to happen on the within-person level. Differences in average levels of E and P could actually confound the relationship we’re interested in. Adjusting for this is possible using various methods (this video gives a great introduction.\nWe can simply subtract the group mean from logOESTR and logPROG.\n\nModel output\n\n\nShow code\n\ncycles_long <- cycles_long %>% group_by(ID) %>% \n              mutate(logOESTRm = mean(logOESTR, na.rm = T),\n                     logPROGm = mean(logPROG, na.rm = T)) %>% \n              mutate(logOESTR_gmc = logOESTR - mean(logOESTR, na.rm = T),\n                     logPROG_gmc = logPROG - mean(logPROG, na.rm = T)) %>% \n              ungroup()\ncycles_long %>% select(starts_with(\"log\")) %>% cor(use = \"pairwise\") %>% round(2)\n\n             logOESTR logPROG logOESTRm logPROGm logOESTR_gmc\nlogOESTR         1.00    0.36      0.39     0.11         0.92\nlogPROG          0.36    1.00      0.08     0.28         0.36\nlogOESTRm        0.39    0.08      1.00     0.28         0.00\nlogPROGm         0.11    0.28      0.28     1.00         0.00\nlogOESTR_gmc     0.92    0.36      0.00     0.00         1.00\nlogPROG_gmc      0.35    0.96      0.00     0.00         0.37\n             logPROG_gmc\nlogOESTR            0.35\nlogPROG             0.96\nlogOESTRm           0.00\nlogPROGm            0.00\nlogOESTR_gmc        0.37\nlogPROG_gmc         1.00\n\nShow code\n\nm1intercoursegmc <- brm(SR_Intercourse ~ logOESTR + logPROG + cycle + (1 + logOESTR + logPROG|i|ID), cycles_long %>% group_by(ID) %>% \n              mutate(logOESTR = logOESTR - mean(logOESTR, na.rm = T),\n                     logPROG = logPROG - mean(logPROG, na.rm = T)) %>% \n              ungroup(), \n            iter = 4000, file = \"m1intercoursegmc\")\nm1intercoursegmc\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: SR_Intercourse ~ logOESTR + logPROG + cycle + (1 + logOESTR + logPROG | i | ID) \n   Data: cycles_long %>% group_by(ID) %>% mutate(logOESTR = (Number of observations: 551) \n  Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 8000\n\nGroup-Level Effects: \n~ID (Number of levels: 87) \n                        Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(Intercept)               0.81      0.07     0.69     0.95 1.00\nsd(logOESTR)                0.07      0.04     0.00     0.17 1.00\nsd(logPROG)                 0.02      0.01     0.00     0.05 1.00\ncor(Intercept,logOESTR)     0.37      0.37    -0.53     0.92 1.00\ncor(Intercept,logPROG)      0.09      0.46    -0.82     0.87 1.00\ncor(logOESTR,logPROG)      -0.05      0.50    -0.88     0.87 1.00\n                        Bulk_ESS Tail_ESS\nsd(Intercept)               1728     3282\nsd(logOESTR)                2570     3237\nsd(logPROG)                 4973     4970\ncor(Intercept,logOESTR)     8913     5207\ncor(Intercept,logPROG)     12655     5410\ncor(logOESTR,logPROG)       8904     6668\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.74      0.09     0.56     0.92 1.00      945     2056\nlogOESTR      0.10      0.03     0.03     0.17 1.00    10853     6651\nlogPROG      -0.03      0.02    -0.07     0.00 1.00    11128     5939\ncycleZ2      -0.00      0.05    -0.09     0.09 1.00    12906     6139\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.51      0.02     0.48     0.54 1.00     8185     5933\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nWell, this makes little if any difference, which makes sense considering that there isn’t much between-subject variance in estradiol and progesterone to begin with.\nLatent group mean centering\nBeing a brms lover, I’ve been looking for an excuse to try Matti Vuorre’s implementation of latent group mean centering in brms. So, here goes.\n\nModel output\n\n\nShow code\n\nlatent_formula <- bf(\n  SR_Intercourse ~ intercept + \n    blogOESTR*(logOESTR - logOESTRlm) # lm = latent mean\n  +  blogPROG*(logPROG - logPROGlm),\n  intercept ~ 1 + (1 | ID),\n  blogOESTR ~ 1 + (1 | ID),\n  blogPROG ~ 1 + (1 | ID),\n  nlf(logOESTRlm ~ logOESTRm), # latent mean estimated from observed mean\n  logOESTRm ~ 1 + (1 | ID), # observed mean estimated as a function of (1|ID)\n  nlf(logPROGlm ~ logPROGm),\n  logPROGm ~ 1 + (1 | ID),\n  nl = TRUE\n) +\n  gaussian()\n\np <- get_prior(latent_formula, data = cycles_long) %>%\n  mutate(\n    prior = case_when(\n      class == \"b\" & coef == \"Intercept\" ~ \"normal(0, 1)\",\n      class == \"sd\" & coef == \"Intercept\" ~ \"student_t(7, 0, 1)\",\n      TRUE ~ prior\n    )\n  )\n\nfit_latent <- brm(\n  latent_formula,\n  data = cycles_long,\n  prior = p,\n  iter = 4000,\n  cores = 8, chains = 4, threads = 2,\n  backend = \"cmdstanr\",\n  control = list(adapt_delta = 0.99),\n  file = \"brm-fit-latent-mean-centered\"\n)\n\nfit_latent\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: SR_Intercourse ~ intercept + blogOESTR * (logOESTR - logOESTRlm) + blogPROG * (logPROG - logPROGlm) \n         intercept ~ 1 + (1 | ID)\n         blogOESTR ~ 1 + (1 | ID)\n         blogPROG ~ 1 + (1 | ID)\n         logOESTRlm ~ logOESTRm\n         logOESTRm ~ 1 + (1 | ID)\n         logPROGlm ~ logPROGm\n         logPROGm ~ 1 + (1 | ID)\n   Data: cycles_long (Number of observations: 551) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~ID (Number of levels: 87) \n                        Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(intercept_Intercept)     0.58      0.20     0.08     0.86 1.02\nsd(blogOESTR_Intercept)     0.08      0.04     0.01     0.14 1.01\nsd(blogPROG_Intercept)      0.02      0.01     0.00     0.06 1.00\nsd(logOESTRm_Intercept)     0.96      0.96     0.03     3.68 1.01\nsd(logPROGm_Intercept)      0.93      0.80     0.04     3.01 1.00\n                        Bulk_ESS Tail_ESS\nsd(intercept_Intercept)      124      171\nsd(blogOESTR_Intercept)      130      367\nsd(blogPROG_Intercept)      2458     2972\nsd(logOESTRm_Intercept)      370      174\nsd(logPROGm_Intercept)      3051     2357\n\nPopulation-Level Effects: \n                    Estimate Est.Error l-95% CI u-95% CI Rhat\nintercept_Intercept     0.26      0.25    -0.25     0.75 1.01\nblogOESTR_Intercept     0.09      0.04     0.01     0.16 1.01\nblogPROG_Intercept     -0.03      0.02    -0.07     0.00 1.00\nlogOESTRm_Intercept    -0.03      1.00    -1.96     1.95 1.00\nlogPROGm_Intercept     -0.02      1.00    -1.94     1.98 1.00\n                    Bulk_ESS Tail_ESS\nintercept_Intercept      562      287\nblogOESTR_Intercept      587      323\nblogPROG_Intercept      2351     2624\nlogOESTRm_Intercept     1671     2151\nlogPROGm_Intercept      5971     3201\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.51      0.02     0.48     0.54 1.00     4646     2892\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nImputations and lag\nTo get at the question, whether estradiol and progesterone have time-delayed effects on sexual desire, we would ideally like to have measured serum steroids a few days ahead. Unfortunately, this wasn’t done here (they did measure serum steroids on some other days, but did not share those data).\nA simple solution would be to substitute in my imputed hormones for the days two days prior to the rating task.\n\nModel output\n\n\nShow code\n\nm1_lagi <- brm(SR_Intercourse ~ est_estradiol_fc_lag2 + est_progesterone_fc_lag2 + cycle + (1 + est_estradiol_fc_lag2 + est_progesterone_fc_lag2|i|ID), cycles_longer, \n            iter = 6000, file = \"m1mv_lagi\",\n            control = list(adapt_delta = 0.99))\nm1_lagi\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: SR_Intercourse ~ est_estradiol_fc_lag2 + est_progesterone_fc_lag2 + cycle + (1 + est_estradiol_fc_lag2 + est_progesterone_fc_lag2 | i | ID) \n   Data: cycles_longer (Number of observations: 570) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 1;\n         total post-warmup draws = 12000\n\nGroup-Level Effects: \n~ID (Number of levels: 88) \n                                                    Estimate\nsd(Intercept)                                           0.72\nsd(est_estradiol_fc_lag2)                               0.17\nsd(est_progesterone_fc_lag2)                            0.03\ncor(Intercept,est_estradiol_fc_lag2)                   -0.26\ncor(Intercept,est_progesterone_fc_lag2)                -0.11\ncor(est_estradiol_fc_lag2,est_progesterone_fc_lag2)     0.10\n                                                    Est.Error\nsd(Intercept)                                            0.34\nsd(est_estradiol_fc_lag2)                                0.07\nsd(est_progesterone_fc_lag2)                             0.02\ncor(Intercept,est_estradiol_fc_lag2)                     0.47\ncor(Intercept,est_progesterone_fc_lag2)                  0.49\ncor(est_estradiol_fc_lag2,est_progesterone_fc_lag2)      0.47\n                                                    l-95% CI u-95% CI\nsd(Intercept)                                           0.10     1.40\nsd(est_estradiol_fc_lag2)                               0.05     0.32\nsd(est_progesterone_fc_lag2)                            0.00     0.09\ncor(Intercept,est_estradiol_fc_lag2)                   -0.85     0.79\ncor(Intercept,est_progesterone_fc_lag2)                -0.89     0.84\ncor(est_estradiol_fc_lag2,est_progesterone_fc_lag2)    -0.79     0.89\n                                                    Rhat Bulk_ESS\nsd(Intercept)                                       1.00     1663\nsd(est_estradiol_fc_lag2)                           1.02      651\nsd(est_progesterone_fc_lag2)                        1.00     1404\ncor(Intercept,est_estradiol_fc_lag2)                1.01      711\ncor(Intercept,est_progesterone_fc_lag2)             1.00     4776\ncor(est_estradiol_fc_lag2,est_progesterone_fc_lag2) 1.00     5148\n                                                    Tail_ESS\nsd(Intercept)                                           3732\nsd(est_estradiol_fc_lag2)                               1688\nsd(est_progesterone_fc_lag2)                            2613\ncor(Intercept,est_estradiol_fc_lag2)                    2065\ncor(Intercept,est_progesterone_fc_lag2)                 7047\ncor(est_estradiol_fc_lag2,est_progesterone_fc_lag2)     7309\n\nPopulation-Level Effects: \n                         Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept                    0.38      0.22    -0.03     0.82 1.00\nest_estradiol_fc_lag2        0.17      0.05     0.06     0.27 1.00\nest_progesterone_fc_lag2    -0.05      0.02    -0.10    -0.01 1.00\ncycleZ2                     -0.03      0.05    -0.12     0.07 1.00\n                         Bulk_ESS Tail_ESS\nIntercept                   19032     9683\nest_estradiol_fc_lag2       14482    10340\nest_progesterone_fc_lag2    18940     8961\ncycleZ2                     25540     7844\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.51      0.02     0.47     0.54 1.00     4467     7815\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nShow code\n\nm1_i <- brm(SR_Intercourse ~ est_estradiol_fc + est_progesterone_fc + cycle + (1 + est_estradiol_fc + est_progesterone_fc|i|ID), cycles_longer, \n            iter = 6000, file = \"m1_i\",\n            control = list(adapt_delta = 0.9))\nm1_i\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: SR_Intercourse ~ est_estradiol_fc + est_progesterone_fc + cycle + (1 + est_estradiol_fc + est_progesterone_fc | i | ID) \n   Data: cycles_longer (Number of observations: 570) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 1;\n         total post-warmup draws = 12000\n\nGroup-Level Effects: \n~ID (Number of levels: 88) \n                                          Estimate Est.Error l-95% CI\nsd(Intercept)                                 0.61      0.30     0.06\nsd(est_estradiol_fc)                          0.13      0.07     0.01\nsd(est_progesterone_fc)                       0.04      0.03     0.00\ncor(Intercept,est_estradiol_fc)              -0.13      0.48    -0.85\ncor(Intercept,est_progesterone_fc)           -0.10      0.48    -0.87\ncor(est_estradiol_fc,est_progesterone_fc)     0.16      0.46    -0.74\n                                          u-95% CI Rhat Bulk_ESS\nsd(Intercept)                                 1.28 1.00     1653\nsd(est_estradiol_fc)                          0.27 1.00      812\nsd(est_progesterone_fc)                       0.11 1.00     1392\ncor(Intercept,est_estradiol_fc)               0.83 1.00     1217\ncor(Intercept,est_progesterone_fc)            0.84 1.00     3423\ncor(est_estradiol_fc,est_progesterone_fc)     0.91 1.00     3410\n                                          Tail_ESS\nsd(Intercept)                                 1468\nsd(est_estradiol_fc)                          1813\nsd(est_progesterone_fc)                       3218\ncor(Intercept,est_estradiol_fc)               1719\ncor(Intercept,est_progesterone_fc)            5540\ncor(est_estradiol_fc,est_progesterone_fc)     5403\n\nPopulation-Level Effects: \n                    Estimate Est.Error l-95% CI u-95% CI Rhat\nIntercept               0.15      0.23    -0.30     0.59 1.00\nest_estradiol_fc        0.20      0.06     0.08     0.31 1.00\nest_progesterone_fc    -0.04      0.02    -0.08     0.01 1.00\ncycleZ2                -0.03      0.05    -0.12     0.06 1.00\n                    Bulk_ESS Tail_ESS\nIntercept              14741     9070\nest_estradiol_fc       10393     4474\nest_progesterone_fc    10516     2249\ncycleZ2                18084     8375\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.51      0.02     0.48     0.55 1.00     5034     2081\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nDirectionally, the same-day imputed hormones has a slightly stronger relationship with SR_Intercourse for oestradiol, and the two-day lag imputation has a slightly stronger relationship with progesterone. Not much that can be concluded at this sample size though.\nLatent lag\nJust using the imputations leaves money on the table though. Next, I thought I would use the strong relationship between imputed hormones and measured hormones to impute the missing values two days prior (and thereby carry forward the inherent uncertainty in imputation plus the individual differences, what little there are).\nI thought I needed only to use the syntactic sugar for missing variables in brms (mi()). After some reshaping magic, I thought I had it, but, nope, it took forever to fit2. And I’ve never seen that many warnings from a Stan model before. I did not succeed in fixing them with the usual tricks (more informative priors, inits, playing with control parameters).\nEdit: Sleeping on it, the solution came to me in a dream.3. That solution did not completely fix the model either though. What did it was rereading the brms vignette on missing values and noticing that Paul adds the | mi() also for the main response. This is necessary so brms won’t drop the rows in which the response is missing. I think you can get away with not doing so, if there is overlap, but in my case there was zero overlap (all values that had an outcome did not have lagged steroid measures). So, I added | mi() to by response SR_Intercourse.\n\nModel output\n\n\nShow code\n\nmis_imp_formula = bf(SR_Intercourse | mi() ~ mi(logOESTR_lag2) + mi(logPROG_lag2) + cycle + (1|ID)) +\n  bf(logOESTR_lag2 | mi() ~ est_estradiol_fc_lag2 + (1|ID)) +\n  bf(logPROG_lag2 | mi() ~ est_progesterone_fc_lag2 + (1|ID)) +\n    set_rescor(FALSE)\n\np <- get_prior(mis_imp_formula, data = cycles_longer) %>%\n  mutate(\n    prior = case_when(\n      class == \"b\" & coef == \"Intercept\" ~ \"normal(0, 2)\",\n      class == \"b\"  ~ \"normal(0, 1)\",\n      class == \"sd\" & coef == \"Intercept\" ~ \"student_t(3, 0, 0.5)\",\n      TRUE ~ prior\n    )\n  )\n\n\nm1lag <- brm(\n  mis_imp_formula,\n  cycles_longer, \n  iter = 4000, \n  init = 0,\n  file = \"m1_impute_latent\",\n  control = list(adapt_delta = 0.99, max_treedepth = 15),\n  prior = p\n  )\n\n\nInstead, I took a leaf out of Matti Vuorre’s book and tried my hand at the nonlinear formula syntax. I find this much less convenient to specify and harder to think about4.\nIt worries me that the results of the latent lag model are more like the results of the imputations without lag than of those with lag. So maybe I didn’t specify the nonlinear model correctly.\nEdit: I slept on it and I did not, so I’ve cut it here. You can see it on Github if you wish.\nBringing it all together\n\n\nShow code\n\ndraws <- bind_rows(\n  latent_impute_lag2 = m1lag %>% gather_draws(`bsp_SRIntercourse_milog.+`, regex = T) %>% mutate(.variable = str_replace(str_replace(.variable, \"bsp_SRIntercourse_mi\", \"b_\"), \"_lag2\", \"\")),\n  imputed_lag2 = m1_lagi %>% gather_draws(`b_est.+`, regex = T) %>% mutate(.variable = str_replace(str_replace(.variable, \"est_estradiol_fc_lag2\", \"logOESTR\"), \"est_progesterone_fc_lag2\", \"logPROG\")),\n  imputed = m1_i %>% gather_draws(`b_est.+`, regex = T) %>% mutate(.variable = str_replace(str_replace(.variable, \"est_estradiol_fc\", \"logOESTR\"), \"est_progesterone_fc\", \"logPROG\")),\n  latent_group_mean_centered = fit_latent %>% gather_draws(`b_blog.+`, regex = T) %>% mutate(.variable = str_replace(str_replace(.variable, \"b_b\", \"b_\"), \"_Intercept\", \"\")),\n  group_mean_centered = m1intercoursegmc %>% gather_draws(`b_log.+`, regex = T),\n  location_scale = m1intercourse_sigma %>% gather_draws(`b_log.+`, regex = T),\n  multivariate = m1mv %>% gather_draws(`b_SRIntercourse_log.+`, regex = T) %>% mutate(.variable = str_replace(.variable, \"b_SRIntercourse_\", \"b_\")),\n  raw = m1intercourse %>% gather_draws(`b_log.+`, regex = T), .id = \"model\") %>%   mutate(model = fct_inorder(factor(model)))\ndraws <- draws %>% group_by(model, .variable) %>% \n  mean_hdci(.width = c(.95, .99)) %>% \n  ungroup()\n\nggplot(draws, aes(y = .variable, x = .value, xmin = .lower, xmax = .upper,\n                  color = model)) +\n  geom_pointinterval(position = position_dodge(width = .4)) +\n  geom_vline(xintercept = 0, linetype = 'dashed') +\n  scale_color_discrete(breaks = rev(levels(draws$model))) +\n  theme_bw() +\n  theme(legend.position = c(0.99,0.99),\n        legend.justification = c(1,1))\n\n\n\nFigure 3: Non-varying slopes for log estradiol and log progesterone\n\n\n\n“Conclusion”\nIn summary, I would say my different analyses did not yield very different conclusions at this sample size. If the authors had shared even more data, maybe slightly cooler reanalyses would be possible. Who knows maybe that twofold change in the effect size for estradiol when bringing in imputations and lags is real.\nI ended up not bothering to bring it all together in one model, but would be interested to see what happens if you, dear reader, give it a go. Given the rest of the literature, I still put stock in a peri-ovulatory sexual desire peak, but I think this is more evidence that we all should design studies to detect small effects (here and most elsewhere in psychology) and effect heterogeneity (especially here).\nCycle researchers have recently started sharing data more widely. It’s cool to see this catch on even in medicine and I hope it continues.5 I think there are interesting substantive and statistical questions both remaining to be answered in this research.\nThings I didn’t do or that still confuse me\nI didn’t do any model comparisons here.\nI never brought it all together in one multivariate location-scale model with imputations and lags\nI didn’t do any group mean centering at the level of the cycle.\nIt confuses me that the results of the latent lag model are more like the results of the imputations without lag than of those with lag.\n\ntheir previous publications on different outcomes in the same study unfortunately didn’t do so↩︎\nwhich, according to the first folk theorem of statistical computing, means there’s something wrong with my model↩︎\nI had confused which imputations to use as predictors and should have used the lagged ones.↩︎\nIf I wanted to be mean, I’d say it feels a little like MPlus with those very strict rules about how variables and parameters can be named.↩︎\nIt would be extra cool if preregistration catches on there outside the narrow remit of clinical trials too.↩︎\n",
    "preview": "https://ars.els-cdn.com/content/image/1-s2.0-S0306453023000380-gr1.jpg",
    "last_modified": "2023-02-24T12:25:36+01:00",
    "input_file": "reanalysis-sexual-attraction-to-visual-sexual-stimuli-in-association-with-steroid-hormones-across-menstrual-cycles-and-fertility-treatment.knit.md"
  },
  {
    "path": "posts/2022-10-20-opportunity-equality-and-genetics-session-2/",
    "title": "Opportunity, equality, and genetics, seminar session 2",
    "description": "Notes on my seminar (German title \"Chancen, Gleichheit und Genetik\") oriented around K. Paige Harden's book \"The Genetic Lottery\" (2021).",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2022-10-20",
    "categories": [
      "teaching",
      "opportunity-equality-genetics"
    ],
    "contents": "\n\nContents\nHow to discuss\nComprehension questions\nQuiz\nPreview\n\nSession 2 is still mainly input from me, with some discussion. We talk about how to have discussions on the controversial topics of the book, I respond to comprehension questions about the chapter, show them the results of their quiz.\nHow to discuss\nI put up a few principles up for discussion (assume good faith, avoid overloaded words, stay friendly, watch how much you’re speaking). Then, we play a game, a confirmation bias exercise. Last year, I learned that most of them knew the 2-4-6 Wason sequences game (where people ask in a confirmatory way and grow overconfident about the rule), so this year, I modified it a little (letters instead of numbers, more complex rule). They shout possible 5-letter-words and I tell them whether they fit the rule or not. I got the desired result (overconfidence about the rule after confirmatory questions), though my game was maybe a little overengineered.\nI use this game as a jumping off point for talking about human (ir)rationality. I tell them that some of the “biases, fallacies, priming, nudging” work hasn’t survived the replication crisis and that some of the newer work on fake news, filter bubbles, the post-truth age, the backfire effect also is full of holes. Still, confirmation bias is very replicable, as the exercise just showed. I namecheck Mercier & Sperber’s argumentative theory of reasoning as one compelling explanation.\nI then show them a graph of their political leanings from the anonymous quiz, which in Leipzig reliably shows that they lean left. I argue that to sharpen our arguments, we need some friction, otherwise we’re at risk of confirmation bias and ending up with weak arguments for predetermined conclusions. If we want sharp arguments that will survive a debate with someone further away on the political spectrum, we need to do better.\nHow? I planned to tell them about how the role of “advocatus diaboli” can help us keep this in check, as it did for the Catholic church, who ended up with an excess of saints and miracles after doing away with their advocatus diaboli. Unfortunately, that stylized fact doesn’t quite hold up to scrutiny (see tweet thread below). So, instead I told them about my journey of discovering that it’s more complicated, after of course seeking initially merely to confirm rather than disprove the story I heard. I guess it works on a meta level?\n\n\nA story I've heard repeated (e.g. in Zenko's book \"Red Team\"): when the Cath church got rid of devil's advocates, the number of saints rose sharply.Problem: I tried to find a quantitative treatment, but found only news items.Self-made graph from Wikipedia's list of blesseds 1/n pic.twitter.com/LQJGAxIyxU\n\n— Ruben C. Arslan (@rubenarslan) October 18, 2022\n\nAs part of this, I remind them that I want to be criticized as well, and that I have set up a way for them to contact me anonymously.\nThis part is a bit long. I don’t know if I need all of it, but the discussions last year were pretty healthy and my tendency is to keep the spiel.\nComprehension questions\nIn this part, I try to answer to comprehension questions they raised as part of their responses to the quiz. For chapter 1, a lot of people always ask about what is basically “happiness” economics. Harden challenges the ‘classic’ Kahneman & Deaton 2010 study which purportedly found a limit after which more money (in income) is no longer associated with more happiness. First, they answer a small survey about the limit where they think happiness no longer increases (or whether they believe in a relationship at all). The modal result is usually something like 80,000€ a year, but this year it was more like 100,000€ a year. Inflation? :-)\nThen, I show them the graph from K&D and then graphs from the international replication by Jebb, Tai, Diener, & Oishi (2018). These both show some sort of flattening or even a peak of happiness (with log income on the X axis). In discussion, they come up with all sorts of reasons why that may be.\nI ask them whether it fits their impression that most people stop hustling after their first million. Then, I show them the following clip:\n\n\nThen, I show them Matthew Killingsworth (2021)1, who found no peak, no flattening, just a plain old loglinear relationship. I walk them through the result, the explanation for the previous results (ceiling effects, insensitive at high levels of positive affect). Then, I show them the graph with income not on a log scale and ask them what it implies for the effect of redistribution on average happiness.\nQuiz\nHere, I just pick some items that many got wrong and try to explain the correct answer with some recycled slides from my lecture. Because they all did their B.Sc. in a bunch of different places, the quantity and quality of their previous genetics lectures varies from “none” to “in depth knowledge of the virtues of the candidate gene paradigm” to “twin studies”. I don’t have the ambition to lay all the groundwork myself, because the book does it well, but of course it’s nice to add some graphs and other illustrative examples.\nPreview\nTo anticipate the next chapter, I close with a video of a Galton board/bean machine plus a picture of a lognormal variant (since we just talked about income). Then, some pictures of basketballers and a scatterplot of height for MZ/DZ twins, because Harden will go on to talk about Shawn Bradley, a very tall basketballer who has been genotyped.\n\nso jealous of this name for a man with this research topic↩︎\n",
    "preview": "https://pbs.twimg.com/media/FfVg9isWIAAGV-Z?format=png&name=medium",
    "last_modified": "2022-10-20T22:34:14+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-10-19-opportunity-equality-and-genes-a-seminar/",
    "title": "Opportunity, equality, and genes, a seminar on The Genetic Lottery",
    "description": "Notes on my seminar (German title \"Chancen, Gleichheit und Genetik\") oriented around K. Paige Harden's book \"The Genetic Lottery\" (2021).",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2022-10-19",
    "categories": [
      "teaching",
      "opportunity-equality-genetics"
    ],
    "contents": "\n\nContents\nThe course\nStudent’s tasks\nReadings\nQuizzes and questionnaires\nUsual schedule\n\nFirst session\n\nLast autumn, I decided, on impulse, to base a Master’s level seminar in personality psychology around Paige Harden’s book The Genetic Lottery. I had only recently obtained a review copy, but I already thought it could be good material for a discussion-oriented seminar based on the many reviews which disagreed with the book and each other. Also, I had enjoyed much of Harden’s writing on her (now-defunct?) blog.\n\n\n\nFigure 1: Book Cover\n\n\n\nIn my opinion and according to the student evaluations, the seminar was a success. Some colleagues asked me about my syllabus, but I didn’t have anything in English. This year, I thought I’d try to keep notes on this blog. Maybe it’ll be helpful to others considering this/a similar format. Or to me, next year.\nThe course\nThe course is open to Master’s level psychology students, though one particularly bright B.Sc. student attended last year too. It’s a 2.5 hour session with a break in the middle.\nStudent’s tasks\nread the book and some additional material, mandatory weekly quiz, not graded\ngive a 10 minute talk on background literature (a paper cited in the book or a paper that could have been cited in the book, I will probably keep replacing papers with newer ones given the rapid developments in genetics), not graded\nsubmit questions for three additional papers\nwrite an essay based on the discussion in the seminar (usually for the topic of the talk, but can differ), graded\nReadings\nThe students read one chapter from the book per week. I added one session with a chapter on sex and gender from Kevin Mitchell’s book Innate, because Harden skips this topic entirely.1\nI also added three videos from Matt McGue’s Coursera course (on eugenics, the John-Joan twins/David Reimer, & PKU) because he can add a bit of history that neither me or Harden lived through. Then, I have them read two blog posts by Scott Siskind on 5-HTTLPR (post cited in the book) and on ADHD (because it makes some discussion-worthy points about equality of opportunity/medically compensating for disadvantages when it comes to a normally distributed trait).\nQuizzes and questionnaires\nAfter the first session, I have them fill out a questionnaire which contains some items from studies discussed in the book\nthe LEGIT questionnaire (estimate h2 for various traits)\nattitude questions (on genes, luck, egalitarianism, their connections)\none question on political leaning left-right\nestimation questions about child mortality and extreme poverty\na brief quiz on genetics so they can self-assess how much they know\nThen, for each session, there’s a brief quiz for them to check their comprehension of the book (and my notes in the margin). In the same quiz, they can submit comprehension questions to me.\nUsual schedule\n13:15-13:20 Organisational matters and short impulse from me\n13:20-13:40 Comprehension questions about the chapter\n13:40-13:50 Impulse talk 1\n13:50-14:00 Discussion, questions 1\n14:00-14:20 Break\n14:20-14:30 Impulse talk 2\n14:30-14:40 Discussion, questions 2\n14:40-15:00 Discussion in small groups\n15:00-15:25 Joint discussion\n15:25-15:35 Teaser/preview next week from me\n15:35 End/assigned tasks for next week\nFirst session\nIn the first session, I introduce the author, the authors of the other readings, talk a little about eugenics and “this debate” in the German context (the book is quite US-centric). I talk about why I think it’s an apt course in the personality module. Then, I introduce the impulse talk papers and have them pick favorites via simpleassign.com.\nI end with this video. Harden cites the study from which it’s derived (Brosnan & de Waal, 2003) in her first chapter:\n\nEven monkeys have a sense of fairness. If two capuchin monkeys are “paid” in cucumber slices for performing a simple task, they will both happily pull levers and munch on their cucumber snacks. Start paying just one monkey in grapes, however, and watch the other monkey throw the cucumber back in the experimenter’s face with the indignation of Jesus flipping the tables of the moneychangers.\n\nI ask the students to think about whether this video shows a sense of fairness or even “inequity aversion” in academese. This time, one noted that you could just call it “jealousy”. After all, the grape-ionnaire monkey is not indignant at all. Once we reach this point, I show a slide with tweets by several primatologists.\n\n\nCute videos are mind viruses that produce \"zombie ideas\" (i.e. ideas that just won't die, no matter how many times you kill them). https://t.co/CAEcOk2uFL\n\n— Claudio Tennie (@CTennie) November 20, 2019\n\n\n\nProblems with the logic of the paradigm:https://t.co/JaetGhAcOaFailed replications (review): https://t.co/m79JvgFtigFailed replication and alternative explanation for effect (example): https://t.co/s34WqpKZMrand another (chimps): https://t.co/kq1osGrjCP\n\n— Prof Nichola Raihani (@nicholaraihani) November 22, 2019\n\nIn short, many primatologists hate this video and study. There are conceptual issues.2 There are design issues.3 It doesn’t replicate.4 It fits Jeremy Freese’s immortal words “more vampirical than empirical, unable to be killed by mere evidence”.\nNow, this study is no cornerstone in Harden’s book. She concludes the section as follows.\n\nAs human adults, we share with our children and our primate cousins an evolved psychology that is instinctively outraged by unfairness. Right now, such outrage is bubbling all around us, threatening to boil over at any moment. In 2019, the three richest billionaires in the US possessed more wealth than the poorest 50 percent of the country. Like capuchin monkeys being paid in cucumbers when their neighbor is being paid in grapes, many of us look at the inequalities in our society and think: “This is unfair.”\n\nSo, it’d be interesting if a sense of fairness is so basic, so widespread, fundamental. But of course, if capuchin monkeys and children don’t share our moral views (and they don’t on things like dominance hierarchies and violence), we don’t have to change our moral views.5.\nI use this teaser to say: Even Paige Harden6 gets things wrong and to turn this into more than reading a pop science book, we need to do read critically and do our own research.\n\nEven though it fits in perfectly in my opinion given that biological sex is randomly assigned, genetic, and we have lots of work unpacking the problem that identifying a causal effect doesn’t mean we understand the mechanism, or that a gene having a causal effect implies only biological processes). I presume she simply had her fill of explosive topics, but in my experience I can use SRY to build intuitions about other genes↩︎\nIs it inequity aversion if the better-paid doesn’t care?↩︎\nMonkeys switched from a model to an observer role, this seems to have induced the frustration.↩︎\nAfter correcting the design mistake↩︎\nOr we shouldn’t I guess. The kind of men who go for the alpha male world view rarely reference alpha male capuchin monkeys as their model for some reason. Too cute probably.↩︎\nwho I’ve previously built up as pretty cool↩︎\n",
    "preview": "https://pup-assets.imgix.net/onix/images/9780691190808.jpg?w=1500&auto=format",
    "last_modified": "2022-10-20T00:22:10+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-09-23-hibar-effects-of-acetaminophen-on-risk-taking/",
    "title": "HIBAR: Effects of acetaminophen on risk taking (with virtual balloons)",
    "description": "Had I Been A Reviewer.",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2020-09-23",
    "categories": [
      "HIBAR",
      "re-analysis",
      "risk taking"
    ],
    "contents": "\n\n\n\nFigure 1: An analogue of the Balloon Analogue Risk Task (BART). From the Internet Archive Book Images\n\n\n\nUpdate March 4, 2021\nI exchanged a few emails with Baldwin Way. After two responses, he stopped replying.\nHe did not make the “preregistration” public, after I repeatedly explained the problem (and why adding me as a contributor was not a real solution).\nHe gave an explanation why the sample sizes deviated from plans (logistic reasons with subject recruitment) and explicitly denied optional stopping.\nHe said that they have updated their IRB to be able to share data in the future.\nHe said that this study was a result of emptying their file drawer on acetaminophen and risk preference (apparently, they consider the study on ibuprofen and risk preference to belong in a different file drawer).\nSeveral of my concerns below are not allayed by his responses, and I’m further concerned that Way does not seem motivated to fix unambiguous errors (non-public preregistration that was not frozen, deviation from preregistered analysis) or respond to a critic. His final sentence to me was that I should try running acetaminophen studies myself, but given the presented evidence, I currently feel like this would be a waste of time.\nOriginal post\nA journalist is calling me later today to talk about this recently published paper, so I read it.\nAlthough I have a research interest in risk taking, I had not read the recent flurry of papers that link acetaminophen (paracetamol/Tylenol) to various psychological outcomes.\n\n\n\nFigure 2: The many risks of balloonery. From Punch in the Internet Archive Book Images\n\n\n\nHere’s the abstract of the paper:\n\nAcetaminophen, an analgesic and antipyretic available over-the-counter and used in over 600 medicines, is one of the most consumed drugs in the USA. Recent research has suggested that acetaminophen’s effects extend to the blunting of negative as well as positive affect. Because affect is a determinant of risk perception and risk taking, we tested the hypothesis that acute acetaminophen consumption (1000 mg) could influence these important judgments and decisions. In three double-blind, placebo-controlled studies, healthy young adults completed a laboratory measure of risk taking (Balloon Analog Risk Task) and in Studies 1 and 2 completed self-report measures of risk perception. Across all studies (total n = 545), acetaminophen increased risk-taking behavior. On the more affectively stimulating risk perception measure used in Study 2, acetaminophen reduced self-reported perceived risk and this reduction statistically mediated increased risk-taking behavior. These results indicate that acetaminophen can increase risk taking, which may be due to reductions in risk perceptions, particularly those that are highly affect laden.\n\nWell, because of my own research and studies like Frey et al. 2017, I have my doubts that changes on the BART will generalize to changes in real world risk taking. I think it’s a somewhat silly task, where the optimal behaviour is to inflate several balloons 64/128 times (unlike real balloons, the balloon has a 1/128 chance of bursting at the first press, which goes to 100% chance of bursting at the 128th press). In the study, they played this task for “imaginary money”, which they “lost” when the balloon burst, so high scores mainly mean people pressed a button a lot of times. Unsurprisingly, people rarely “pump” (press a button) the optimal number of times, perhaps because it is boring to do so. Ironically, the BART is in wide use, because it is supposed to measure the affectively-laden side of risk taking (rather than supposedly even more boring lotteries). To be honest, I would not bet money that the BART even predicts how much air people put in a real balloon, let alone bigger life choices.\nThey also look at self-reported perceptions of risk on the DOSPERT and in a inventory by Finucane, finding mixed results.\nBut before asking whether the results will generalize to real world behavior, I should first try to judge whether the results are even likely to replicate.\n\n\n\nFigure 3: The many risks of balloonery, part 2. From the Internet Archive\n\n\n\nAn initial overview doesn’t inspire confidence:\nThe two significant p values for the BART are on the uncanny mountain (BART S1: 0.023, S2: 0.033, S3: 0.84, Combined: 0.024). Such p values should be rare, but they are common in this study.\nOnly one study, Study 1, was preregistered. Studies 2 and 3 were not, even though they were highly similar.\nThe preregistration link on OSF for Study 1 is not accessible.\nSeveral other outcomes (Columbia Card Sorting, Iowa Gambling, etc.) are mentioned in the text, but “will be reported separately”.\nThe data are not public, even though they are not sensitive and can easily be anonymized (the authors did not obtain the necessary consent).\nThere are multiple outcomes and multiple hypotheses relating to these outcomes (pertaining to mean differences and correlations), but no accounting for multiple testing.\nThe DOSPERT outcome is present and significantly different in S2 (P = 0.002). Study 3 “replicates and extends” Study 2, but the DOSPERT is not reported.\nSeveral apparent mediators (emotional experience during the BART) that did not show significant differences were relegated to the supplement.\nI emailed the last author, Baldwin Way, to get access to the preregistration, which he granted (the link still isn’t public).\nAs it turns out:\nThe preregistration wasn’t formally registered with OSF (i.e. the version was not frozen). This is not an uncommon error, but we can look at file timestamps.\nThe date the preregistration was uploaded (2015-01-26) was after the study’s start date (according to BW: Study 1 was run between Jan 15th and April 17th 2015). Normally, when we say a study was preregistered, we mean pre data collection, not during.\nThe preregistered sample size, 120, is lower than the final S1 sample size (140, after exclusions). Of course, that raises the spectre of optional stopping, i.e., that the authors consciously or unconsciously made the data collection’s end contingent on the significance of the results. The authors write that they aimed for 200 participants in both S2 and S3 based on S1’s results. In this context, it is interesting that the sample size for S3 (the nonsignificant result) exceeded 200 (214 after exclusions) and the sample size for S2 (barely significant) fell short of it (188 after exclusions).\nThey preregistered that they would examine whether the correlation between risk and benefit perception in their inventories would change as a function of acetaminophen usage. To test this, they tested for moderator effect in a linear regression. This is not the same thing as testing for a difference in correlations, see this explainer.\nI emailed the last author some questions to ask for explanations of some of these deviations.\nDoing some further digging, I found that the first author’s master’s thesis reports a third study that tested whether these effects extended to ibuprofen (but not the study 2 reported here).\nTo my mind, the empirical evidence isn’t very strong and it’s unfortunate that the authors’ studies left open several researcher degrees of freedom, making it hard to take their p values at face value.\nI don’t know if this study is characteristic of the broader literature (see here for a critical take), but I think if I avoid paracetamol in the future, the liver damage will weigh heavier on my mind than the supposed psychological effects.\nIf someone wants to do further research on this, especially with undergraduates, I’d recommend asking them whether they drank the night before or are in other pain. We would not want to claim that paracetamol affects real world risk taking, when it really just affects whether we’re willing to hear a loud bang while hungover.\nFurther reading:\nHere’s a critical commentary on another acetaminophen study by Jonathon McPhetres: https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00705/full\nThe authors rebut some, but not the most damning criticisms, namely that the sample was small, the evidence weak and the study not preregistered: https://www.frontiersin.org/articles/10.3389/fpsyg.2020.02099/full\n\n\n\n",
    "preview": "posts/2020-09-23-hibar-effects-of-acetaminophen-on-risk-taking/pole_balloon.png",
    "last_modified": "2021-03-04T14:37:19+01:00",
    "input_file": {},
    "preview_width": 525,
    "preview_height": 391
  },
  {
    "path": "posts/2020-06-23-mis-allocated-scrutiny-in-science-a-quick-simulation/",
    "title": "Mis-allocated scrutiny: a quick simulation",
    "description": "Below I document my simulation code underlying an upcoming blog post at The 100% CI.",
    "author": [],
    "date": "2020-06-23",
    "categories": [
      "meta science",
      "reproducibility",
      "mistakes",
      "quick job"
    ],
    "contents": "\nYou can read the blog post about mis-allocated scrutiny at the 100% CI. This is just where I document the R code for my stupid little simulation.\n\n\n# load packages\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\n\nParameters\n\n\nn_papers <- 10000\nn_journals <- 15\nn_revisions <- 3\nsubmission_limit <- 10\n\nSpawn papers and journals\n\n\n\nset.seed(1610)\njournals <- tibble(\n  journal = 1:n_journals,\n  threshold = rnorm(n_journals, sd = 1.8),\n  fame = threshold + 0.3 * rnorm(n_journals),\n  submitted = 0,\n  accepted = 0,\n  reviewer_count = case_when(\n    fame > 2 ~ 5,\n    fame > 1 ~ 4,\n    fame > 0 ~ 3,\n    fame > -1 ~ 2,\n    TRUE ~ 1\n  )\n) %>% arrange(desc(fame)) %>%\n  mutate(journal = 1:n_journals) %>% \n  as.data.frame()\n\npapers <- tibble(\n  paper = 1:n_papers,\n  fitness = rnorm(n_papers, sd = 1.5),\n  reviews = 0,\n  revisions = 0,\n  submissions = 0,\n  submission_sequence = \"\",\n  published = FALSE,\n  journal = NA_real_,\n  first_choice = NA_real_,\n  authors_own_assessment = NA_real_,\n  editors_assessment = NA_real_,\n  most_recent_assessment = NA_real_\n) %>% \n  as.data.frame()\n\nkable(table(journals$reviewer_count), \n      caption = \"How many journals recruit how many reviewers on average?\")\n\nTable 1: How many journals recruit how many reviewers on average?\n\n\nVar1\n\n\nFreq\n\n\n1\n\n\n2\n\n\n2\n\n\n4\n\n\n3\n\n\n3\n\n\n4\n\n\n3\n\n\n5\n\n\n3\n\n\ndecisions <- tibble(\n  did_not_submit = 0,\n  desk_rejection = 0,\n  reject_after_reviews = 0,\n  revise_and_resubmit = 0,\n  accepted = 0\n) %>% \n  as.data.frame()\n\n\nget_reviews <- function(fitness, n = 1) {\n  error <- 1/(sqrt(1+n))\n  sqrt((1 - error)) * fitness + (sqrt(error)) * rnorm(length(fitness))\n}\n\nMain simulation loop\n\n\n# library(profvis)\n# profvis({\nfor(p in 1:n_papers) {\n  papers[p, \"authors_own_assessment\"] <- 1 + get_reviews(papers[p, \"fitness\"], 1)\n  # submission loop\n  for(j in 1:n_journals) {\n    if(papers[p, \"authors_own_assessment\"] <\n       (journals[j, \"fame\"] - 1.8)) {\n      decisions$did_not_submit = decisions$did_not_submit + 1\n      # WOULD NOT EVEN SUBMIT\n    } else {\n      # SUBMIT\n      papers[p, \"submissions\"] <- papers[p, \"submissions\"] + 1\n      papers[p, \"submission_sequence\"] <- paste0(\n        papers[p, \"submission_sequence\"], j, \", \")\n      journals[j, \"submitted\"] = journals[j, \"submitted\"] + 1\n      if(is.na(papers[p, \"first_choice\"])) {\n        papers[p, \"first_choice\"] <- j\n      }\n\n      # EDITOR REVIEWS\n      papers[p, \"editors_assessment\"] <- get_reviews(papers[p, \"fitness\"], 1)\n      papers[p, \"reviews\"] <- papers[p, \"reviews\"] + 1\n\n      if(papers[p, \"editors_assessment\"] <\n         (journals[j, \"threshold\"] - 1.5)) {\n        # DECISION: DESK REJECTION\n        decisions$desk_rejection = decisions$desk_rejection + 1\n        papers[p, \"fitness\"] <- papers[p, \"fitness\"] + \n          0.05/papers[p, \"submissions\"]\n        papers[p, \"revisions\"] <- papers[p, \"revisions\"] + 1\n      } else {\n        # SENT FOR REVIEW\n        # revision loop\n        for(r in 1:n_revisions) {\n          papers[p, \"most_recent_assessment\"] <-\n            get_reviews(papers[p, \"fitness\"], journals[j, \"reviewer_count\"])\n\n          if(papers[p, \"most_recent_assessment\"] <\n                    (journals[j, \"threshold\"] - 0.5)) {\n            # DECISION: REJECT AFTER REVIEWS\n            decisions$reject_after_reviews = decisions$reject_after_reviews + 1\n            papers[p, \"reviews\"] <- papers[p, \"reviews\"] + journals[j, \"reviewer_count\"]\n            papers[p, \"revisions\"] <- papers[p, \"revisions\"] + 1\n            # diminishing returns\n            papers[p, \"fitness\"] <- papers[p, \"fitness\"] + \n              0.1/papers[p, \"submissions\"]\n            break\n          } else if(papers[p, \"most_recent_assessment\"] <\n                    (journals[j, \"threshold\"])) {\n            # DECISION: MAJOR REVISION/R&R\n            decisions$revise_and_resubmit = decisions$revise_and_resubmit + 1\n            papers[p, \"reviews\"] <- papers[p, \"reviews\"] + journals[j, \"reviewer_count\"]\n            papers[p, \"revisions\"] <- papers[p, \"revisions\"] + 1\n            papers[p, \"fitness\"] <- papers[p, \"fitness\"] + \n              0.3/papers[p, \"submissions\"]\n          } else if(papers[p, \"most_recent_assessment\"] >=\n             journals[j, \"threshold\"]) {\n            # DECISION: ACCEPTED/MINOR REVISION\n            decisions$accepted = decisions$accepted + 1\n            papers[p, \"reviews\"] <- papers[p, \"reviews\"] + journals[j, \"reviewer_count\"]\n            papers[p, \"published\"] <- TRUE\n            journals[j, \"accepted\"] = journals[j, \"accepted\"] + 1\n            papers[p, \"journal\"] <- journals[j, \"journal\"]\n            break # acceptance\n          }\n        } # end revision loop\n      }\n    }\n    if (papers[p, \"published\"]) {\n      break # done\n    } else if (papers[p, \"submissions\"] >= submission_limit) {\n      break # give up\n    }\n  } # end journal loop\n} # end paper loop\n# })\n\nInspect results\n\n\n\ntheme_set(theme_minimal())\noptions(digits = 2)\nkable(decisions, \n      caption = \"How common are certain editorial decisions?\")\n\nTable 2: How common are certain editorial decisions?\n\n\ndid_not_submit\n\n\ndesk_rejection\n\n\nreject_after_reviews\n\n\nrevise_and_resubmit\n\n\naccepted\n\n\n17244\n\n\n31843\n\n\n26577\n\n\n7195\n\n\n8729\n\n\nkable(table(papers$submissions), \n      caption = \"How often do papers get submitted?\")\n\nTable 2: How often do papers get submitted?\n\n\nVar1\n\n\nFreq\n\n\n1\n\n\n230\n\n\n2\n\n\n288\n\n\n3\n\n\n695\n\n\n4\n\n\n715\n\n\n5\n\n\n1642\n\n\n6\n\n\n887\n\n\n7\n\n\n1408\n\n\n8\n\n\n887\n\n\n9\n\n\n1261\n\n\n10\n\n\n1987\n\n\nkable(table(papers$published, exclude=NULL), \n      caption = \"How many do not end up published, i.e. authors give up after 8 tries?\")\n\nTable 2: How many do not end up published, i.e. authors give up after 8 tries?\n\n\nVar1\n\n\nFreq\n\n\nFALSE\n\n\n1271\n\n\nTRUE\n\n\n8729\n\n\npapers_in_journals <- papers %>% left_join(journals)\npapers_in_journals %>% select(fitness, fame, submissions, reviews) %>% \n  cor(use = 'pairwise') %>% round(2) %>% \n  kable(caption = \"How do paper fitness, journal fame, paper's number of submissions and paper's accumulated number of reviews intercorrelate?\")\n\nTable 2: How do paper fitness, journal fame, paper’s number of submissions and paper’s accumulated number of reviews intercorrelate?\n\n\n\n\nfitness\n\n\nfame\n\n\nsubmissions\n\n\nreviews\n\n\nfitness\n\n\n1.00\n\n\n0.89\n\n\n-0.58\n\n\n0.02\n\n\nfame\n\n\n0.89\n\n\n1.00\n\n\n-0.59\n\n\n-0.17\n\n\nsubmissions\n\n\n-0.58\n\n\n-0.59\n\n\n1.00\n\n\n0.55\n\n\nreviews\n\n\n0.02\n\n\n-0.17\n\n\n0.55\n\n\n1.00\n\n\nggplot(papers_in_journals, aes(journal, reviews)) +\n  geom_jitter(alpha = 0.2) +\n  geom_pointrange(stat = 'summary', color = \"blue\") +\n  ggtitle(\"Mis-allocated scrutiny\", subtitle = \"Simulated data\") +\n  xlab(\"Journal rank\") +\n  ylab(\"Accumulated reviews\")\n\n\njournals %>% mutate(acceptance_rate = round(accepted/submitted,2)) %>% \n  kable(caption = \"How many papers are submitted to each journal and how many are accepted?\",\n        digits = 1)\n\nTable 2: How many papers are submitted to each journal and how many are accepted?\n\n\njournal\n\n\nthreshold\n\n\nfame\n\n\nsubmitted\n\n\naccepted\n\n\nreviewer_count\n\n\nacceptance_rate\n\n\n1\n\n\n2.9\n\n\n2.8\n\n\n4891\n\n\n132\n\n\n5\n\n\n0.0\n\n\n2\n\n\n2.8\n\n\n2.7\n\n\n5358\n\n\n112\n\n\n5\n\n\n0.0\n\n\n3\n\n\n2.2\n\n\n2.1\n\n\n7112\n\n\n407\n\n\n5\n\n\n0.1\n\n\n4\n\n\n2.0\n\n\n1.6\n\n\n7856\n\n\n329\n\n\n4\n\n\n0.0\n\n\n5\n\n\n1.2\n\n\n1.5\n\n\n7651\n\n\n1459\n\n\n4\n\n\n0.2\n\n\n6\n\n\n1.4\n\n\n1.2\n\n\n6723\n\n\n377\n\n\n4\n\n\n0.1\n\n\n7\n\n\n0.8\n\n\n0.9\n\n\n6704\n\n\n1117\n\n\n3\n\n\n0.2\n\n\n8\n\n\n0.8\n\n\n0.7\n\n\n5681\n\n\n600\n\n\n3\n\n\n0.1\n\n\n9\n\n\n0.1\n\n\n0.4\n\n\n5260\n\n\n1620\n\n\n3\n\n\n0.3\n\n\n10\n\n\n0.4\n\n\n-0.1\n\n\n3772\n\n\n512\n\n\n2\n\n\n0.1\n\n\n11\n\n\n0.3\n\n\n-0.2\n\n\n2653\n\n\n309\n\n\n2\n\n\n0.1\n\n\n12\n\n\n-0.5\n\n\n-0.3\n\n\n2205\n\n\n835\n\n\n2\n\n\n0.4\n\n\n13\n\n\n-0.9\n\n\n-0.6\n\n\n1067\n\n\n426\n\n\n2\n\n\n0.4\n\n\n14\n\n\n-2.6\n\n\n-2.1\n\n\n498\n\n\n474\n\n\n1\n\n\n0.9\n\n\n15\n\n\n-2.2\n\n\n-2.2\n\n\n23\n\n\n20\n\n\n1\n\n\n0.9\n\n\n\n\n",
    "preview": "posts/2020-06-23-mis-allocated-scrutiny-in-science-a-quick-simulation/mis-allocated-scrutiny-in-science-a-quick-simulation_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2020-06-24T16:37:58+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2019-09-03-hibar-sexdifferentiated-changes-in-sexual-desire-predict-marital-dissatisfaction/",
    "title": "HIBAR: Sex‑Differentiated Changes in Sexual Desire Predict Marital Dissatisfaction",
    "description": "Had I Been a Reviewer. Actually, I was a reviewer. Huh! So, how did this turn out?",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2019-09-03",
    "categories": [
      "HIBAR",
      "post-publication review",
      "sexual desire",
      "marriage",
      "relationships"
    ],
    "contents": "\nMcNulty, Maxwell, Meltzer, & Baumeister make use of two cohorts of newlyweds to find out whether discrepancies in sexual desire contribute to reducing marital satisfaction. The study is based on the same data as McNulty et al. 2016 and tries to answer a very similar question. The only difference is that here we are looking at sexual desire (which was measured less often) rather than sexual satisfaction and frequency as the predictor, and there’s an added consideration of childbirth and stress as mediating factors. I reviewed a previous version of this manuscript at another journal, so this blog post is an edited version of that review minus the points the authors addressed1.\nIn all, I think the results are plausible and the data are rich, but I wanted to think through some important limitations of their data (some of them discussed at length, some less so) to figure out how I think about the results.\n\nThe Authors’ Abstract\n\nSex is critical to marriage. Yet, there are several reasons to expect spouses to experience declines in the desire for sex over time, and the rates of any declines in sexual desire may differ for men and women. We used two multi-wave, longitudinal studies to test whether male and female members of newlywed couples experienced different rates of change in sexual desire, whether any such changes were accentuated by childbirth, and whether any such changes had implications for marital satisfaction. In both studies, spouses provided multiple reports of sexual desire, marital satisfaction, and childbirth. Results demonstrated that women’s sexual desire declined more steeply over time than did men’s sexual desire, which did not decline on average. Further, childbirth accentuated this sex difference by partially, though not completely, accounting for declines in women’s sexual desire but not men’s. Finally, declines in women’s but not men’s sexual desire predicted declines in both partners’ marital satisfaction. These effects held controlling depressive symptoms and stress, including stress from parenthood. The current findings offer novel longitudinal evidence for sex-differentiated changes in sexual desire and therefore suggest an important source of marital discord.\nThe three key limitations:\n\n\n\nFigure 1: A closer look. From the Internet Archive Book Images\n\n\n\nData start at marriage. At this point most relationship will have been going on for a (variable) while.\nNo data on hormones (age trends, menstrual cycle change), hormonal contraception, pregnancy, and breast feeding.\nSystematic attrition. Given that the goal of the study is to predict marital dissatisfaction, and that it followed newlyweds for 4.5 years, it baffles me that the authors do not discuss what happened to marriages that ended in divorce and how that relates to dropout (which was substantial).\nRelationships don’t start with marriage anymore\nOne key limitation is not addressed by design. Many couples never marry, and most couples don’t marry right after meeting. We may be looking at a very heterogeneous group here with respect to relationship duration. Why is that important? For example, couples who marry after having been together for longer may be more likely to have children. We would then spuriously conclude effects of childbirth that are in reality driven by pre-existing differences in relationship duration. The authors did not share data on relationship duration preceding marriage. Their data on newlyweds are obviously valuable, but for answering the specific research question posed, I’d hazard starting with unmarried couples would give us clearer answers.\nHormones\n\n\n\nFigure 2: Mother and Baby. From the book Woman in Girlhood, Wifehood, Motherhood in the Internet Archive Book Images\n\n\n\nAt the end, the authors say that hormonal fluctuations may be proximal mechanisms by which desire changes.\nYet, they do not discuss menstrual cycles, hormonal contraception, pregnancy and breastfeeding. All of these entail hormonal changes. Let’s think this through: If newlywed women are more likely to be already pregnant at the first timepoint, changes in sexual desire after birth might rather reflect a shift from pregnancy back to breastfeeding and/or regularly ovulating or hormonal contraception.2\nHormonal contraception causes small decreases in sexual desire on average. If newlywed women are more likely to have gone off the pill, they may temporarily have higher sexual desire in the first wave, and then decrease again after a return to hormonal contraception after birth.\nMore mechanistically, given that we found that women experiences peaks in sexual desire before ovulation, it may have been more likely that women were asssessed around ovulation during the first wave and less likely after childbirth (given that both breastfeeding and combined hormonal contraceptives can suppress ovulation).\n\n\n\nFigure 3: What comes before childbirth? From the book Woman in Girlhood, Wifehood, Motherhood in the Internet Archive Book Images\n\n\n\nFinally, with the age range of their sample, I don’t think anyone entered menopause during the study period, but I still would have liked to see their analyses adjusted for age.\nAre the effects reported by the authors small enough to be fully explained by these slightly roundabout explanations? In standard deviations, the effect is approximately a decrease of 0.18 across both studies, if I understood their table correctly. I don’t know how many women change their contraceptive method after marriage in their sample, nor do they report when and how many couples had children, so there are a lot of unknowns here.\nCombined with the problem that relationships don’t start at marriage, I do wonder if we were really shown evidence of a linear decline in sexual desire or whether we just started following couples right after a small uptick in sexual desire after the honeymoon (for hormonal and many other plausible reasons). I think getting this right makes a real difference to the counseling of couples.\nSystematic attrition\nI don’t really know what the right approach would be here, but certainly the authors should have mentioned how they dealt with missing data (FIML? Listwise deletion?) and I don’t think adjusting for the number of waves does much good. Presumably, dissatisfied couples are more likely to drop out, because they divorce or separate, so a censored model could be appropriate for the marital dissatisfaction analyses. In all, I think these problems could lead to an underestimation of effects, but I could be wrong about this because I don’t know the details of the model the authors fit.\nOverinterpretation\nIn all, the conclusions were tempered a lot between the version I saw and this one; in fact, I feel like I can see the signature of certain well-known reviewers in the limitations section. But these two slipped through:\n\nquality close relationships are a significant source of mental and physical health\n\nThis is an unsupported causal claim. The correlation may well be due to reverse causation or unobserved third variables. It would have be supported by something stronger than meta-analyses of correlations (e.g., propensity score matching). I’d add that divorce does not imply that people will necessarily end up lonely; they may end up happier. There’s still friends, new partners, or remarriage. To make the claim you’re trying to make, it would be more apt to cite negative consequences of divorce for well-being and mortality, rather than show positive correlates of marriage and assume that those whose marriages end will be alone.\n\ndesire for sex dwindles among newly married women but not men\n\nGiven the small effect size, the word “dwindles” is misleading.\nReproducibility\nGiven that the last two papers I did HIBARs on provided open data and one provided open analysis scripts, I have to point out that I really felt the lack of reproducibility for this paper. The data is not open and there is no syntax for the quite complex models. To my mind, this makes issues with things like missing data handling much more pressing, because I and others cannot easily re-analyse the data.\nThere is still at least one inconsistent p value in here (as identified by Statcheck.io), even after I recommended Statcheck in my review. I could not reproduce the authors measure of within-subject variability (presumably because I could not figure out how they went about it), although I could reproduce the directional result using my own approach.\nThere is no codebook for the two studies, so I have to rely on various descriptions of the data strewn across multiple papers to find out what they did and did not measure.\nThey report Cronbach’s α, but no retest reliabilities, nor reliabilities of change3; both of which of would be relevant to the question of whether they had adequate power. My admonition that they needed to provide more detail for their power analysis (e.g., predicted effect sizes) for it to make sense was apparently dealt with by omitting the power analysis entirely.\nFigure 1 just shows simple means with standard errors. A spaghetti plot (showing trajectories for all couples) or a smoothed spline over time superimposed on raw data would have done justice to the data.\n\nFurther, given the birth of children is consistently linked to marital satisfaction, a potential confound, we controlled marital satisfaction in these analyses as a time-varying covariate.\n\nMarital satisfaction is not just a potential confound, it’s also a potential outcome of lower sexual desire. Adjusting for it is hence not straightforward in a timeseries with long lags like this. I would like to see the results without this adjustment.\nThe authors use the infamous terms “marginally significant” and “trended toward significance”. As many others have pointed out, p values aren’t Geiger counters that tell you when you’re approaching the truth.\nConclusion\n\n\n\nFigure 4: This book on Girlhood, Wifehood, Motherhood seems a tad outdated, but at least it has sections on courtship before marriage, menstruation, ovulation, and menopause (and the benefits of bathing).\n\n\n\nWhile I found the paper interesting in general, I took less away from this than I could have. Of course, not everyone has a focus on hormones in their work, but given the limitations discussed above I cannot integrate their findings with what we already know about sexual desire and hormones. I hope future work revisits these issues.\n\nfor example, they pulled in the sexual frequency and satisfaction data here to link the two papers a bit more↩︎\nThe authors never discuss collecting information on whether women were pregnant when measured, although I assume they could back-calculate that from children’s birth dates (if those were collected) or approximately infer it depending on whether any children were born between waves (they definitely collected that).↩︎\nCronbach’s alpha is not a sufficient measure of reliability to report for longitudinal measures such as these. I recommend reporting multilevel generalizability (Shrout and Lane 2012), as implemented e.g. in the psych package by Revelle. Especially the coefficient reliability of change is interesting for the analyses reported. Also, simply reporting that coefficients were “more than .90” is too imprecise.↩︎\n",
    "preview": "posts/2019-09-03-hibar-sexdifferentiated-changes-in-sexual-desire-predict-marital-dissatisfaction/book_cover.png",
    "last_modified": "2021-03-05T12:50:29+01:00",
    "input_file": {},
    "preview_width": 673,
    "preview_height": 1019
  },
  {
    "path": "posts/2019-06-20-correction-to-arslan-et-al-2019-using-26000-diary-entries-to-show-ovulatory-changes-in-sexual-desire-and-behavior/",
    "title": "Correction to Arslan et al. (2019).",
    "description": "Some additional information on the correction notice for _Using 26,000 diary entries to show ovulatory changes in sexual desire and behavior_ that appeared today.",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2019-06-20",
    "categories": [
      "correction",
      "ovulation"
    ],
    "contents": "\nTable of Contents\nCorrectionFigure 1 and case numbers\neffsize package bug\nProgramming error for a moderator variable\n\nOther post-publication feedback (not part of the correction)Figure 5\nFollowing the preregistration\n\nConclusion\nWe (me, Katharina Schilling, Tanja M. Gerlach, & Lars Penke) recently published a diary study on ovulatory changes in the Journal of Personality and Social Psychology.\nUnfortunately, we made a few mistakes in reporting the study. The correction appeared today in JPSP. Because corrections have to be quite short, we will use this blog post to give a little more detail.\nAccording to our assessment, the mistakes, although annoying and preventable, changed nothing substantive. I have taken to adding automated testing to my data cleaning code and instituted a bug bounty policy to reduce the odds of such errors in my future work.1\nAfter expanding on the correction, we will also respond to some criticisms that we do not think are errors in our work, but differences in interpretation.\n\n\n\nFigure 1: Several bugs in our code. From the Internet Archive Book Images\n\n\n\nCorrection\nFigure 1 and case numbers\nWe regret the following errors and inconsistencies in our published paper. Between our initial submission and our revision, we had made a small adjustment to the code for our exclusion criteria and neglected to update Figure 1 and Table 3 (because we did not notice that we had a few more participants and days). This led us to report an incorrect, lower number of total participants (1043 instead of 1054) for the robustness checks. The number of days were also off by a few hundred, as well as various sample means. The substantive results (model coefficients etc.) were reported correctly and with correct case numbers (in the online supplement).\nThe preregistered work is unaffected by this error. A corrected Figure 1 also shows two exclusion criteria (hypothesis guessing and long interruptions of the diary) that were mentioned on the supplementary website, but missing from Figure 1. A corrected figure can be found here and in the updated article.\neffsize package bug\nWe reported inflated effect sizes for the Hedges’ g differences between hormonal contraceptive users and non-users in Table 1. After re-analysing data for the correction, we suddenly got different effect sizes. It turned out there was a bug in the effsize package for Hedges’ g computation that had been fixed in a newer version.\nIn all, we reported larger effect size differences between our naturally cycling group and our hormonal contraception quasi-control group; they were more comparable than Table 1 made them seem.\nProgramming error for a moderator variable\nI made a programming error when aggregating the variable “partner’s attractiveness relative to self”. Specifically, I accidentally sorted values because of a typo in the data.table syntax. This led to nonsense values (women’s values were jumbled). A reader who re-analysed our data found it, for which are grateful. Fixing this error led to the following changes:\n\n\n\nFigure 2: We needed some help to get this one. From the Internet Archive Book Images\n\n\n\nIn the preregistered analyses, the moderation of fertile window effects on extra-pair desire and behaviour was no longer non-significant in the opposite direction of the prediction, but non-significant in the predicted direction (p = 0.23).\nIn the robustness analyses, the predicted interaction was significant for extra-pair desire and behaviour (p = 0.00565) and partner mate retention (p = 0.0014).\nOur preregistered tests, following the literature at the time, had not permitted slopes for menstruation and the fertile window to vary by woman, even though fitting a cross-level moderation essentially stipulates that varying slopes must exist (an internal conceptual inconsistency).\nModels with varying slopes indeed fit better for all outcomes. We reported robustness checks with varying slopes for all main effects, but we had not done so for our moderators tests, because we found no evidence of moderation and the check would have only made the test more conservative. Given that correcting the error led to a nominally significant result, we also tested a model, allowing for slopes to vary. In this model, the predicted interaction was non-significant for extra-pair desire (p = 0.085). The predicted interaction for partner mate retention in the robustness check would have been significant (p = 0.0072) according to our threshold of .01 for the preregistered tests, but still potentially consistent with sampling error given that 24 moderator effects had been tested (four moderators, three outcomes, two subsamples) were tested for essentially one hypothesis.\nThis programming error, though severe, did not affect the preregistered results. In our robustness checks, the error led to some changes in nominal significance, but the overall pattern still cannot be seen as evidence for the predicted moderation pattern.\nOther post-publication feedback (not part of the correction)\nFigure 5\nDan Engber helpfully pointed out that the caption for Figure 5 could have been clearer. The figure was intended to show differences in patterns across the cycle. To this end, we standardised differences within variables and hormonal contraceptive status (“within-subject change” in the figure caption). This focuses the eye on the differences in changes for HC users and non-users. In Figure 3, we also showed the mean differences. An alternative version of Figure 5, including mean differences between HC users and non-users, can be found online.\n\n\n\nFigure 3: These aren’t true bugs, but still good to discuss. From the Internet Archive Book Images\n\n\n\nFollowing the preregistration\nWe were criticised for not following our preregistration to the letter. It was our intention to be faithful to the preregistration as much as possible and transparent about the deviations that we considered reasonable and necessary. We think we succeeded in doing so and that problems raised by the critic are mainly problems of explicitness and interpretation.\nIt was our first preregistration (in 2014), we had no models for how to preregister correlational work with many simultaenous (but not all related) hypothesis tests. It was also our first menstrual cycle study and my first repeated measures study. For this reason, we relied on expert opinion to design, for example, our exclusion criteria.\nThis process led to a few suboptimalities (still an incomplete list, I am sure):\nOur exclusion criteria were overly strict and would have led to excluding most of the women for no good reason (according to our effect size estimates, excluded women were not more likely to be anovulatory).\nWe preregistered the use of windowed fertility predictors, which throw away most of the informative variation in fertility and reduce the number of usable days.\nWe preregistered no strategy to deal with multiple testing, although we had multiple outcomes (some of which were highly correlated).\nWe preregistered several moderators that were all designed to test the same hypothesis, instead of the strongest possible specification.\nWe did not preregister how we would aggregate some of the more complex items in the data.\nWe preregistered a scale optimisation algorithm based on Cronbach’s alpha, which is not the best way to estimate reliability for multilevel data like ours\nWe think we transparently reported how we chose to deal with these problems. We did not make any decisions to arrive at foregone conclusions; instead, we think we had good reasons for non-arbitrary decisions.\nOperationalisation of hypothesis 2.2\nThe reader alerted us that our hypothesis _H.2.2. Moderation or shift hypotheses: The ovulatory increase in women’s extra-pair desires and reported male mate retention behavior is strongest (and the in-pair desire increase is weakest) for women who perceive their partners as low in sexual attractiveness relative to long-term partner attractiveness. could also be interpreted to mean a different statistical model than the one we fitted.\nWe interpreted it as meaning that women who have a partner who is high in long-term attractiveness but low in short-term attractiveness would show ovulatory increases in extra-pair desire, whereas all other women would not. Basically, women who have a partner who is a “provider” but does not have “good genes” would be interested in extra-pair men; other women would not be.\nWe saw this in contrast to the simpler model, which we also fit, with only short-term attractiveness as the moderator. The reader interpreted it as meaning that we should adjust for long-term attractiveness to remove a “positivity bias” and test only the interaction between the fertile window and short-term attractiveness. Previous work had sometimes tested such a model and sometimes a difference score.\nAlthough we reported them, we recommend not interpreting difference scores such as this (or the relative attractiveness variable above) in isolation, because they assume that women with partners who are attractive for both long- and short-term relationships behave the same way as women with partners who are not attractive for either long- or short-term relationships. We think this is not what the verbally specified theory predicts, but of course verbal specifications can be debated because they often leave some room for ambiguity.\nIn our preregistered analyses, none of these alternative specifications would have yielded a significant effect, except one significant result in the opposite direction for in-pair desire. However, in our robustness checks, the interaction for this alternative specification would have been significant (p = 0.006). Again, allowing for slopes to vary rendered this interaction nonsignificant at .01 (p = 0.045).\nOverall, as we had already stressed in our discussion, it would be premature to conclude an absence of moderation: confidence intervals were too wide to rule out potentially relevant effect sizes and patterns were often in the predicted form for extra-pair desire (but not for in-pair desire). But neither should these models, which were suggested after seeing the results for other models, be seen as evidence for moderation, given the number of tests performed. If a prediction from the literature is supported in preregistered tests, checks like ours can show robustness to relaxing or tightening assumptions. The evidence for the predicted moderators is clearly not robust in our data. More data is needed to reach adequate power for more informative tests of moderation patterns, and is indeed forthcoming. Maybe more importantly, theories need to be clearer, so that they can specify severe tests. We found this difficult to do at the time of planning the study.\nOperationalisation of preregistration regarding hormonal contraceptive users\nLastly, we did not preregister that we would use hormonal contraception (HC) users as a quasi-control group for the naturally cycling group. Consistent with this, our preregistered tests compared fertile window changes with zero, not with the baseline change for HC users. However, we reported the latter comparison as well, in the preregistered analysis section. We mainly did this to show that despite the fact that we only had an ad-hoc strategy to deal with multiple testing, we never found an ovulatory change among hormonal contraceptive users (for whom ovulation is suppressed). We thought reporting the quasi-control group was one way to show that our ad-hoc strategy was effective.\nWe hope these additional tests, which were in fact always consistent with our preregistered tests, did not lead to confusion regarding our preregistration. The choice of additionally presenting these analyses did not affect our conclusions and was not made conditional on the results.\nConclusion\nWe are glad the paper led to animated post-publication discussion and are grateful to all who pointed out errors or ways the paper could be improved. We will implement the suggestions and lessons when publishing the results from the second, larger cycle study we conducted after this one.\nIn all, the conclusions of our paper remain the same, although quite a few numbers changed a little. The replicability of the ovulatory change literature still seems decidedly mixed. Our work was not (and was never meant to be) the last word on moderators of cycle changes.\nI also stopped using data.table in favour of dplyr which has a more explicit syntax.↩\n",
    "preview": "https://live.staticflickr.com/3862/14751616975_c06d479338_o_d.jpg",
    "last_modified": "2020-06-06T06:58:54+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-06-19-tympanic-temperature-and-social-connectedness/",
    "title": "HIBAR: Tympanic temperature and social connectedness",
    "description": "Re-examining a reported association between physical temperature and social connectedness.",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2019-06-19",
    "categories": [
      "HIBAR",
      "re-analysis",
      "temperature",
      "experience sampling"
    ],
    "contents": "\nThere was recently a bit of a tussle in the literature about the question whether physical warmth prime social social warmth. A nonreplication of Williams & Bargh (2008) by Chabris, Heck, Mandart, Benjamin, & Simons (2018) did not support that holding a hot coffee cup would make people judge others as warmer, among other things. Bargh & Melnikoff (2018) responded and pointed out that the larger question about the connection between social and physical warmth no longer rested on their initial small study.\nAmong other studies, they cited the Human Penguin Project and a study by Inagaki & Human (2019) in which daily tympanic (in the ear) temperature readings where correlated with feelings of social connectedness in an experience sampling design.\n\n\n\nFigure 1: Human penguins? From the Internet Archive Book Images\n\n\n\nI decided to look the experience sampling study up, because I wanted to know how the authors had dealt with the well-known diurnal changes in body temperature and the circamensal rhythm, in which naturally cycling1 women experience increases in body temperature after ovulation.\nThe authors seemed to be aware of these issues (e.g., they excluded pregnant women and women who used hormonal birth control), but took a fairly strictly correlational approach to the data. The literature discussed was all about high temperatures increasing social warmth though. However, their design was used to remove between-person confounds (such as age and pregnancy), so they do seem to want to lay the groundwork for causal claims.\n\n\n\nFigure 2: Diurnal variation in temperature. From the Wikipedia\n\n\n\nThe authors analyses left me wishing for more though. I thought I could potentially exclude a confound of post-ovulatory change in temperatures by looking at within-day variation and that I could maybe adjust for time of day to rule out a common cause confounder of both temperature and feelings of connectedness. The authors simply wrote “there are no hypothesized effects related to time of day in the current study.”\nTo my great pleasure, I found the authors had uploaded a processed subset of their data to the Open Science Framework.\nAs far as I can tell from the also provided R source code, this is the final dataset used for analysis (I can reproduce their Table 1).\n\n\n\nThere are 6633 observations in the dataset from 212 people.\nThe authors had participants measure their temperature twice 3 minutes apart, but did not respond the correlation between the two measures. I graphed it.\n\n\n\nFigure 3: Two temperature readings from the right ear 3 minutes apart.\n\n\n\nThere were three surprising things about this graph for me.\nIt’s quite noisy (r=0.88)—as a psychologist myself I always kind of expect physiological measures to have better reliability (even though I know that need not be the case).\nIt is bunchy. Either the thermometers reported readings only to a tenth of a degree or people only reported tenths or the authors rounded the data. This seems like a low standard for accuracy for a scientific study (for comparison, women who measure basal body temperatures for contraception usually track hundredths of a degree).\nSome people had temperatures which should have made them too comatose to enter them in a survey. The minimum value recorded for the average was 30.05, the maximum was 38.85. The authors reported only excluding “Two participants with tympanic readings that were consistently outside the normotensive range and were therefore suspected to be ill were excluded from final analyses, leaving a final sample of 211 participants.”. However, their abstract says “in the nonfebrile range”. But 38.8 °C is in the febrile range. And 30 °C is not febrile, but should be excluded as an outlier because of likely measurement error/participant being a zombie.\nExclusions\nI restricted the range of the data to what Wikipedia calls normal range (36.5–37.5 °C) plus/minus 0.2 for a rough standard error in measurement for each measurement.\n\n\n\n740 measurements were excluded. The correlation changed a little (r=0.83).\n\n\n\nFigure 4: Restricted data. Two temperature readings from the right ear 3 minutes apart.\n\n\n\nI also wondered about the diurnal variation. The authors did not share time of day or time since waking, but they shared the number of the within-day assessment.\n\n\n\nFigure 5: Diurnal variation. Means + SEs.\n\n\n\nRe-analysis results\n\nMultilevel regression results\n\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: tempavg ~ (1 | ID) + (1 | ID:Day)\n   Data: temp\n\nREML criterion at convergence: 213.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.5004 -0.6159  0.0072  0.6322  3.7343 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID:Day   (Intercept) 0.005167 0.07188 \n ID       (Intercept) 0.030825 0.17557 \n Residual             0.050922 0.22566 \nNumber of obs: 5893, groups:  ID:Day, 1463; ID, 212\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)  36.9041     0.0126 208.2758    2928   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: connected ~ temp_b + temp_w + (1 | ID) + (1 | ID:Day)\n   Data: temp\n\nREML criterion at convergence: 17416.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-5.3529 -0.4451  0.0970  0.5186  4.3220 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID:Day   (Intercept) 0.1351   0.3676  \n ID       (Intercept) 0.9166   0.9574  \n Residual             0.9027   0.9501  \nNumber of obs: 5893, groups:  ID:Day, 1463; ID, 212\n\nFixed effects:\n              Estimate Std. Error         df t value Pr(>|t|)    \n(Intercept)   28.38771   13.60878  212.19305   2.086   0.0382 *  \ntemp_b        -0.62335    0.36876  212.17414  -1.690   0.0924 .  \ntemp_w         0.24957    0.05661 5665.95669   4.409 1.06e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n       (Intr) temp_b\ntemp_b -1.000       \ntemp_w  0.000  0.000\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: \nconnected ~ temp_b + temp_b_day + temp_w_day + (1 | ID) + (1 |  \n    ID:Day)\n   Data: temp\n\nREML criterion at convergence: 17418.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-5.3458 -0.4433  0.0959  0.5169  4.3173 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID:Day   (Intercept) 0.1354   0.3679  \n ID       (Intercept) 0.9165   0.9573  \n Residual             0.9025   0.9500  \nNumber of obs: 5893, groups:  ID:Day, 1463; ID, 212\n\nFixed effects:\n              Estimate Std. Error         df t value Pr(>|t|)    \n(Intercept)   28.38532   13.60835  212.21364   2.086   0.0382 *  \ntemp_b        -0.77081    0.38954  263.68655  -1.979   0.0489 *  \ntemp_b_day     0.14752    0.12547 1339.02065   1.176   0.2399    \ntemp_w_day     0.27567    0.06344 4458.60405   4.346 1.42e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n           (Intr) temp_b tmp_b_\ntemp_b     -0.947              \ntemp_b_day  0.000 -0.322       \ntemp_w_day  0.000  0.000  0.000\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: \nconnected ~ temp_b + temp_b_day + temp_w_day + factor(WithinDayAssessment) +  \n    (1 | ID) + (1 | ID:Day)\n   Data: temp\n\nREML criterion at convergence: 17426.5\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-5.4094 -0.4465  0.0991  0.5113  4.2991 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID:Day   (Intercept) 0.1349   0.3673  \n ID       (Intercept) 0.9168   0.9575  \n Residual             0.9022   0.9498  \nNumber of obs: 5893, groups:  ID:Day, 1463; ID, 212\n\nFixed effects:\n                               Estimate Std. Error         df t value\n(Intercept)                    28.21859   13.61064  212.17769   2.073\ntemp_b                         -0.76601    0.38959  263.59833  -1.966\ntemp_b_day                      0.14594    0.12541 1340.27676   1.164\ntemp_w_day                      0.25343    0.06430 4459.65903   3.941\nfactor(WithinDayAssessment)2    0.02306    0.03955 4706.24655   0.583\nfactor(WithinDayAssessment)3    0.06896    0.04001 4716.92339   1.724\nfactor(WithinDayAssessment)4    0.11034    0.04016 4718.30844   2.748\nfactor(WithinDayAssessment)5    0.04046    0.04084 4753.66239   0.991\nfactor(WithinDayAssessment)6   -0.05942    0.14702 5319.09589  -0.404\nfactor(WithinDayAssessment)7    0.01317    0.57594 5214.95864   0.023\nfactor(WithinDayAssessment)8   -0.92273    0.99542 5168.25697  -0.927\n                             Pr(>|t|)    \n(Intercept)                   0.03935 *  \ntemp_b                        0.05032 .  \ntemp_b_day                    0.24475    \ntemp_w_day                   8.23e-05 ***\nfactor(WithinDayAssessment)2  0.55988    \nfactor(WithinDayAssessment)3  0.08483 .  \nfactor(WithinDayAssessment)4  0.00602 ** \nfactor(WithinDayAssessment)5  0.32183    \nfactor(WithinDayAssessment)6  0.68609    \nfactor(WithinDayAssessment)7  0.98175    \nfactor(WithinDayAssessment)8  0.35399    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) temp_b tmp_b_ tmp_w_ f(WDA)2 f(WDA)3 f(WDA)4\ntemp_b      -0.947                                             \ntemp_b_day   0.000 -0.322                                      \ntemp_w_day   0.001 -0.001  0.001                               \nfctr(WtDA)2 -0.005  0.005 -0.004 -0.100                        \nfctr(WtDA)3 -0.004  0.002  0.000 -0.140  0.521                 \nfctr(WtDA)4 -0.006  0.005 -0.004 -0.115  0.516   0.516         \nfctr(WtDA)5 -0.002 -0.003  0.011 -0.030  0.499   0.497   0.494 \nfctr(WtDA)6 -0.002  0.005 -0.010 -0.017  0.141   0.141   0.142 \nfctr(WtDA)7  0.000 -0.003  0.008 -0.005  0.035   0.035   0.034 \nfctr(WtDA)8  0.000 -0.004  0.011 -0.013  0.021   0.022   0.019 \n            f(WDA)5 f(WDA)6 f(WDA)7\ntemp_b                             \ntemp_b_day                         \ntemp_w_day                         \nfctr(WtDA)2                        \nfctr(WtDA)3                        \nfctr(WtDA)4                        \nfctr(WtDA)5                        \nfctr(WtDA)6  0.139                 \nfctr(WtDA)7  0.034   0.032         \nfctr(WtDA)8  0.020   0.019   0.056 \n\nInterestingly, the effects actually get much stronger when excluding these measurements. Their within-person change score for temperature has an effect size of .13, after these exclusions, it’s .24. I also tried centering the temperature by day (to get a within-day change measure that should be independent of ovulatory change and other daily change), and the estimate was .27. I also adjusted for within-day assessment, this did not change the within-day temperature effect much.\nStill, a plot showed that the effect may still be driven by values which are more than 0.5 degrees away from the person mean. This stuff makes me worry about correlated measurement error.\n\n\n\nFigure 6: Values that are more than .5 degrees away from the person mean, drive the association.\n\n\n\nReplication\nI tried replicating the association with another, larger dataset that I have access to with daily basal body temperature. Results descriptively went in the opposite direction for outcomes like feeling sociable or supportive (non-sig. neg. effects of within-person temperature), or withdrawn (positive effects).\nSummary\nOutlying values in the data should have been excluded. The article should probably be corrected. I can replicate the effects based on their own data, associations get even stronger. I cannot shake the feeling that the authors did not do a good enough job to rule out “boring” common cause confounders like time of day or physical activity. The authors stuck to presenting the data as correlations, but people only care about the data because of the implied causal path temperature -> connectedness. If it was people exercising in team sports -> connectedness and exercise -> temperature, few readers would care.\n\n\n\nFigure 7: Penguins are simply way classier than us. From Wikipedia\n\n\n\n\nnot using hormonal contraceptives, premenopausal, not pregnant or breastfeeding↩︎\n",
    "preview": "posts/2019-06-19-tympanic-temperature-and-social-connectedness/tympanic-temperature-and-social-connectedness_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2021-03-04T14:37:54+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2019-06-14-hibar-how-methods-and-practices-changed-after-the-replication-crisis-in-social-psychology/",
    "title": "HIBAR: How methods and practices changed after the replication crisis in social psychology",
    "description": "Had I Been a Reviewer. A post-publication peer review with some added figures.",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2019-06-14",
    "categories": [
      "HIBAR",
      "re-analysis",
      "post-publication review",
      "meta science",
      "bibliometrics"
    ],
    "contents": "\nEdit: Authors’ response\nThe authors of the study have responded to the points raised here. You can read their response here. We had a little bit of follow-up discussion on Twitter. In all, I found this was a productive exchange and I’m happy the authors took the time to respond in such detail.\n\n\n\n\n\n\nFigure 1: Change in proportion of studies that are online over time by journal. Bootstrapped means and 95% CIs.\n\n\n\nSassenberg and Ditrich published a paper in Advances in Methods and Practices in Psychological Science in May. It’s on a topic I care about deeply, namely the impact of changes in academic culture on research quality. Specifically, the authors were interested whether social psychologists have responded to the replication crisis in their subdiscipline and subsequent cries for higher methodological rigour (especially higher statistical power) by switching to less effortful methods of data collection (self-report).\nI was not a reviewer of the paper, but given that I’ve already re-analyzed the N-pact paper, it felt only appropriate to do the same with this paper. I decided to do this post in the format of HIBAR.1 I think it’s an important topic and the authors collected valuable data, which surely took a lot of coding effort. The authors, regrettably, did not share any figures for their data. Their findings, which are easily summarised graphically, may therefore become less widely known. So, I made some figures from the open data (above and below).\nI frequently hear arguments of the form “calls for rigour in some practices will just lead to less rigour in other areas”, “labour-intensive research will go extinct if higher sample sizes are required” from senior researchers. These arguments are often used to urge caution in response to calls for reform. They may end up being interpreted as advocacy for the status quo.\nEmpirical evidence that given consistent publication pressure, researchers urged to increase their sample sizes will do less rigorous research in other ways is thus worrying.2\nMajor points\nOmitted variables\nThe authors mention a number of coded variables analysed that they say are not relevant for the questions addressed here. I disagree with this assessment. The broader question is whether low-effort methods of data collection such as self-report and online research have replaced high-effort methods. However, the differences in effort for running an effective online study (especially when first learning about online research) versus running a lab study on undergraduates are smaller and more arguable than the differences in effort for running a study online vs. on a population-representative sample or a community sample. The same holds true for self-report and reaction time measures (both not very high-effort) versus e.g. genetic, or endocrinological data, intelligence testing, or observer coding. So, as a reader I would like to know whether self-report and online research replaced other low-effort or high-effort modes of data collection. The researchers disclose that they also coded study design, exclusion of participants, student vs. nonstudent sample, mediation analysis, behavioral measures, response times, memory measures, performance measures, coding of written materials, and physiological measures. Given that the authors give no strong rationale for excluding this data from analyses and given the absence of a preregistration, the omission of these data seems unjustifiable and should be rectified to give readers a fuller picture.\nWasteful sample size transformation\nThe authors winsorize sample size. I do not think this is an appropriate treatment of this continuous variable. Yes, there are outlying values, but these are presumably not the result of miscoding, but the result of massive heterogeneity. A study of 10000 people really is a hundred times as big as a study of 100 people. There are better ways to deal with non-normally distributed statistics without discarding information. As an example, I chose to plot the logarithmised sample sizes below.\nFigures\nFigures are essential for communicating data and effect sizes effectively. I took the liberty of generating a few figures below. What I would like to see in addition is figures on the omitted variables. Further inferential testing is, in my opinion, not necessary. We are interested in some measure of overall rigour, but there will be no agreeable way to aggregate the different variables into one measure of rigour, so the best we can do is present the data and discuss it.\n\n\n\nFigure 2: Change in proportion of studies that use only self-report over time by journal. Bootstrapped means and 95% CIs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Change in median sample size over time by journal\n\n\n\n\n\n\nFigure 4: Change in sample size over time by journal. Sample sizes were logarithmised with base 10. Bootstrapped means and 95% CIs.\n\n\n\n\n\n\nFigure 5: Change in number of studies per article over time by journal. Bootstrapped means and 95% CIs.\n\n\n\nDid submitters or editors and reviewers change their behaviour?\nThe authors frame their results as evidence of changes in the behaviour of research teams. Arguably, science reform is mediated in many places by editors and reviewers. Maybe just as many small-sample studies are being done, but they do not get published in these journals. To begin to answer this question, it is interesting to see (emphasis on see, below) how the different outcome measures associate. The authors should discuss this question more explicitly and discuss the correlations. Can they be used to make the case that researchers in the same team trade off sample size for self-report? Or are we seeing an increase in self-report measures only among online (Mturk?) researchers, while other researchers independently increase their sample sizes without changing their methods?\n\n\n\nFigure 6: Sample size by self-report. Bootstrapped means and 95% CIs.\n\n\n\n\n\n\nFigure 7: Sample size by online. Bootstrapped means and 95% CIs.\n\n\n\nBibliographic data\nThe published data does not contain bibliographic information on the papers. This makes it impossible to check the accuracy of codings, to re-use and extend the data (by, for example, looking up DOIs and fetching citation counts in a few years). If the authors did this to preserve researcher anonymity, I want to strongly argue that this is misguided when it comes to published literature.\nCausal inference\nThe researchers give the standard disclaimer that they have examined only correlations. This would become more vivid if they discussed other known time trends that could confound their results, such as the rise of Mturk. They could also discuss ways in which a stronger causal inference would be possible. Are there subdisciplines akin to social psychology in their use of small samples that were not hit by the reform calls as early (developmental, evolutionary?) which we might examine additionally? Is the question important enough that we should advocate for large-scale experimentation with journal policies?\nMinor points\nThe authors say that their analysis explains 31% of the variance in the online variable. This is a dichotomous variable, so you cannot report an R2. Same for self-report. Please run logistic regressions and report pseudo R2s (if you must).\nI took the liberty of generating a human- and machine-readable codebook for the data, see below.\nSummary\nGiven the presented data, I am not convinced that the researchers have shown that calls for increased rigour in terms of sample size have led to decreased rigour in measurement. To get a fuller sense of valid information, it would also have been interesting to look at other measures of rigour, such as the number of items, reliability, and whether the measure was ad-hoc. This cannot be done with the existing data. What the authors can do, is to fully present the data they have collected, including data on other measurement methods. As a final note, I am not aware that many voices in the reform movement called for more studies per article, yet we see this trend. This might serve as a vivid example that there are always many things going on simultaneously when just examining trends over time.\nCodebook\n\n\n\n\n\n\n\n\nMetadata\nDescription\n\nDataset name: Research in social psychology changed\n\n\nThe dataset has N=1300 rows and 6 columns. 458 rows have no missing values on any column.\n\n\nMetadata for search engines\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate published: 2021-03-04\n\n\n\n\n\n\nx\npaperID\nJournal\nJahr\nStudynum\nSample\nonline\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodebook table\n\n\n\n\n\n\n\n\n\n\nJSON-LD metadata\nThe following JSON-LD can be found by search engines, if you share this codebook publicly on the web.\n{\n  \"name\": \"Research in social psychology changed\",\n  \"datePublished\": \"2021-03-04\",\n  \"description\": \"The dataset has N=1300 rows and 6 columns.\\n458 rows have no missing values on any column.\\n\\n\\n## Table of variables\\nThis table contains variable names, labels, and number of missing values.\\nSee the complete codebook for more.\\n\\n|name     |label                                  | n_missing|\\n|:--------|:--------------------------------------|---------:|\\n|paperID  |unique paper identifier                |         0|\\n|Journal  |journal in which article was published |         0|\\n|Jahr     |year of publication                    |         0|\\n|Studynum |number of studies per paper            |       842|\\n|Sample   |sample size                            |         0|\\n|online   |online data connection                 |         0|\\n\\n### Note\\nThis dataset was automatically described using the [codebook R package](https://rubenarslan.github.io/codebook/) (version 0.9.2).\",\n  \"keywords\": [\"paperID\", \"Journal\", \"Jahr\", \"Studynum\", \"Sample\", \"online\"],\n  \"@context\": \"http://schema.org/\",\n  \"@type\": \"Dataset\",\n  \"variableMeasured\": [\n    {\n      \"name\": \"paperID\",\n      \"description\": \"unique paper identifier\",\n      \"@type\": \"propertyValue\"\n    },\n    {\n      \"name\": \"Journal\",\n      \"description\": \"journal in which article was published\",\n      \"value\": \"1. JESP,\\n2. JPSP,\\n3. PSPB,\\n4. SPPS\",\n      \"maxValue\": 4,\n      \"minValue\": 1,\n      \"@type\": \"propertyValue\"\n    },\n    {\n      \"name\": \"Jahr\",\n      \"description\": \"year of publication\",\n      \"value\": \"0. 2009,\\n1. 2011,\\n2. 2016,\\n3. 2018\",\n      \"maxValue\": 3,\n      \"minValue\": 0,\n      \"@type\": \"propertyValue\"\n    },\n    {\n      \"name\": \"Studynum\",\n      \"description\": \"number of studies per paper\",\n      \"@type\": \"propertyValue\"\n    },\n    {\n      \"name\": \"Sample\",\n      \"description\": \"sample size\",\n      \"@type\": \"propertyValue\"\n    },\n    {\n      \"name\": \"online\",\n      \"description\": \"online data connection\",\n      \"value\": \"0. no,\\n1. yes\",\n      \"maxValue\": 1,\n      \"minValue\": 0,\n      \"@type\": \"propertyValue\"\n    }\n  ]\n}`\n\n\n\n\n\n (Had I been a Reviewer)↩︎\nIt seems easier to change standards at journals than to decrease publication pressure and competititon throughout academia.↩︎\n",
    "preview": "posts/2019-06-14-hibar-how-methods-and-practices-changed-after-the-replication-crisis-in-social-psychology/hibar-how-methods-and-practices-changed-after-the-replication-crisis-in-social-psychology_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-03-04T14:38:25+01:00",
    "input_file": {},
    "preview_width": 3456,
    "preview_height": 768
  },
  {
    "path": "posts/2019-04-21-who-initiates/",
    "title": "Who initiates sex?",
    "description": "A chicken-and-egg-question?",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2019-04-26",
    "categories": [
      "sex diary",
      "open science",
      "sexual activity",
      "sex",
      "quick job"
    ],
    "contents": "\nI’m tempted to say I started writing this post over Easter, because the question “who initiates sexual behaviour in relationships” seems like a chicken-and-egg-question. There are no easy answers. Of course, societal expectations and relationship habits imply that we cannot take whatever answers we find to mean that this translates to who wants (certain) sex (acts) more. And of course, none of this gets any easier given that in our dataset women reported their perceptions of both their partner and themselves—we did not hear from the partners.\n\n\n\nFigure 1: Figure from “Mrs. Basley’s poultry book; tells you what to do and how to do it; the chicken business from first to last including 1001 questions and answers, relative to up-to-date poultry culture” in the Internet Archive Book Images\n\n\n\nBut this is just a blog post, so I’ll ask you to kindly keep these caveats in mind.1\n\n\n\nTo look at who initiates sex more often, I’ll restrict the diary dataset to the 628 women who filled out the diary on more than 30 days and who were in a heterosexual relationship. I’ll also restrict it to days on which women had seen their partners at least briefly. We asked women in heterosexual relationships to endorse the following specific, awkwardly pointed statements. Because we were trying not to bore our participants out of their minds we only asked these questions on 30% of days. This still lets me examine 7303 days, with sexual activity on 3054 of those days.\nMy partner initiated sexual acts with me.\nI initiated sexual acts with my partner.\nSingle women and women who had non-heterosexual relationships filled out detailed questions about their love lives as well, but we’ll leave that for another day.\nWomen and men\n\n\n\nFigure 2: As you can maybe already see, women reported their partners initiated sex more often, on average.\n\n\n\n\n\n\nFigure 3: By looking at this in two dimensions, we can see a bit more detail. On most days, women report equal initiative by both, but on many days they also report initiative from the partner, when they themselves showed zero initiative. It becomes apparent that stretching the response options out from zero to four may not have made that much of a difference.\n\n\n\n\n\n\nFigure 4: Let’s simplify it down to yes or no. I counted everything higher than zero as a yes. That’s probably not the best approach to ordinal data and definitely not a good approach to consent.\n\n\n\nIndividual differences\nI don’t want to neglect individual differences, but visualising them well is hard! Therefore, I hid these attempts here.\n\n\n\nFigure 5: Simplifying it gives us a chance to make a tapestry of the individual differences in these patterns I’m restricting it to women with a lot of data here, so we can still see. Each four-coloured square is one couple/woman. White squares should really be dark blue (zero counts), but I couldn’t quickly make ggplot2 do my bidding.\n\n\n\n\n\n\nFigure 6: We can also look at the number of days on which both, either, or neither initiated sex in a table. Each color is one woman/couple.\n\n\n\n\nTable 1: We can look at the five women those whose initiative exceeded their partners’ most, and those five women whose initiative was lower than their partners most often.\nboth_init\npartner_more\npartner_less\npartner_same\npartner_same_and_nonzero\n7\n0\n7\n14\n1\n7\n0\n5\n19\n2\n7\n6\n10\n11\n4\n20\n2\n7\n17\n12\n6\n7\n2\n14\n2\n11\n13\n4\n6\n4\n9\n14\n0\n7\n3\n3\n11\n1\n10\n3\n5\n24\n0\n2\n1\n\nBy time\nIn the last post, we looked at sexual activity across the day and week. So, you have some idea when sex happens. But who initiates sex on these days? Unsurprsingly, it seems both (or more in some cases) parties are initiating sex more on the weekend.\n\n\n\nFigure 7: Are their partners more likely to initiate sex during the week than our participants? The difference does not seem large.\n\n\n\nA different look at the same data\n\n\n\nFigure 8: Okay, so I have a problem with letting go of redundant plots. So what?\n\n\n\nWhat about time of day? In the last post we saw that women reported slightly lower enjoyment for morning sex on average. Here, we see a corresponding gap in initiation. However, we also see a gap for daytime sex and we saw no enjoyment gap there. I’m very interested in your theories (or literature) why these gaps turn out differently.\n\n\n\nFigure 9: Interesting difference! It may seem odd that average initiation goes down in the evening, even though people have more sex in the evening, but remember that I can only plot sex according to time conditional on having sex. I don’t know exactly what everyone is doing at night, but maybe sex ‘just happens’ more often? Or the kind of people who only have sex in the evenings are less likely to strongly endorse the initiation items. Complicated, huh? I’m lucky this is just a blog post.\n\n\n\nA different look at the same data\n\n\n\nFigure 10: Another redundant plot, but IT LOOKS NICE.\n\n\n\nWho initiates which acts?\nNow, we did not ask for each sexual act who initiated it. That kind of play-by-play just did not seem like a reasonable thing to ask. Still, it might be fun to look at the initiation on each day by the kind of sex people had on that day.\n\n\n\nFigure 11: First, we can look at raw means.\n\n\n\nNow, looking at raw means ignores that certain sex acts are more likely to be performed in the evenings or on weekends and that they co-occur. We already saw these factors have something to do with initiation as well. I’m not sure what the best model is to take all this into account. I’m happy for better suggestions!\nSome activities trade ranks, but fellatio and BDSM (submissive)2 stay at the top. Fellatio is the only act where we see almost no gap in initiation.\n\n\n\nFigure 12: What do we get when we adjust for these other factors and between-individual differences in an ad-hoc model?\n\n\n\n\n\n\nFigure 13: We can also limit the data to only days on which no sexual acts were combined.\n\n\n\nSo, this is a first look at the question who initiates (what kind of) sex. I had a busy week, so this is just quick and dirty.3 I plan to analyse sexual initiation across the menstrual cycle at some point, so it was good to do some sanity checks with this data.\nSelf-reported initiation—not total nonsense, maybe?\nPart of the reason for doing this blog post was seeing whether the items we used give reasonable results. I did not want to bore you with these sanity checks, but I’m also not good at deleting graphs either.\n\n\n\nFigure 14: How would have thought? Initiating sex predicts more sex acts on that day.\n\n\n\n\n\n\nFigure 15: And sexual initiation in the absence of partner initiation is associated with masturbation\n\n\n\n\n\n\nFigure 16: Initiating sex has a stronger relationship with own libido than partner initiation\n\n\n\n# A tibble: 2 x 2\n  who                       `cor(value, high_libido)`\n  <chr>                                         <dbl>\n1 sexual_initiation_partner                     0.453\n2 sexual_initiation_self                        0.609\n\n\n\n\nFigure 17: Initiating sex has a stronger relationship with with wanting to satisfy own sexual needs than partner initiation\n\n\n\n\n\n\nFigure 18: Initiating sex has a stronger relationship with with wanting to be desired than partner initiation\n\n\n\n\n\n\nFigure 19: Self- and partner initiation are similarly associated with wanting to satisfy partner’s sexual needs.\n\n\n\n\n\n\nFigure 20: Guess who enjoys partner-initiated sex? Partners.\n\n\n\n\n\n\nFigure 21: However, own enjoyment is not higher when having initiated sex.\n\n\n\n\n\n\nFigure 22: Neither is happiness.\n\n\n\nLest I sell the data short, the initiation questions do show reasonable associations with a bunch of other questions we asked, see Appendix. However, I have tagged this post a “quick job”, so it is excluded from by Bug Bounty program. I still appreciate hearing about errors of course.↩\nThis response meant engaging in some BDSM play in a submissive role. It was also possible to specify BDSM play in a dominant role, but that fell below my arbitrary cutoff of at least 30 observed acts↩\nBut let me know if you want to see a graph I could add.↩\n",
    "preview": "posts/2019-04-21-who-initiates/who-initiates_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2020-06-06T06:58:54+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2019-04-08-sex-by-day-and-by-night/",
    "title": "Sexual activity by time of day",
    "description": "Examining when women in our diary study were sexually active.",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2019-04-12",
    "categories": [
      "sex diary",
      "open science",
      "sexual activity",
      "sex"
    ],
    "contents": "\nWe collected detailed data on sexual activity in our diary study. After a lot of discussion in the team, we agreed on the following method:\nWe asked women whether they had been sexually active (including masturbation, and caresses1)\nIf they said yes, we asked how often\nIf they gave a number higher than two, we asked them to describe only the first two activities\nThen, for each sexual activity, we asked\nWhen?\nWith whom?\nWhat did you do?\nIf they mentioned a partner, we asked about contraception.\nIf they mentioned masturbation, we asked about sexual fantasies\nWho/what did you think about?\n\nWe then asked about own satisfaction and partner satisfaction, and whether it made them happy.\n\nA big part of our discussion was which sexual activities we should list. A very long list of activities seemed a bit intimidating, plus many sexual activities in German have either weirdly academic or vulgar names, but nothing that seemed usable. We didn’t want to exclude non-genital sexual contact from consideration, but also didn’t want to ask our participants to report every goodbye kiss or hug. In the end, we opted for a subset of activities (including kissing and cuddling) and the ability to write in unlisted options, which we coded afterwards. We think this worked quite well, but it is possible that the activities we listed were “normalised” more than unlisted activities. I’m curious how others go about this.2\nBecause we tried to impose as few restrictions as possible, cleaning this data was a bit cumbersome though (people have sex in manifold ways!). To motivate myself to do it, I wanted to blog a few descriptive statistics. I don’t have a sexology background, so I don’t know what is well-known to experts in the field and what isn’t. Of course, we mainly plan to use the data to study sex across the menstrual cycle, but I think there are many interesting aspects to the data unrelated to that.\n\n\n\nHere, I am looking at all data (1345 women over 61,365 days, ~45 days per woman). First off, how many sexual acts do women report across days?\n\n\n\nFigure 1: Number of sexual acts on each diary day. X-axis is log1p-scaled.\n\n\n\nThis looks good. Women rarely report more than two acts a day, so we are not missing much in our survey. On average, people in our sample engaged in some sexual activity (including kissing and cuddling) on 31% of days.3 Excluding kissing and cuddling, women in our sample either masturbate or have some sort of sex on 28% of days. Broken down even further, women in our sample have sex with a partner on 16% of days and masturbate on 13% of days. In the following, I will exclude kissing and cuddling, although it makes little difference for the results.\nOf course, there are individual differences in these frequencies. In yellow, you see women in relationships, in blue single women.4\n\n\n\nFigure 2: Sexual act frequency differences\n\n\n\nMost readers probably know people are more sexually active on weekends:\n\n\n\nFigure 3: More sex on the weekends\n\n\n\nWhat’s up with Monday though? Because women filled out our diary from 17:00-03:00, they also reported on sex the previous night. Maybe some of the increase we’re seeing is due to this? I excluded sex on the previous night in the below graph.\n\n\n\nFigure 4: Without sex the previous night\n\n\n\nDetailed break-up by time of day\n\n\n\nFigure 5: Sexual activity by time of day\n\n\n\nIt seems the Monday bump is just Sunday night sex (see also the details graph, if you are interested). We can also move all last night’s sexual activity to the day before and see whether Mondays look more like we expect Mondays to look.5\n\n\n\nFigure 6: Sex and time of sex across the week. Y axis shows the count of sex acts on that day at that time as a percentage of the total number of diary days divided by 7. We can see that daytime sex increases\n\n\n\nLooks reasonable. So far, I have lumped all sexual activity, partnered and non-partnered.\n\n\n\nFigure 7: The weekend bump appears only for partnered sexual activity. But there is an interesting decrease in masturbation before falling asleep on Thursday, Fridays, and Saturdays.\n\n\n\nSo, maybe it’s not mainly about having more time on the weekend, but rather about coordination? We have a lot of data about whether people are living together, in the same city, or in a long-distance relationship.\n\n\n\nFigure 8: Long-distance relationships make the week-end gap worse, but even couples who live together have more sex on week-ends.\n\n\n\n\n\n\nFigure 9: The week-end gap is smaller, but not gone for couples who spend the more days a week together.\n\n\n\nWe can also relate the timing of sex to own/partner satisfaction and happiness. For example, we saw above that women report masturbating in the morning and during the night quite rarely, whereas partnered sexual activity was comparatively more common then.\n\n\n\nFigure 10: Women’s own satisfaction and happiness and their partner’s satisfaction as a function of time of day. The scale went from 0 [not at all] to 4 [very much so].\n\n\n\nIn fact, women report being less satisfied with and happy about morning sex.6 The difference is small and there could be a ton of factors (from circadian hormone change, to different activities by time of day, to differing partner attentiveness, to feeling rushed before work, and so on).\nWe have data on aspects of the sexual activity other than time, so we can potentially pull apart different influences on happiness and enjoyment (although still with much less than experimental rigour).\nThis is an incredibly rich dataset, so I am very interested in suggestions what else to look at and how.\nPS\nIn follow-up discussions, it occurred to me that I never included two of the most obvious graphs. Luckily, I can remedy that now.\n\n\n\nFigure 11: People have the most sex in the evenings. On week-ends, they also get a chance during the day and in the mornings.\n\n\n\n\n\n\nFigure 12: We can show it even more strongly by collapsing the two evening and the two morning categories\n\n\n\nprobably the German word Zärtlichkeiten sounds less weird than this translation. Or more so.↩\nI’ll blog about this list of activities another time.↩\nIf this seems low to you: as you can see in the aside, most women did not report kissing and cuddling if there was not also some other sexual contact.↩\nI restricted the dataset to the 878 women who had participated for at least 40 days to make sure we could estimate the frequency with some accuracy.↩\nSteering clear of any Garfield references here.↩\nThey say the same thing about their partner’s enjoyment.↩\n",
    "preview": "posts/2019-04-08-sex-by-day-and-by-night/sex-by-day-and-by-night_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2020-06-06T06:58:55+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2019-04-02-measuring-contraception/",
    "title": "Measuring contraception",
    "description": "How we measured methods of contraception, reasons for using different contraceptives, and fertility awareness.",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2019-04-02",
    "categories": [
      "sex diary",
      "open science",
      "contraception"
    ],
    "contents": "\nIn our sex diary study, one of the most important components was our contraception questionnaire. Surprisingly, to us, we did not find a good, open standard questionnaire that fit our needs.1 We needed something that would measure\nnot only one main, but all methods of contraception\nfertility awareness2 independently of whether it was used for contraceptive purposes, i.e. including apps like Clue\nthe reasons why people mix contraceptive methods\nthe exact contraceptive pill, intra-uterine device, ring, patch etc.3\nwhat fertility-awareness method users do when fertile\nall potential contraceptive methods that we could imagine\nWhy do we need such detailed information on contraception to study ovulatory effects?\nCombined hormonal contraceptives suppress ovulation—we could use them as a quasi-control group for our last study. However, progestogen-only contraceptives do not reliably suppress ovulation.\nSome fertility awareness method users are sexually abstinent in the fertile window. When we are interested in whether ovulation whets the appetite for sex and changes sexual behaviour, we should probably exclude these women or at least treat them separately.\nAwareness of the cycle phase could lead to different responses. Potentially, women actually feel or report feeling more desirable, or more sexual when they believe they are fertile—independently of, or on top of any hormonally caused changes.4\nToday, I want to show the questions we chose and share the questionnaire. We’re still in the market for improvements. At the same time, I want to encourage others to more fully report contraception information in their menstrual cycle studies. When you are reporting effects on sexual desire or activity, we need to know more than that participants were not on the pill and not pregnant. I’ll try to show why in the coming blog posts.\nTranslation details\nTo be able to show the descriptive graphs below, we translated the questions.5\n\n\n\nContraception or not?\nWe began by asking whether women used contraception at all. This time, we only asked women who were not pregnant. Next time, we plan to ask all women about contraception because even pregnant women could e.g. use condoms to prevent sexually transmitted infections, urinary tract infections. However, so that it does not like a lack of forethought, we should probably optionally display some explanation to this effect for e.g. menopausal and pregnant women, because some women found it odd to be asked these questions. In this study, we gave women a free text field to write in if they wanted to specify other reasons why they didn’t use contraception.\n\n\n\nFigure 1: Pregnant women were excluded from the contraception questionnaire.\n\n\n\n\n\n\nFigure 2: Different degrees of using contraception\n\n\n\nMethods\nNext, we asked all women who used contraception which methods they used. Multiple methods could be checked. As you can see, condoms and the the pill were the two most common methods. A lot of women also combined both. Next, you might be surprised at the number of women who report using coitus interruptus (in the lower left graph), the pull-out method. However, more women combined this with condoms or a fertility awareness method than used only coitus interruptus. Next were intra-uterine devices and hormonal contraceptives other than the pill. We will look at these in detail next.\n\n\n\nFigure 3: Methods of contraception and how they are combined. In this UpSet plot, we see how common each contraceptive is (on its own or in combination with others) in the small bar chart in the lower left. We see which combinations are common by checking which circles are connected in the panel at the bottom and checking the height of the intersection bar.\n\n\n\nAs you can see, the non-pill hormonal methods were mainly NuvaRing (a estrogen/progestogen vaginal ring) and Mirena (a progestogen-only intra-uterine contraceptive).\n\n\n\nFigure 4: Other hormonal contraceptives\n\n\n\nCombining methods\nAbove, we saw that many women combine multiple contraceptives. We had a list of reasons that we considered likely, but many women also gave reasons we hadn’t included.\n\n\n\nFigure 5: Why combine several contraceptives?\n\n\n\nThe most common reason was as a fallback method during fertile days (i.e., for women using fertility awareness methods). Many used condoms in addition to the pill to also prevent STDs, but many also used the pill and condoms to decrease conception risk even further. Fallback methods were also common (e.g. condoms as a fallback to the pill, or pull-out as a fallback to condoms). A substantial number of women also used different methods for different partners, and a small minority also said they used condoms when their partner has a cold.\nFrom the reasons we hadn’t included in our list, we should include at least the following in the future:6\nfallback in case the pill might not have worked (e.g., stomach flu, throwing up, travel, medication)\npill against acne/hypermenorrhoe/menstrual pain/other reasons, another method for contraception\ncondoms for hygienic reasons\ncondoms to avoid urinary tract infections\naccording to mood\nFertility awareness\nA special case of combining contraceptive methods are the fertility awareness methods. How many of our participants are sexually abstinent during the fertile phase, how many switch to other methods? As you can see, most switch to other methods. Total sexual abstinence is rare, although quite a few report having penetrative sex less often, or not at all.\n\n\n\nFigure 6: What do fertility awareness method users do during their fertile phase?\n\n\n\nMethods and reasons for combining methods in two big graphs\nWe can of course also merge the reasons for combining contraceptives with the contraceptive information itself.\n\n\n\nFigure 7: Which contraceptives are combined for which reasons?\n\n\n\n\n\n\nFigure 8: Which contraceptive method do fertility awareness method users switch to during their fertile phase?\n\n\n\nThe pill\nTo help our participants identify their pill, we used a searchable drop-down that showed the brand name of the pill together with a picture of the packaging. Most women found their pill in our list; the others were asked to enter name and details (progestogen type and amount, estrogen amount) into text fields.\n\n\n\nFigure 9: Common oral contraceptive pills. Only those used by at least 10 women shown.\n\n\n\n\n\n\nFigure 10: Micrograms of estrogen in a pill (unified to average content over 21 days, without pill break)\n\n\n\nAwareness\nQuite a few women used some sort of cycle app.\n\n\n\nFigure 11: Cycle app users\n\n\n\n\n\n\nFigure 12: Cycle apps. Only those used by at least 10 women shown.\n\n\n\nWe looked at all of these apps and coded their purpose. Some of them are just pill reminders, some additionally allow you to track symptoms, whereas others really lead to fertility awareness (i.e., tell you when they estimate you will be fertile).\n\n\n\nWe are really glad we asked about apps. As you can see below, the vast majority of cycle awareness app users do not use them as a primary method of contraception; most use condoms and IUDs.\n\n\n\nFigure 13: Cycle awareness app users’ contraceptive methods.\n\n\n\nEstrogen and progestogen\nAs you could see above, our participants used a wide variety of contraceptives. Among them were quite a few progestogen-only contraceptives (hormonal IUDs, such as Mirena, patches and depots, and of course various mini-pills, such as Jaydess, Cyprella, Desirett, Cerazette, etc.). When we add all this together, we see that a substantial minority uses progestogen-only contraceptives.\n\n\n\nSummary\n\n\n\nFigure 14: To summarise all this for our purposes, we constructed the above categories. In A, we do not yet include information on cycle tracking apps and on the different hormones in contraceptives. In B, we account for this but lump women who combine hormones and barrier methods with other hormonal contraception users. To do so, we differentiate two hormonal methods, awareness methods, condoms, non-hormonal IUDs, and no contraception. The rest are lumped. For women who combine several contraceptives, the order in the preceding sentence determines precedence.\n\n\n\n\n\n\nSo, these were the main questions from our questionnaire. I didn’t get into how we combined this with questions about the period (menarche/menopause, regularity, cycle length, etc.), family planning, and so on.\nI added the entire list of questions, including skipping logic (which takes some forethought) below. You can export these to Excel and use them directly in formr.org. This is already an adapted version of the questionnaire we used and I’m sure it can be improved further. What questions are you asking? What can we improve in our next study?\nOur questions\n\n\n\n\nAcknowledgements\nThanks to Tessa Cappelle and Kim Gloystein for help translating the questionnaire. Thanks to Julie Driebe and Iro Eleftheriadou who helped me clean and code the contraception questionnaire data. The questionnaire was designed by our study team (Julie Driebe, Tanja M. Gerlach, Lars Penke, Julia Jünger (now: Julia Stern), Julia Ostner).\nWe checked a few familiar demographic surveys, which erred on the side of asking fewer questions, and the psychological literature, which erred on the side of not reporting exactly which questions were asked↩\nCounting days, measuring temperature, mucus↩\nso we could differentiate between contraceptives with different kinds and amounts of progestogens and different amounts of estrogens↩\nIn our last study, we only found some descriptive differences between non-hormonal methods. The only significant difference was between hormonal and non-hormonal methods, but our sample size for fertility awareness methods was small and potentially women who used condoms also used a fertility tracking app for fun, but not contraception. Descriptively, fertile window increases in extra-pair desire were larger for women using awareness methods than for barrier method (condoms, mostly) users, but the opposite pattern held for in-pair desire, and we found no apparent difference for self-perceived desirability.↩\nIf you ever find yourself in the situation of wanting to re-label items in your language with English labels, you can follow along the code for this post on Github. It’s really simple as long as you have a well-structured item sheet.↩\nTaken from the written responses to the other reasons prompt.↩\n",
    "preview": "posts/2019-04-02-measuring-contraception/measuring-contraception_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2020-06-06T06:58:54+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2019-03-13-intra-individual-feedback/",
    "title": "Intra-individual feedback",
    "description": "Thinking through an intra-individual menstrual cycle feedback.",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2019-03-19",
    "categories": [
      "sex diary",
      "open science",
      "feedback",
      "visualization"
    ],
    "contents": "\nIn our first sex diary study, we had no real budget, so we encouraged users to participate by promising them detailed feedback. This worked great1 and was well-received by participants. In the second study, we could pay participants up to 45€, but of course I wanted to one-up the feedback from the first study, given that we were using formr.org and I’m super proud of its feedback capabilities.\nSpecifically, I wanted to also include intra-individual feedback on menstrual cycle changes. After all, we had collected up to 70 days worth of data from each woman and asked them quite many questions. Even if the results wouldn’t always be diagnostic (there may well be cycles changes that are missed), we could at least show that. After all, many women have theories about how they personally change over the cycle.2 Most women do not explicitly track or notice ovulation.3 So, for most it is easier to notice menstrual changes rather than ovulatory changes. Our feedback might actually uncover something about them that they did not already know better themselves. I would not say this about most personality feedback based on self-report.\nDecisions\nWhen designing feedback plots that will be generated live without a human in the loop, you have to make many decisions.\nDo you require a minimum of data?\n(How) do you display uncertainty?\nDo you show the raw data?\nWhich outcomes are interesting?\nWe pretty much free-styled these decisions. Given that my collaborators in Göttingen might run such studies again, I thought I’d show what we did and ask for reader input. We didn’t require a minimum of data, but we showed uncertainty and raw data instead. I’ve gotten the feedback from my collaborators at Clue that they would not show their users such complex plots though, so I’m very interested in simplifying them or the messages they contain.\n\n\n\n\n\n\nFigure 1: An example feedback plot. On the X axis you see the days until the next menstruation. On the Y axis, you see the outcome (here, high sex drive). The line is a locally weighted regression smooth with a 95% confidence interval.\n\n\n\nPlanned revisions\nOf course, for many women the answers from the plots were pretty equivocal, like this plot.\nI should not have used LOESS, but a GAM with a cyclic spline s(menstrual_onset_days_until, bs = \"cc\"), given that it is, you know, a cycle. I did not know that then. Thanks to Mike Lawrence for pointing this out in response to our first study’s graphs.\n\n\n\nFigure 2: The same graph as above with cyclic splines.\n\n\n\nI should have included menstruation dates from our screening and follow-up surveys, not just the diary. I forgot or didn’t get the code working in time. This meant that some days on either side of the diary could not be included. Doing this for this participant, we get 20 days more and a clearer pattern.\n\n\n\n\n\n\nFigure 3: The same graph as above with all days included.\n\n\n\nI’m not happy about how we showed the fertile window. In our research work, we use a continuous measure of conception risk and of course we cannot be sure that we estimate the day of ovulation precisely with counting data. So, our precise fertile window above actually went against our own philosophy of showing uncertainty.\n\n\n\nFigure 4: The same graph as above with a more continuous fertile window.\n\n\n\nLastly, showing an intra-individual plot is great, but in the end, we are giving particpants something they could have found for themselves by tracking their cycle and psychological changes. And it is simply interesting to compare yourself to others.\nTo this end, it would have been cool to show norm data as well. We did not have such data yet because the feedback was generated live, while the study was running. Now, I can add data for other women as well. I’ll show the code for the “final” plot function here.4.\n\n\ndiary_comparable <- diary %>% \n  group_by(session, cycle_nr) %>% \n  filter(!is.na(prc_stirn_b), \n         hetero_relationship == 1,\n         RCD > -30, reasons_for_exclusion == \"\",\n         between(cycle_length, 27, 30))\n\nplot_menstruation = function(data, y, ylab, ylim = c(0, 4)) {\n  if (!is.null(ylim)) {\n    ymax = ylim[2]; ymin = ylim[1]\n  } else {\n    ymax = max(data %>% select_(y), na.rm = T)\n    ymin = min(data %>% select_(y), na.rm = T)\n  }\n  alphas <- s3_daily %>% \n    ungroup() %>% \n    select(menstrual_onset_days_until, prc_stirn_b) %>% \n    distinct() %>% \n    filter(prc_stirn_b > 0.1) %>% \n    deframe()\n\n  rects <- alphas %>% \n    imap(~ annotate('rect', \n                    xmin = as.numeric(.y), xmax = as.numeric(.y) + 1, \n                    ymin = ymin, ymax = ymax + 1, \n                    fill = '#37af9bAA', color = NA, alpha = .x))\n  \n  ggplot(data, aes_string(x = \"menstrual_onset_days_until\", y = y)) +\n    rects +\n    annotate('rect', xmin = -6, xmax = 0, \n             ymin = ymin, ymax = ymax + 1, fill = '#ed9383AA', color = NA) +\n    annotate('text', label = 'fertile\\nwindow', x = -19.5, \n             y = ymax, size = 4, hjust = 0) +\n    annotate('text', label = 'premenstrual\\nphase', x = -5.5, \n             y = ymax, size = 4, hjust = 0) +\n    geom_jitter(aes_string(shape = \"menstruation_labelled\", \n                           color = \"menstruation_labelled\"), size = 1.5) +\n    scale_color_manual(\"Menstruation\", \n                       values = c(\"no\" = \"black\", \"probably\" = \"#b86147\", \n                                  \"yes\" = \"#cf6030\")) +\n    scale_shape_manual(\"Menstruation\", \n                       values = c(\"no\" = 16, \"probably\" = 17, \"yes\" = 17)) +\n    geom_smooth(aes(group = 3), data = diary_comparable %>% \n                  filter(hormonal_contraception == \"FALSE\"), \n                method = \"gam\", formula = y ~ s(x, bs = 'cc'), \n                color = \"red\", fill = \"red\", alpha = 0.1) +\n    geom_smooth(aes(group = 2), data = diary_comparable %>% \n                  filter(estrogen_progestogen == \"progestogen_and_estrogen\"), \n                method = \"gam\", formula = y ~ s(x, bs = 'cc'), \n                color = \"black\", fill = \"black\", alpha = 0.1) +\n    geom_smooth(aes(group = 1), \n                method = \"gam\", formula = y ~ s(x, bs = 'cc'), \n                color = \"#ee00ee\", fill = \"#ee00ee\", alpha = 0.1) +\n    ylab(ylab) + \n    xlab(\"Days until next menstruation\") +\n    theme(legend.title = element_text(size = 10), \n          legend.text = element_text(size = 8)) +\n    coord_cartesian(ylim = ylim)\n}\nplot_menstruation(s3_daily, \"high_libido\", \"High sex drive\")\n\n\n\n\nFigure 5: The same graph as above with the average curves. The black curve shows women who use combined hormonal contraceptives. The red curve shows women who don’t use hormonal contraception.\n\n\n\nAs you can see, this woman, whether by chance or because of meaningful individual differences5, seems to show a larger-than-average increase in libido in the fertile window.\nSummary\nThe last graph does a better job than the original. It shows the uncertainty for the participant (including the fertile window estimate), includes more of their data, uses cyclic splines, and shows the normative pattern.\nI’m sure it could still be improved. For example, the splines for the rest of the sample ignore the multilevel structure of the data. I have fit models with brms that could do a better job of this, but I’ll save those for another day. Do you have any other suggestions?\nMore feedback\nI didn’t want to bore my audience too much, but if anyone is curious and doesn’t mind reading German, I uploaded an example of a full feedback for this participant. It includes personality feedback, notes on how to interpret the cycle graphs, and several interactive graphs (on time use on weekends versus weekdays, and on mood across the period of the entire diary). You can find the code here. I did not share the data to protect participant privacy, but it may still be useful if you want to make your own feedback plots.\n\nOk, we didn’t randomise this, so I don’t actually know whether it wasn’t something else - we really went all-in on recruiting too.↩︎\nWe asked about these theories after the diary concluded, but that is a story for another day.↩︎\nWith the exception of the large minority, ca. 30%, of women who experience mittelschmerz, or ovulation pain.↩︎\nYou can find the intermediate steps on Github.↩︎\nI plan to rigorously test such questions soon.↩︎\n",
    "preview": "posts/2019-03-13-intra-individual-feedback/intra-individual-feedback_files/figure-html5/unnamed-chunk-7-1.png",
    "last_modified": "2021-03-04T14:39:31+01:00",
    "input_file": {},
    "preview_width": 1920,
    "preview_height": 1344
  },
  {
    "path": "posts/2019-03-12-moderation-vs-distributional-regression/",
    "title": "Do single mothers have a stronger influence on their kids?",
    "description": "And how would you test that?",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2019-03-13",
    "categories": [
      "simulation",
      "data-generating model",
      "brms"
    ],
    "contents": "\nYesterday, I sat down with Lisa Reiber, who is doing her master’s thesis with me. She is working on the question of the transmission of risk preferences in families. Many of the potential predictions we hope to test involve mean level changes (e.g., children of divorcees will be more risk-averse because they learned the world is less certain). In other cases, once we get down to which models we want to test, it is a lot less clear.\nOne question which I have struggled with in the past often comes up when the phrase “strength of influence” comes up. For example, some theories say that mothers have a stronger influence on their children’s traits if the fathers are absent. Verbally, I have also seen this expressed “play a bigger role”. Intuitively, how would you test this?\nWe decided we should make a quick data-generating model to clarify what we mean when we talk about this.1\nWe start by generating families, half of which are divorced. Mothers and fathers aren’t mating assortatively in this example.\n\n\nlibrary(tidyverse)\nlibrary(brms)\ntheme_set(theme_bw())\nfam <- tibble(\n  mother = rnorm(1000),\n  father = rnorm(1000),\n  divorce = rep(c(0,1), each = 500)\n)\n\n\n\nSo far, so good. We have a 1000 couples - let’s make children. We’ll assume all transmission is through parenting, which these hypothetical parents share equally, not genetics. Hence, in two-parent families, they share parenting equally and both have the same influence on their child’s trait.\nIf there was no divorce, we would expect the following. We have equal contributions by each parent (0.6 * parent). Despite all the power of parenting in this hypothetical world, children turn out somewhat differently from their parents, which is reflected by the final term 0.6 * rnorm(1000).\n\n\nfam <- fam %>% \n  mutate(\n   child = 0.6 * mother + 0.6 * father + 0.6 * rnorm(1000)\n  )\n\n\n\nWhat happens in case of divorce? In divorced families, fathers have absolutely no influence.2 One thing that is pretty clear, is that the term for the father’s influence should be zero in our model ((1 - divorce) * 0.6 * father). And isn’t it logical that the mother’s regression weight should hence go up by the same amount (divorce + 1) * 0.6 * mother?\n\n\nfam <- fam %>% \n  mutate(\n    child = (divorce + 1) * 0.6 * mother + (1 - divorce) * 0.6 * father + 0.6 * rnorm(1000)\n  )\n\n\n\nOn thinking about this, we reconsidered. Does having a stronger influence mean that\nwe think risk-averse divorced mothers make their children twice as risk-averse as themselves compared to non-divorced mothers?\nthat there is no difference between divorced and non-divorced mothers when the mothers are average in risk preference?\nThis would mean that divorcee’s children are actually less similar to their mothers in absolute terms. No, we decided by “having a stronger influence” in this case, we actually meant simply that another systematic influence (the father) was removed, so the mothers’ contribution to differences in their children would be bigger and the children would be more similar to them. This is a simpler model. We only say that the contribution by the father is removed (1 - divorce) * 0.6 * father.\n\n\nfam <- fam %>% \n  mutate(\n    child = 0.6 * mother + (1 - divorce) * 0.6 * father + 0.6 * rnorm(1000)\n  )\n\n\n\nIf you think the second model makes more sense, you would probably tend to test an interaction between mother’s trait and divorce. But how would you test the third scenario? When there is distinct groups, I have been trained to think of this as a difference in correlations (similarity, variance explained). I didn’t really have a lot of experience teaching this particular nuance. I think I left my own graduate statistics classes thinking that correlations are basically regressions with the variables standardised.\nNow, really, this is the model we would want to test, the data-generating model.\n\n\nsummary(brm(child ~ mother + divorce * father, data = fam, cores = 4, file = \"dgm\"))\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: child ~ mother + divorce * father \n   Data: fam (Number of observations: 1000) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept         -0.01      0.03    -0.06     0.05 1.00     5029\nmother             0.60      0.02     0.56     0.64 1.00     5777\ndivorce           -0.01      0.04    -0.08     0.07 1.00     4637\nfather             0.62      0.03     0.56     0.68 1.00     3222\ndivorce:father    -0.61      0.04    -0.69    -0.53 1.00     3316\n               Tail_ESS\nIntercept          2969\nmother             2920\ndivorce            3167\nfather             2962\ndivorce:father     3243\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.63      0.01     0.60     0.66 1.00     5997     3004\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nNice.3 But in many datasets (and in ours), divorced families will have missing data for the fathers.\n\n\nfam$father <- NA\n\n\n\nSo, we might instead test the following model; after all we think mothers will have greater influence in divorced families and a lot of people seem to test “greater influence” via interaction tests.\n\n\nsummary(brm(child ~ divorce * mother, data = fam, cores = 4, file = \"interaction_model\"))\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: child ~ divorce * mother \n   Data: fam (Number of observations: 1000) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept          0.01      0.03    -0.05     0.08 1.00     4345\ndivorce           -0.03      0.05    -0.12     0.07 1.00     4342\nmother             0.60      0.03     0.54     0.67 1.00     3590\ndivorce:mother    -0.00      0.05    -0.09     0.09 1.00     3393\n               Tail_ESS\nIntercept          2856\ndivorce            2679\nmother             2943\ndivorce:mother     2735\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.75      0.02     0.72     0.78 1.00     5118     2475\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nBut the interaction is estimated at zero! A plot to the rescue!\n\n\nggplot(fam, aes(mother, child)) +\n  geom_point(alpha = I(0.1)) +\n  geom_smooth(method = 'lm') +\n  coord_cartesian(c(-3,3), c(-3,3)) +\n  facet_wrap(~ divorce, \n             labeller = labeller(divorce = c(\"0\" = \"Not divorced\", \"1\" = \"Divorced\")))\n\n\n\n\nHere, we are looking at scatter plots of mother and child by marital status. We can see visually that the slopes of the regression lines are the same. However, now we notice that the scatter around the regression line is more dispersed in the non-divorced group. I have to say, I am not sure how easily this sort of thing is noticed in plots with real data, noisier relationships, or if the moderator of influence strength is continuous.\nInstead of regressions, we can also run correlations\n\n\nfam %>%  \n  summarise(cor(child, mother))\n\n\n# A tibble: 1 x 1\n  `cor(child, mother)`\n                 <dbl>\n1                0.630\n\nfam %>% group_by(divorce) %>% \n  summarise(cor(child, mother))\n\n\n# A tibble: 2 x 2\n  divorce `cor(child, mother)`\n*   <dbl>                <dbl>\n1       0                0.567\n2       1                0.725\n\nNow, we see that the correlation between mother and child is indeed stronger in divorced families. However, I never particularly liked this approach to this problem. I find correlations harder to think about in terms of my data-generating model (you’ll notice that the correlations .55 and .70 appear nowhere in the code above). It also becomes difficult when moving to multiple regression, multilevel models, or non-normal data. That’s why I am so happy about brms. It allows me to think about the models I want to fit in almost the same language that I use to think about data-generating models. This greatly reduces cognitive friction for me.\nWhat would this model look like in brms? It’s an example of a distributional regression with unequal variances. The brmsformula function allows us to group multivariable formulas.\n\n\nmodel_formula <- brmsformula(\n  child ~ mother, # the regression of mother on child\n  sigma ~ divorce # sigma is a reserved word. \n  # we are predicting the size of the residual variation \n  # using the divorce variable\n  )\n\n\n\nLet’s run this model.\n\n\nmod <- brm(model_formula, \n  data = fam, cores = 4, \n  file = \"divorce_importance\")\nsummary(mod)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = log \nFormula: child ~ mother \n         sigma ~ divorce\n   Data: fam (Number of observations: 1000) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept          -0.00      0.02    -0.05     0.04 1.00     4308\nsigma_Intercept    -0.25      0.03    -0.31    -0.19 1.00     4143\nmother              0.60      0.02     0.56     0.64 1.00     4081\nsigma_divorce      -0.22      0.05    -0.32    -0.13 1.00     4401\n                Tail_ESS\nIntercept           2940\nsigma_Intercept     3360\nmother              3148\nsigma_divorce       3068\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nHere we go. We see clearly that there is less residual variation when the mother is the only parent. We can visualise this too. We have to use “predict” method, because this leads brms to include the residuals (sigma) in the uncertainty intervals. This plot nicely recapitulates our scatter plots from above.\n\n\nconds <- data.frame(divorce = c(0,1))\nrownames(conds) <- c(\"not divorced\", \"divorced\")\nplot(marginal_effects(mod, effects = \"mother\", \n                 method = 'predict',\n                 conditions = conds))\n\n\n\n\nSummary\nIt often helps to generate data according to the model we have in mind. Even such simple simulations can give us a sense of whether we are able to recover our model and sometimes they may lead us to notice that we are using a word like “influence” in a very vague sense and deriving the wrong test because of that. A way that helps me clarify this is to ask whether I am really thinking about another influencing variable that is reduced in importance (here, the father).\nIn personality psychology, I think a lot of us intuitively grok this problem when the two variables are the same thing measured twice (e.g. stability, consistency, items), but even then we sometimes lose sight of it.4 Maybe one reason is that for more complex questions, the right models are harder to fit. That’s where brms comes in handy.\nAcknowledgements\nThanks to Lisa Reiber, Julia Rohrer, and Paul Bürkner for related discussions.\n\nI am very fond of simulating things to figure out stuff that others may learn through math, I just grok it more quickly. Fortunately, it works similarly for Lisa, so we decided to share this simple model.↩︎\nThis is a bit internally inconsistent with them wanting to share parenting equally before, but whatever, custody battles really favour mothers in this hypothetical world.↩︎\nYou can see how neatly it recovers all the parameters in our data-generating model.↩︎\nAnother problem may be that our love-hate relationship with measurement error makes us regard absolute regression coefficients with suspicion, and as fickle.↩︎\n",
    "preview": "posts/2019-03-12-moderation-vs-distributional-regression/moderation-vs-distributional-regression_files/figure-html5/unnamed-chunk-8-1.png",
    "last_modified": "2021-03-04T14:31:44+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2019-03-08-the-golden-age-of-never-finishing-anything/",
    "title": "The Golden Age of Never Finishing Anything",
    "description": "Serialising the results from our sex diary study.",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2019-03-11",
    "categories": [
      "sex diary",
      "open science"
    ],
    "contents": "\nI have too many unfinished projects. Thanks to social media, I know I’m not alone with this problem, but this is probably the only thing I can thank social media for with respect to this.\n\n\n\nFigure 1: Sagrada Família. Unfinished projects can still be pretty neat. From Wikipedia.\n\n\n\nDuring my PhD I (barely) wrapped up two projects with supersized supplementary websites that contained lots of extra work, robustness analyses, so many little sidetracks, footnotes and so on. In one case, it took me so long to finish the project that I felt compelled by my newly gained statistical knowledge and love of brms to do over all main analyses. Although I’m not a perfectionist1, the fact that traditional publication is final and corrections are difficult exacerbated any such tendencies in me.2 In the end, making these websites was fun and I learned a lot, but few people ever really engaged with their contents.3\nThat is okay - not everyone needs to care about the intricacies behind the question whether older fathers have more harmful mutations in their sperm, or the many decisions on can make when calculating a fertile window probability. Nor do most people stay around me at parties when I start talking about a cool R package I found for easily using a computing cluster.\nThen again, some people may care. Potentially related to this, we are currently in the Second Golden Age of Television according to some. Some of this is due to the ability to reach more niche audiences using the internet. Maybe this format just takes advantage of our more limited attention spans. Anyway, it might work for me.\n\n\n\nFigure 2: Tower of Babel by Lucas van Valckenborch (1594). Famously unfinished because of Netflix binging. From Wikipedia.\n\n\n\nIn an effort to stop myself accumulating results sections in need of introduction and discussion, and to get a chance to talk about some of the smaller steps in the process, I decided to start blogging a current project. Fittingly, there is a project that I started during the last year of my PhD. It would have provided ample data for my post-doc in Göttingen, but I moved back to Berlin to work at the MPI. The project suffered owing to the many new exciting collaborations that resulted from this move. We wrote a humongous preregistration for it, but did not give enough thought to the question how we would organize all these results.4\nI plan to blog preliminary5 results from this large sex diary study, but also nifty workflow stuff, lost trails in the literature, struggles with my own preregistration, and so on. I hope this bite size series on this project can start discussing some results sooner. I still hope to publish most of this in traditional journals at some point, but this approach makes make me feel less bad about working on some smaller projects before finishing the write-up of our fifty preregistered hypotheses.\n\n\n\nFigure 3: The Berlin Babel Imitation. When I read about how they have to replace all monitors because they installed them six years before opening, I was painfully reminded of transitioning my years-old code to dplyr 0.8.0. From Wikipedia.\n\n\n\nTry using formr.org or codebook and you’ll find this to be true↩\nNot that the results were anywhere close to perfect.↩\nAnd I’m not saying I know this because I hid hilarious easter eggs in these supplements that no one ever found.↩\nThis experience is one of the reasons I’m a big believer in Registered Reports, which require us to be more realistic about these things.↩\nBut not that preliminary. My bug bounties apply to these posts.↩\n",
    "preview": "https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Baldomer_Gili_Roig._La_Sagrada_Fam%C3%ADlia%2C_1905_Copia_moderna_del_negatiu_original_de_vidre.jpg/981px-Baldomer_Gili_Roig._La_Sagrada_Fam%C3%ADlia%2C_1905_Copia_moderna_del_negatiu_original_de_vidre.jpg",
    "last_modified": "2020-06-06T06:58:54+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-01-21-genetic-analyses-and-solidarity/",
    "title": "Genetische Analysen implizieren keineswegs Unmenschlichkeit – im Gegenteil",
    "description": "Genetische Unterschiede sind ein Argument für den Sozialstaat",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      },
      {
        "name": "Gert G. Wagner",
        "url": {}
      },
      {
        "name": "Philipp Köllinger",
        "url": {}
      }
    ],
    "date": "2019-01-21",
    "categories": [],
    "contents": "\nMy colleagues and I wrote the following (in German) to announce the release of a new GWAS on risk preferences. We also respond to an article in the Sueddeutsche Zeitung on the heritability of intelligence that we thought was misleading on some major points. Maybe some of those misconceptions and the desire to reject genetic explanations for individual differences come from an assumption that genetic research must lead to a “survival of the fittest” mentality. We disagree. A shorter version appeared in the Sueddeutsche Zeitung today.\ngekürzt erschienen unter dem Titel „Argumente für mehr Solidarität“ in der Süddeutschen Zeitung am 21. Januar 2019, S. 18\nRuben C. Arslan ist Psychologe am Max Planck Institut für Bildungsforschung, Berlin, wo auch der Ökonom Gert G. Wagner tätig ist. Philipp Köllinger ist Professor für Genom-Ökonomie an der Freien Universität Amsterdam. Köllinger und Wagner sind auch Research Fellows am Deutschen Institut für Wirtschaftsforschung (DIW Berlin). Alle Autoren waren 2014 bis 2017 Mitglied in der Forschergruppe „Genetic and Social Causes of Life Chances“ am Zentrum für interdisziplinäre Forschung (ZiF) der Universität Bielefeld.\nMitte Januar 2019 ist in der Fachzeitschrift Nature Genetics ein Aufsatz zu den genetischen Grundlagen der menschlichen Risikobereitschaft online gegangen, an dem zwei der Autoren dieses Beitrags beteiligt sind (u.a. auf Basis der Daten der Berliner Altersstudie). Im Genom von über einer Million Menschen, deren Daten analysiert wurden, wurden 124 Stellen gefunden, die die Risikobereitschaft vorhersagen, die von den analysierten Befragten angegeben wurde. Außerdem wurden entsprechende molekulargenetische Zusammenhänge mit tatsächlichem Verhalten, etwa Rauchen und Trinken, gefunden. Aber von der enormen Streuung der menschlichen Risikobereitschaft kann durch einzelne Gen-Varianten fast nichts statistisch erklärt werden. Die wichtigste Variante erklärt nur 0,02 Prozent der Streuung – statistisch signifikant, also kein reiner Zufall, aber trotzdem wird so gut wie kein Unterschied in der Risikobereitschaft durch eine Stelle im Genom erklärt.\nDurch die Betrachtung von größeren Bereichen des Genoms, die Millionen von einzelnen Gen-Buchstaben enthalten (aus über sechs Milliarden Buchstaben, aus denen ein menschliches Genom besteht), konnten immerhin 1,6 Prozent der Streuung statistisch aufgeklärt werden. Die winzigen Effekte vieler Stellen im Genom summieren sich. Aber auch nun würde es sich nicht lohnen die Speichelproben von Investmentbankern zu analysieren, um herauszufinden, wie risikobereit sie sind. In der Studie wird ausdrücklich festgestellt, dass das Ergebnis der Analyse sich nicht eignet um die Risikobereitschaft eines einzelnen Menschen vorherzusagen – der Prognosefehler wäre viel zu hoch. Wozu also der ganze Aufwand? Was kann man aus solchen Genom-Analysen schlussfolgern und was nicht? Sind derartige genetische Analysen nicht von Grund auf menschenunwürdig und führen in moralische Abgründe? „Nein“ ist unsere im folgenden begründete Antwort. Genetische Erkenntnisse können sogar zur Menschenwürde beitragen, da sie gute Argumente liefern für Solidarität und für Bestrebungen hin zu mehr Chancengleichheit in unserer Gesellschaft.\nErst einmal ist gewissermaßen „innerwissenschaftlich“ festzuhalten, dass die erfolgreiche Erklärung von psychologischen Unterschieden durch molekulargenetisch gemessene Unterschiede die bereits länger bestehenden Kernergebnisse der sogenannten Verhaltensgenetik bestätigt. Diese Disziplin berechnet auf Basis von Studien zur Ähnlichkeit von beispielsweise adoptierten Geschwistern oder separat aufgewachsenen eineiigen Zwillingen die Wichtigkeit von genetischen Unterschieden gezeigt. Demnach sind im statistischen Mittel genetische Unterschiede innerhalb von Familien maßgeblicher für Persönlichkeit und kognitive Leistungsfähigkeit als Unterschiede in der Erziehung zwischen Familien. Eltern mit mehreren Kindern wissen auch wie unterschiedlich ihre Kinder sein können, obwohl ihre familiäre und soziale Umgebung ja ähnlich ist. Aber weder die menschliche Erfahrung und erst recht nicht die neuartigen genetischen Analysen können die Kritiker der Humangenetik überzeugen.\nKürzlich bestritt zum Beispiel der Regensburger Psychologieprofessor Christof Kuhbandner in der Süddeutschen Zeitung (14. Dezember 2018), dass Intelligenz überhaupt in einem nennenswerten Ausmaß erblich sei – und legt nahe, dass Kinder mehr lernen, wenn man sie glauben lässt, dass an Intelligenz nichts Angeborenes ist. Er kritisiert die Aussagekraft der Verhaltensgenetik und prognostiziert, dass das Genom niemals mehr als etwa vier Prozent der Streuung von gemessener Intelligenz vorhersagen können wird. In der Tat sind es aber bereits jetzt bis zu 10 Prozent, die sich molekulargenetisch erklären lassen, d. h. durch die Betrachtung des Genoms im Detail – Buchstabe für Buchstabe. Und selbst wenn es wirklich „nur“ vier Prozent wären, wäre das eine ganze Menge. Wenn jemand bei allen gefundenen Genen die intelligenzzuträglichen Varianten hätte, entspräche das dem Effekt eines zusätzlichen Schuljahrs. Und Kuhbandner unterschätzt die genetische Prognostik systematisch. Er hat zwar recht, dass Gen-Varianten, die mit Hilfe von immer größeren Stichproben von Menschen gefunden werden, immer weniger an Streuung erklären werden (weil man die größeren Effekte bereits mit kleineren Stichproben gefunden hat), aber das bedeutet nicht, dass deswegen die Analyse nicht lohnt. Denn es werden immer mehr einzelne Gen-Buchstaben gefunden werden, die in ihrem Zusammenwirken sehr wohl mehr erklären werden. Dies zeigen Studien beispielsweise zur Genetik von Körpergröße sehr eindeutig. Für diese Bereiche können wir bereits jetzt ein Viertel der Streuung mit Hilfe tausender Gen- Buchstaben erklärt werden. Forscher nehmen an, dass für den IQ über 30% mit riesengrossen Stichproben von Millionen von Menschen aus den Molekülen des Genoms vorhersagbar sein werden. Auch wenn 30 Prozent übertrieben sein mögen, zeigen die Molekulargenetik, dass angeborene Unterschiede der Intelligenz nicht ganz unwichtig sind. Das heisst aber natürlich nicht, dass deswegen die Schlaueren dies ungehemmt ausnützen können sollten. Wir werden darauf am Ende zurückkommen.\nErziehungswissenschaftler wie auch Kuhbandner argumentieren auf einer pädagogischen Ebene. Sie sagen, dass es für Kinder in der Schule besser sein, wenn man gar nicht von angeborenen Unterschieden spricht. Wir behaupten das genaue Gegenteil. Es wäre offenbar ja unverantwortlich und grausam, von einem Kind mit eingeschränkter kognitiver Leistungsfähigkeit soviel zu erwarten wie vom begabten Geschwisterkind. Genauso wäre es grausam jemandem, der mit Mühe den Schulabschluss geschafft zu empfehlen, doch zum Softwarearchitekten umzuschulen, wenn seine berufliche Tätigkeit wegautomatisiert wird. Die Note von „nicht bestanden“ in „noch nicht bestanden“ zu ändern, wie Kuhbander nahe legt, wird auch kaum helfen – neuere Studien können die von Carol Dweck vermarkteten Erfolge des growth mindset jedenfalls nicht unabhängig replizieren.\nSchule bildet ohne Zweifel, aber sie kann die Effekte genetischer Unterschiede nicht völlig einebnen. Man kann auch Menschen durch „Schulung“ nicht beliebig risikofreudig machen, um mehr Unternehmertum zu haben oder sich einiges an sozialer Sicherung zu ersparen, da risikofreudige Menschen große Einkommensschwankungen klaglos hinnähmen.\nBei der modernen genetischen Forschung, wie sie hier berichtet wird, geht es auch nicht nur darum einzelnen Menschen bessere Therapien bei schweren Krankheiten oder maßgeschneiderte Lehr-Konzepte anzubieten (es bleibt ohnehin abzuwarten was da möglich sein wird). Es geht auch darum, und das mag sich am Ende vielleicht als noch wichtiger erweisen, bestimmte gesellschaftliche Strukturen, die immer wieder in Gefahr geraten zerstört zu werden, besser zu begründen und abzusichern als bislang. Also: Man sollte die Evidenz relevanter genetischer Unterschiede nicht leugnen. Sie bedeutet keineswegs, dass daraus ein „Survival of the Fittest“ als normative Leitlinie für das menschliche Zusammenleben folgen muss. Ganz im Gegenteil! Man kann auch ohne weiteres auch argumentieren, dass Nachteile, die einem Menschen durch seine „genetische Ausstattung“ entstehen, von der Gesellschaft zumindest teilweise kompensiert, vielleicht sogar möglichst weitgehend ausgeglichen werden sollten, da ja niemand was für seine Gene kann und sie mit dazu beitragen an welcher Stelle in der Gesellschaft sich jemand findet. Vielfältigkeit der Menschen ist ein Wert an sich. Genetische Vielfalt erhöht die Anpassungsfähigkeit einer Art und Gene, die heutzutage mit Nachteilen verbunden sind, können sich in Zukunft für die Menschheit als lebenswichtig erweisen. In der Tat orientiert sich unsere Steuer- und Sozialpolitik an diesen Überlegungen – in Deutschland und in vielen Ländern in der Welt. Wir wollen die Menschen nicht gleichmachen, sondern wir wollen Nachteile aller Art, mit denen wir ohne eigene Schuld durch das Leben gehen müssen, soweit es vernünftig ist, kompensieren.\nEin Wirtschaftsphilosoph, John E. Roemer, hat diesen Standpunkt mit seiner Theorie zur Chancengleichheit (Equality of Opportunity) auf den Punkt gebracht: individuelle Anstrengung sollte sich lohnen, aber Unterschiede im Einkommen, die sich aufgrund der Chancen ergeben, die einem die Eltern mitgaben (sowohl genetisch wie sozial), sollten durch Steuern und Transfers ausgeglichen werden. Eine progressive Besteuerung hoher Einkommen einerseits und andererseits Transfers an Menschen, die Probleme haben ein ordentliches Einkommen zu erzielen, machen genau dieses. Natürlich nicht perfekt, aber weit jenseits eines ungebremsten individuellen Egoismus, der un-verdiente Vorteile, die jemand mitbekommen hat, ausnützt. Mit anderen Worten: Da eine günstige genetische Ausstattung im Wortsinne un-verdient ist, können die Analysen, die die Bedeutung der Gene für das menschliche Leben zeigen, die Argumente für einen starken Steuer- und Sozialstaat stärken.\n\n\n",
    "preview": {},
    "last_modified": "2020-06-06T06:58:53+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-01-02-are-studies-that-replicate-cited-more/",
    "title": "Revised: Are studies that replicate cited more?",
    "description": "Looking at the RPP to bring data to a discussion",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      },
      {
        "name": "Ioanna Iro Eleftheriadou",
        "url": {}
      }
    ],
    "date": "2019-01-02",
    "categories": [
      "meta science",
      "open science",
      "reproducibility",
      "quick job"
    ],
    "contents": "\nReplication in the Reproducibility Project Psychology and citations\n\n\n\nFigure 1: Does it replicate? From the Internet Archive Book Images\n\n\n\nAfter his talk at the Center for Adaptive Rationality, Stephan Lewandowsky and I had a small discussion whether scientists can actually pick “winners”. The discussion stemmed from a larger discussion about whether we get more research waste, if we replicate first, then publish, or publish first, and then replicate those studies that are found interesting.\nIf I recall correctly, we didn’t really disagree that scientists can tell if things are off about a study, but we did disagree on whether citation indexes such a quality assessment, and is a useful way to find out which studies are worthy of more attention.\nSo, I ran the numbers for one of the few studies where we can find out, the Reproducibility Project: Psychology. I tweeted it back then, but felt like making the graphs nicer and playing with radix on a train ride.\n\n\n\n\n\n\n\n\n\nWe found 167 DOIs, so we had DOIs for all our studies1.\n\n\nscopus_pre2015\nscopus_2018\nscopus_post2015\ngscholar_pre2015\ncrossref_2018\nmixed_post2015\nscopus_pre2015\n1.00\n0.98\n0.93\n0.97\n0.97\n-0.05\nscopus_2018\n0.98\n1.00\n0.98\n0.97\n0.98\n0.04\nscopus_post2015\n0.93\n0.98\n1.00\n0.93\n0.97\n0.13\ngscholar_pre2015\n0.97\n0.97\n0.93\n1.00\n0.97\n-0.15\ncrossref_2018\n0.97\n0.98\n0.97\n0.97\n1.00\n0.10\nmixed_post2015\n-0.05\n0.04\n0.13\n-0.15\n0.10\n1.00\n\nDoes replication in the RPP predict how often a paper is cited?\nNo, not for the citation count recorded in the RPP.\n\n\n\nCall:\nglm(formula = citations_2015 ~ replicated_p_lt_05, family = quasipoisson(), \n    data = .)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-8.331  -4.810  -1.726   3.067  14.583  \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            3.93854    0.09962  39.534   <2e-16 ***\nreplicated_p_lt_05yes -0.08052    0.17203  -0.468    0.641    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 32.61327)\n\n    Null deviance: 2813.6  on 98  degrees of freedom\nResidual deviance: 2806.4  on 97  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\nDoes replication predict 2018 citation counts?\nDetails: I got DOIs, which were missing from the RPP data, by searching Crossref on titles, authors, and dates. I did some checking to see if matches were proper. Next, I got citation counts from Scopus and validated those against those in the RPP and Crossref. Find the improved dataset with DOIs below.\nI used the Crossref API to get DOIs and the Scopus API to get yearly citation counts for the papers contained in the RPP.\nEdit: The SCOPUS citation count up to 2015 was highly correlated with the one stored in the dataset (based on Google Scholar). Rank order were also very similar for citations pre and post 2015 using Scopus, CrossRef, or Google Scholar. However, subtracting CrossRef citation counts from Google Scholar counts amplified error (to get citations after the publication of the RPP) - the correlation with the “citations after 2015 (Scopus)” variable was low. Therefore, the revised version of this blog post uses only the Scopus numbers.\nAgain, there was no association with replication status for 2018 citation counts.\n\n\n\nCall:\nglm(formula = citations_2018 ~ replicated_p_lt_05, family = quasipoisson(), \n    data = .)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-11.005   -6.988   -3.263    4.546   19.781  \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            4.50328    0.10635  42.344   <2e-16 ***\nreplicated_p_lt_05yes -0.04297    0.18138  -0.237    0.813    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 65.37293)\n\n    Null deviance: 5660.0  on 98  degrees of freedom\nResidual deviance: 5656.3  on 97  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\nDoes replication predict subsequent citation counts (ie. 2015-2018)?\nThe correlation between 2018 Scopus and 2015 Google Scholar counts is 0.97, but the means differ (2018 Scopus = 72, Scholar 2015 = 90). Can citations go down? No, but Google Scholar includes more sources than Scopus, leading to the mean being higher. Still, these sources don’t seem to be systematically different, leading to the maintained rank order.\n\n\n\nThis is pretty dirty work, because I’m subtracting citation counts from one source with another, so most papers are cited less in 2018 than in 2015. But haven’t found a quick way to get citation counts in 2015 from rcrossref. I’ve requested the necessary access to Scopus, where I could check, but Elsevier is being annoying.\nAgain, no association. So, assuming the dirtiness of the analysis doesn’t matter, \nThe literature hasn’t reacted at all to the presumably important bit of information that a study doesn’t replicate.\n\n\n\nCall:\nglm(formula = citations_after_2015 ~ replicated_p_lt_05, family = quasipoisson(), \n    data = .)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-7.899  -5.302  -2.963   3.103  13.664  \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           3.662760   0.119244  30.717   <2e-16 ***\nreplicated_p_lt_05yes 0.004458   0.200260   0.022    0.982    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 35.46258)\n\n    Null deviance: 3101.3  on 98  degrees of freedom\nResidual deviance: 3101.3  on 97  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\nWhat about self citations?\nThe RPP emphasised its own overall result. Hence, some nonreplications of specific studies may have gone unnoticed by researchers in the field. But the study authors hardly have this excuse; they knew whether their study was replicated (probably even prior to 2015, but this is hard to figure out). However, there is also no significant difference in self citation count (before or after 2015) by publication status.\n\n\n\nCall:\nglm(formula = self_cites_before_2015 ~ replicated_p_lt_05, family = quasipoisson(), \n    data = .)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-4.1533  -1.8906  -0.3514   1.3266   6.3949  \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            2.15466    0.09269  23.246   <2e-16 ***\nreplicated_p_lt_05yes -0.07880    0.15997  -0.493    0.623    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 4.742497)\n\n    Null deviance: 463.83  on 98  degrees of freedom\nResidual deviance: 462.67  on 97  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\nCall:\nglm(formula = self_cites_after_2015 ~ replicated_p_lt_05, family = quasipoisson(), \n    data = .)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.6939  -2.0400  -0.6064   0.3752   7.5933  \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             1.0934     0.1699   6.437 4.65e-09 ***\nreplicated_p_lt_05yes   0.1954     0.2688   0.727    0.469    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 5.510687)\n\n    Null deviance: 429.28  on 98  degrees of freedom\nResidual deviance: 426.40  on 97  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 6\n\nHow does pre-2015 citation count predict post-2015 citations accounting for replication status?\nA slightly different way of looking at it does not yield different conclusions for me.\n\n\n\nDoes the association differ by journal?\nHard to tell with this little data!\n\n\n\nCall:\nglm(formula = citations_2015 ~ Journal * replicated_p_lt_05, \n    family = quasipoisson(), data = .)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-8.331  -4.332  -1.445   2.532  12.122  \n\nCoefficients:\n                                  Estimate Std. Error t value\n(Intercept)                        3.47197    0.24258  14.313\nJournalJPSP                        0.64544    0.27814   2.321\nJournalPS                          0.49518    0.28506   1.737\nreplicated_p_lt_05yes             -0.18759    0.37517  -0.500\nJournalJPSP:replicated_p_lt_05yes -0.01447    0.50369  -0.029\nJournalPS:replicated_p_lt_05yes    0.36557    0.43739   0.836\n                                  Pr(>|t|)    \n(Intercept)                         <2e-16 ***\nJournalJPSP                         0.0225 *  \nJournalPS                           0.0857 .  \nreplicated_p_lt_05yes               0.6182    \nJournalJPSP:replicated_p_lt_05yes   0.9771    \nJournalPS:replicated_p_lt_05yes     0.4054    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 28.42273)\n\n    Null deviance: 2813.6  on 98  degrees of freedom\nResidual deviance: 2419.1  on 93  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\nConclusion\nSo, are citation counts a poor indicator of quality? The most common reaction I received to these results was saying that the 7 years from the publication of the studies to 2015 are probably not enough for citation counts to become more signal than noise, or at least that the 3 years from the publication of the RPP results to 2018 are not enough. These reactions mostly came from people who did not really believe in citations-as-merit before anyway.\nTo me, if 10 years after publication citations cannot be used to distinguish between studies that replicated and those that didn’t, they’re probably not a useful measure of thoroughness that can be used in assessment, hiring, and so on. They may be a useful measure of other important skills for a scientist, such as communicating their work; they may measure qualities we don’t want in scientists, but it seems they are not useful to select people whose work will replicate. I think that is something we should want to do.\nIn addition, the literature does not react quickly to the fact that studies do not replicate. Given that people also keep citing retracted studies (albeit with a sharp drop), this does not surprise me. It will be interesting to revisit the data in a few years time and see if researchers picked up on replication status then.\nLimitations\nThese were all studies from reputable journals, so we might have some range restriction here. On the other hand, plenty of these studies don’t replicate, and citation counts go from 0 to >300.\nWhich studies keep being cited after not being replicated?\nHover your mouse over the dots to see the study titles.\n\n\n\nWhich authors keep citing their own studies after they do not replicate?\nHover your mouse over the dots to see the study titles.\n\n\n\nList of studies\n\n\n\nAppendix\n\n\n\nThese analyses are based on Chris J. Hartgerink’s script. The data and his script can be found on the OSF. Did I get the right DOIs? There are probably still some mismatches. Titles are not exactly equal for 84 studies, but on manual inspection this is only because Crossref separates out the subtitle, and 150 of 167 titles start exactly the same.\nWere they they all correct? See Appendix↩\n",
    "preview": "posts/2019-01-02-are-studies-that-replicate-cited-more/are-studies-that-replicate-cited-more_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2020-06-06T06:58:54+02:00",
    "input_file": {},
    "preview_width": 1152,
    "preview_height": 768
  },
  {
    "path": "posts/2018-10-26-on-making-mistakes-and-my-bug-bounty-program/",
    "title": "New rational athletics for boys and girls.",
    "description": "Accounting for mistakes in my scientific work and announcing a bug bounty program.",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      }
    ],
    "date": "2018-10-26",
    "categories": [
      "mistakes",
      "bug bounty"
    ],
    "contents": "\nA story of few papers and many corrections\nMy first published paper had a typo in the title. I had gone over every use of the word “parental” and “paternal” in my draft and asked a friend to do the same, because I knew I tended to mix them up. I forgot the title. I emailed PLoS ONE frantically when I noticed, as the paper had not yet been published, but apparently it slipped their mind, and I had to ask again after publication.\nSo, my academic career started with a correction. And it was not going to be the last.\n\n\n\nFigure 1: Figure from the book New rational athletics for boys and girls (1917) in the Internet Archive Book Images\n\n\n\nHere, we accidentally reported a lower cutoff than we actually used owing to some miscommunication to my co-authors on my part.\nAnd recently, my co-authors and I replied to a critical commentary of one my dissertation papers. I actually love this kind of stuff, as I personally feel that I learn the most when seeing a nice debate between two parties of opposite viewpoints.1 However, this was a fundamentally dissatisfying experience because I spent more time battling journal submission forms than counter-arguments, because the journal caused a version problem and then hardly owned up to the mistake (see Appendix).\nI only noticed the version problem because an anonymous submission via my Tell me I’m wrong form alerted me to the fact that I was misquoting the authors. Thank you, anonymous commenter.\nAnd lately, I’ve received some useful post-publication peer review of my ovulatory changes paper. I had put all my code online, and a previous peer reviewer was actually motivated to check it for errors. Others like Dan Engber or Mike Wood just noticed problems right away, by virtue of their different background in journalism and statistics. This is great, but I admittedly dread another corrections process. I would love to work in a system where we publish and update our knowledge base more continuously than through the antiquated system of publication, correction, and retraction. But I don’t and here’s an attempt to reckon with that.\nConsequences\nThis is the story of the mistakes I know about so far. It is not an impressively low rate for a fledgling scientist, but I’m at my limit in terms of reducing my own error rate through best practices on my own.2\nI also know that for every new release of formr.org that involves more than a few lines of code, I make mistakes. With formr.org I usually find out quite early, because users notice the ensuing problems. Some of my scientific data analyses also involve a lot of code. Do I magically make fewer errors when working with R than with PHP and JavaScript?\nNo. If I’m honest with myself, I think there are probably even more errors in my work than the ones that have been found. Unfortunately, psychological science does not have a well-developed error culture and it is rare for people to reanalyse others’ data, even if they build on it.\nCode review\n\n\n\nFigure 2: Watch closely. Figure from the book New rational athletics for boys and girls (1917) in the Internet Archive Book Images\n\n\n\nIt is probably a co-incidence, but my paternal and fitness paper was the only one where one of my co-authors (thanks, Kai) independently re-did some of my central analyses completely independently3 - and it is also the only one where I haven’t yet had to issue a correction, even though I was primarily responsible for analysis.\nSo, I want to further promote code review in my work. I urge it on the people I supervise, I’m collaborating on a draft to advertise the practice. But there is also one other avenue that I want to try.\nA bug bounty program\n\n\n\nFigure 3: Get him. Figure from the Internet Archive Book Images\n\n\n\nSo, I’m announcing a bug bounty program. Briefly, I will pay you to report errors in my work to me (up to 760€). It generally only applies to first-authored scientific work I publish from now on, but my co-author and friend Laura Botzet volunteered her first-authored preprint on birth order effects in Indonesia as a guinea pig. I’m senior author on this paper, and tried my best to check the code (I also wrote some parts myself). Data and code are openly available, so if you feel like playing with a cool dataset and an interesting research question, we encourage you to check and review our code. Please see here for the exact conditions4\nA bad error culture at Proceedings of the Royal Society B\nI was invited to peer review the critique5 and pointed out a few factual errors. As a result, the critique that was accepted for publication already partially addressed some counterpoints, leading to a quite jumbled argument-counterargument sequence.\nThen, the journal messed up. After a first round of peer review and then acceptance, they allowed the authors to revise their critique further. The authors substantially changed the text and added two new arguments. But the journal sent me the older version to comment, not the one they published. As a result, our reply quotes the commenters three times - and none of those quotes are in the published version - we looked quite sloppy.\nMistakes happen (I know!), but it took a while for the journal to acknowledge the mistake, and even longer for them to decide how to deal with it. We then had to submit an erratum (apparently, in their parlance, an erratum is for journal errors, corrections are for author errors). The journal then desk-rejected the erratum, because they felt replying to the newly added arguments didn’t fit in the erratum. I then added a sentence to reflect the fact that we were not allowed to respond to these additional points. They removed this sentence without my consent, and then rephrased the erratum to put it in the journal’s voice. In the end, this is all they published. The whole ordeal after I pointed out the error, took from March to August, in excess of 40 emails, and a lot of nerves.\nThe original authors also did not permit me to simply post the versions that we were reacting to, including the review process, to actually allow those who care to see the whole back and forth. For posterity, the director’s cut of the erratum is here.\nI still need to read The Enigma of Reason which makes the point that arguing is how we reason best.↩\nOr at least at the level that collaborators and employers will tolerate with respect to how much this slows me down↩\ndifferent data cleaning, used Stata instead of R, used a different model in some places↩\nThey are phrased rather lawyerly, because I would expect a bug bounty program to attract nitpicky people.↩\nwhich I didn’t like because I didn’t feel I should get to influence whether criticism of my work is published↩\n",
    "preview": "https://farm6.staticflickr.com/5578/14804680103_c8d5ef8ef0_o_d.jpg",
    "last_modified": "2020-06-06T06:58:54+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2018-10-15-are-big-studies-cited-more/",
    "title": "Are big studies cited more?",
    "description": "Does sample size predict number of citations?",
    "author": [
      {
        "name": "Ruben C. Arslan",
        "url": "https://rubenarslan.github.io"
      },
      {
        "name": "Ioanna Iro Eleftheriadou",
        "url": {}
      }
    ],
    "date": "2018-10-22",
    "categories": [
      "meta science",
      "open science",
      "reproducibility",
      "quick job"
    ],
    "contents": "\nAfter asking whether studies that replicate are cited more and finding that this is not the case, I turned to a different analysis that I once did quickly. Namely, I reviewed the N-pact paper by Chris Fraley and Simine Vazire back in 2014. I got excited about the paper, as I’m wont to, and tried redoing their analyses because they had provided the data with their manuscript. I also decided to see if I could find a relationship at the article level as well.\n\n\n\nFigure 1: Ample size? From the Internet Archive Book Images\n\n\n\nIro Eleftheriadou, our new RA, helped me clean up the messy code that I wrote at the beginning of my dissertation (for-loops, ugh).\n\n\n\n\n\n\n\n\n\nAgain, we first needed to get the DOIs by querying the Crossref API. Using the DOIs, we could next get the citation counts. We found 1028 DOIs out of 1042 studies.\nReproducing the original result\nHere, I first checked whether I would obtain the same measure as Fraley & Vazire did, when I simply averaged the citations to the articles in this set for each year and journal. Interestingly, I could not, or at least it was substantially weakened. I’m pretty sure that when I did this in 2014, I could reproduce the finding. As you can also see, the association is even weaker when using medians for the citation counts instead of means. However, I can still reproduce their original result with the Thomson-Reuters Impact Factors that I quickly googled. I know the Impact Factor isn’t just a simple metric, but a shady business including some negotiation. Do journal executives sometimes try a pity move, asking for a higher impact factor by highlighting paltry poor sample sizes? It’s impossible to prove this never happened ;-)!\n\n\n\nFigure 2: Correlation between IF and NF on the journal level.\n\n\n\nMoving to the study level\nFraley & Vazire were interested in highlighting how impact factors do not track a no-nonsense aspect of study quality (all else equal, bigger N is simply better). So, they focused on journals. But I, having recently invested a lot of time into obtaining large samples, was curious to see whether these efforts translated into any sort of citation advantage, and more generally, whether we pay more attention to research that is presumably more reliable.1.\nBy year of publication\nMaybe it takes us some time to notice how paltry a sample size was?2 Or maybe early citations are all about the glamour and flair, but over time the best and biggest studies win out?\n\n\n\nFigure 3: There is no association between N and citations, including for studies that had more years to accumulate citations.\n\n\n\nBy journal\nMaybe we don’t see an association between N and citations in Psychological Science, because some small-N papers are solid vision studies with good power within-subject? In the analysis by journal, we see that there is no association between sample size and number of citations within each journal, including some that focus on personality research only, which is a pretty N-driven area.\n\n\n\nFigure 4: Even in the Journal of Personality and the Journal of Research in Personality, there is no association between N and citations. There appears to be some in SPPS, but the number of studies is small and we should not overinterpret it.\n\n\n\nThe Spearman rank correlations between sample size and citations by journal tell the same story.\n\nTable 1: Correlation values per journal\nIF\nNF\nJournal\nk_studies\ncorrelation\n21\n194\nSPPS\n48\n0.36\n32\n273\nJRP\n129\n0.05\n34\n119\nJESP\n192\n-0.01\n46\n147\nPSPB\n155\n0.14\n49\n334\nJP\n70\n0.01\n65\n132\nPS\n269\n0.02\n85\n225\nJPSP\n179\n-0.01\n\nThere isn’t really any perceptible time trend in sample size,3 but it still seems worthwhile to divide the citation count by number of years until 2018 to see whether that makes a difference.\n\n\n\nFigure 5: We do not collect bigger samples over time.\n\n\n\nIt does not.\n\n\n\nFigure 6: Because there is no sample size trend, citations over years published is not related to sample size any differently than simple citation count.\n\n\n\nMaybe the problem is that I ignored the fact that citations are a count variable and did not adjust those correlations for the publication year. Nope!\n\nTable 2: Predicting citation count\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\nreis_n\n1.00\n0.00\n1.3\n0.2\n1.00\n1.00\nYear\n0.83\n0.02\n-8.1\n0.0\n0.79\n0.87\nTable 2: Predicting citation count by journal\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\nreis_n\n1.00\n0.00\n-0.37\n0.71\n1.00\n1.00\nJournalJP\n1.16\n0.27\n0.54\n0.59\n0.67\n1.94\nJournalJPSP\n2.08\n0.17\n4.36\n0.00\n1.49\n2.90\nJournalJRP\n0.83\n0.23\n-0.78\n0.43\n0.53\n1.30\nJournalPS\n1.74\n0.16\n3.45\n0.00\n1.27\n2.39\nJournalPSPB\n1.17\n0.20\n0.76\n0.45\n0.78\n1.73\nJournalSPPS\n0.70\n0.39\n-0.91\n0.36\n0.30\n1.44\nYear\n0.85\n0.02\n-7.49\n0.00\n0.81\n0.88\nreis_n:JournalJP\n1.00\n0.00\n0.63\n0.53\n1.00\n1.00\nreis_n:JournalJPSP\n1.00\n0.00\n0.73\n0.47\n1.00\n1.00\nreis_n:JournalJRP\n1.00\n0.00\n0.46\n0.65\n1.00\n1.00\nreis_n:JournalPS\n1.00\n0.00\n0.33\n0.74\n1.00\n1.00\nreis_n:JournalPSPB\n1.00\n0.00\n0.44\n0.66\n1.00\n1.00\nreis_n:JournalSPPS\n1.00\n0.00\n1.12\n0.26\n1.00\n1.00\nTable 2: Predicting citation count by year\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\nreis_n\n1.24\n0.19\n1.1\n0.26\n0.85\n1.8\nYear\n0.85\n0.03\n-5.6\n0.00\n0.80\n0.9\nreis_n:Year\n1.00\n0.00\n-1.1\n0.27\n1.00\n1.0\n\nSo, how does sample size relate to citation counts?\nThere seems to be pretty much nothing there! Maybe we can come up with a post-hoc narrative by looking at all studies and seeing which studies are cited a lot and have large or small samples.\nHover your mouse over the dots to see the study titles. Jean Twenge with her humongous name study is hiding behind the legend, scroll to find her.\nMy current favourite post-hoc narrative is that citation counts are just very poor measures of importance. I wouldn’t bet that a better measure of importance would correlate with sample size, but I’m fairly convinced by now that citation counts just suck as a metric even of the thing they’re meant to index (impact/importance). I am especially worried about the difference simple citation counts make between a study that is synthesised in a review that then gets cited a lot4 and a study that doesn’t get synthesised in a review. I tried to make the case for a better, more PageRank-y metric, but it would already be interesting to redo my analysis here and from the previous blog post after excluding self citations. Unfortunately, Elsevier still hasn’t given me Scopus API access, and I lack the chops to do anything more fancy. I really hope projects like the Open Citations Corpus lead to such fancy metrics becoming available.\n\n\n\n\nFigure 7: Interactive plot of Ns and citation counts.\n\n\n\nLimitations\nWell, there are some vision studies in here that used a within-subject paradigm and probably had adequate power for the question they asked anyway. Their small sample size may limit generalizability to other people, but I guess that’s not the dominant question asked in vision science.5 But then again, for some pure-personality journals, we also find no association. There is of course the possibility that studies with very large Ns are more likely to use abbreviated measures, only self-report, and online samples. But then, they are also more likely to be from representative panel studies and online samples aren’t actually any less representative than lab samples. It seems unlikely that any disadvantages exactly balance out with the advantages associated with sample size, so that we arrive at a zero correlation with importance.\nList of studies\nThought of something fun to do with the data that I didn’t do here? Grab the data below!\n\n\n\n\n\n\nFigure 8: Ample size ain’t worth it. From the Internet Archive Book Images\n\n\n\nAppendix\nYou can grab the original data on the OSF. Did we get the right DOIs? There are probably still some mismatches and for some, we didn’t find the DOI at all.\nI understand this is a presumption, see limitations↩\nI hope nobody skims that badly.↩\nUgh, that alone is depressing. Since 2006, so many new tools came on the market. How did that not help?↩\nObviously, reviews aren’t included here, but neither is their reflected glory.↩\nWhich is consistent with the fact that there are low-hanging fruit like The Dress waiting to be picked in the study of individual differences in vision.↩\n",
    "preview": "posts/2018-10-15-are-big-studies-cited-more/are-big-studies-cited-more_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2020-06-06T06:58:54+02:00",
    "input_file": {},
    "preview_width": 1920,
    "preview_height": 768
  }
]
